
// ---------------- [ File: src/keys.rs ]
crate::ix!();

pub fn z2c_key(region: &WorldRegion, postal_code: &PostalCode) -> String {
    format!("Z2C:{}:{}", region.abbreviation(), postal_code.code())
}

pub fn s_key(region: &WorldRegion, postal_code: &PostalCode) -> String {
    format!("S:{}:{}", region.abbreviation(), postal_code.code())
}

pub fn c_key(region: &WorldRegion, city: &CityName) -> String {
    format!("C2S:{}:{}", region.abbreviation(), city.name())
}

pub fn c2z_key(region: &WorldRegion, city: &CityName) -> String {
    format!("C2Z:{}:{}", region.abbreviation(), city.name())
}

pub fn c2s_key(region: &WorldRegion, city: &CityName) -> String {
    format!("C2S:{}:{}", region.abbreviation(), city.name())
}

pub fn s2c_key(region: &WorldRegion, street: &StreetName) -> String {
    format!("S2C:{}:{}", region.abbreviation(), street.name())
}

pub fn s2z_key(region: &WorldRegion, street: &StreetName) -> String {
    format!("S2Z:{}:{}", region.abbreviation(), street.name())
}

/// Builds the RocksDB key for house-number ranges on a particular street in a region.
///
/// For example: 
///    `HNR:{region_abbr}:{street_name}`
/// where `street_name` has already been normalized to lowercase, 
/// but we rely on `StreetName::name()` for that.
pub fn house_number_ranges_key(region: &WorldRegion, street: &StreetName) -> String {
    format!("HNR:{}:{}", region.abbreviation(), street.name())
}

// ---------------- [ File: src/create_address_stream_channel.rs ]
crate::ix!();

/// Creates a bounded sync channel for streaming address results.
/// Returns `(SyncSender, Receiver)`.
pub fn create_address_stream_channel(
) -> (
    std::sync::mpsc::SyncSender<Result<WorldAddress, OsmPbfParseError>>,
    std::sync::mpsc::Receiver<Result<WorldAddress, OsmPbfParseError>>
) {
    // Capacity of 1000 is arbitrary; can be tweaked depending on performance needs.
    std::sync::mpsc::sync_channel(1000)
}

// ---------------- [ File: src/write_cities_to_region_and_street.rs ]
// ---------------- [ File: src/write_cities_to_region_and_street.rs ]
crate::ix!();

pub trait WriteCitiesToRegionAndStreet {
    fn write_cities_to_region_and_street(
        &mut self, 
        region: &WorldRegion, 
        street: &StreetName, 
        cities: &BTreeSet<CityName>
    ) -> Result<(),DatabaseConstructionError>;
}

impl WriteCitiesToRegionAndStreet for Database {

    fn write_cities_to_region_and_street(
        &mut self, 
        region: &WorldRegion, 
        street: &StreetName, 
        cities: &BTreeSet<CityName>
    ) -> Result<(),DatabaseConstructionError> {
        let key = s2c_key(region,street);
        self.put(&key, compress_set_to_cbor(cities))?;
        Ok(())
    }
}

// ---------------- [ File: src/street_exists_in_postal_code_in_region.rs ]
crate::ix!();

pub trait StreetExistsInPostalCodeInRegion {

    fn street_exists_in_postal_code(
        &self, 
        region_name: &WorldRegion, 
        postal_code: &PostalCode, 
        street:      &StreetName
    ) -> bool;
}

impl<I:StorageInterface> StreetExistsInPostalCodeInRegion for DataAccess<I> {

    fn street_exists_in_postal_code(&self, region: &WorldRegion, postal_code: &PostalCode, street: &StreetName) -> bool {
        if let Some(sts) = self.street_names_for_postal_code_in_region(region, postal_code) {
            sts.contains(street)
        } else {
            false
        }
    }
}

// ---------------- [ File: src/infer_country_from_region.rs ]
// ---------------- [ File: src/infer_country_from_region.rs ]
crate::ix!();

/// Converts a [`WorldRegion`] into a [`Country`], logging the attempt and result.
/// Returns an error if the region is unknown to our system.
pub fn infer_country_from_region(
    region: &WorldRegion
) -> Result<Country, OsmPbfParseError> {
    trace!("infer_country_from_region: region={:?}", region);
    let country = Country::try_from(*region)?;
    debug!("infer_country_from_region: resolved to {:?}", country);
    Ok(country)
}

crate::ix!();

#[derive(Debug, Builder)]
#[builder(setter(into))]
pub struct StdoutBackup {
    stdout_fd: i32,
    backup_fd: i32,
}

impl StdoutBackup {
    pub fn new() -> io::Result<Self> {
        let stdout_fd = io::stdout().as_raw_fd();
        eprintln!(
            "[StdoutBackup::new] duplicating current stdout_fd={} with libc::dup()",
            stdout_fd
        );
        let backup_fd = unsafe { libc::dup(stdout_fd) };
        if backup_fd == -1 {
            let err = io::Error::last_os_error();
            eprintln!("[StdoutBackup::new] ERROR: dup() failed: {:?}", err);
            Err(err)
        } else {
            eprintln!(
                "[StdoutBackup::new] success: new backup_fd={} to represent the old stdout",
                backup_fd
            );
            Ok(Self { stdout_fd, backup_fd })
        }
    }

    pub fn restore(&self) -> io::Result<()> {
        eprintln!(
            "[StdoutBackup::restore] about to call libc::dup2(backup_fd={}, stdout_fd={})",
            self.backup_fd, self.stdout_fd
        );
        let rc = unsafe { libc::dup2(self.backup_fd, self.stdout_fd) };
        if rc == -1 {
            let err = io::Error::last_os_error();
            eprintln!(
                "[StdoutBackup::restore] ERROR: dup2({}, {}) failed: {:?}",
                self.backup_fd, self.stdout_fd, err
            );
            Err(err)
        } else {
            eprintln!(
                "[StdoutBackup::restore] success: stdout now restored to fd={}",
                self.backup_fd
            );
            Ok(())
        }
    }
}

impl Drop for StdoutBackup {
    fn drop(&mut self) {
        eprintln!(
            "[StdoutBackup::drop] about to dup2(backup_fd={}, stdout_fd={}) (ignoring errors)",
            self.backup_fd, self.stdout_fd
        );
        let rc_dup2 = unsafe { libc::dup2(self.backup_fd, self.stdout_fd) };
        if rc_dup2 == -1 {
            let err = io::Error::last_os_error();
            eprintln!("[StdoutBackup::drop] WARNING: dup2 failed: {:?}", err);
        } else {
            eprintln!(
                "[StdoutBackup::drop] dup2 succeeded; restored stdout to backup_fd={}",
                self.backup_fd
            );
        }

        eprintln!(
            "[StdoutBackup::drop] now closing backup_fd={} (ignoring errors)",
            self.backup_fd
        );
        let rc_close = unsafe { libc::close(self.backup_fd) };
        if rc_close == -1 {
            let err = io::Error::last_os_error();
            eprintln!(
                "[StdoutBackup::drop] WARNING: close(backup_fd={}) failed: {:?}",
                self.backup_fd, err
            );
        } else {
            eprintln!(
                "[StdoutBackup::drop] closed backup_fd={} successfully",
                self.backup_fd
            );
        }
    }
}
// ---------------- [ File: src/parse_housenumber_value.rs ]
crate::ix!();

/// Parses a non-empty housenumber string as either a single number or a range.
///
/// # Returns
///
/// * `Ok(Some(HouseNumberRange))` on success.
/// * `Ok(None)` if the start-end was reversed or invalid in an ignorable way.
/// * `Err(IncompatibleOsmPbfElement)` if a parse error occurs.
pub fn parse_housenumber_value(
    hn_value: &str,
    element_id: i64,
) -> Result<Option<HouseNumberRange>, IncompatibleOsmPbfElement> {

    let hn_value = hn_value.trim();

    // Grab the leading digit sequence only (stop at first non-digit).
    let numeric_prefix: String = hn_value
        .chars()
        .take_while(|ch| ch.is_ascii_digit())
        .collect();

    // If no digits at all, skip it
    if numeric_prefix.is_empty() {
        debug!(
            "parse_house_number_value: skipping '{}'; element_id={} => no leading digits",
            hn_value, element_id
        );
        return Ok(None);
    }

    let hn_value = numeric_prefix;

    trace!(
        "parse_housenumber_value: attempting to parse='{}' (element_id={})",
        hn_value,
        element_id
    );

    if let Some(idx) = hn_value.find('-') {
        let (start_str, rest) = hn_value.split_at(idx);
        // skip the dash
        let end_str = &rest[1..];

        let start_num = parse_integer(start_str.trim(), element_id)?;
        let end_num = parse_integer(end_str.trim(), element_id)?;

        if start_num > end_num {
            debug!(
                "parse_housenumber_value: reversed or invalid range '{}-{}' => ignoring (element_id={})",
                start_num, end_num, element_id
            );
            return Ok(None);
        }

        let range = HouseNumberRange::new(start_num, end_num);
        debug!(
            "parse_housenumber_value: parsed valid range '{}' => {:?} (element_id={})",
            hn_value, range, element_id
        );
        Ok(Some(range))
    } else {
        // single integer
        let single_num = parse_integer(&hn_value, element_id)?;
        let range = HouseNumberRange::new(single_num, single_num);
        debug!(
            "parse_housenumber_value: parsed single '{}' => {:?} (element_id={})",
            hn_value, range, element_id
        );
        Ok(Some(range))
    }
}

// ---------------- [ File: src/imports.rs ]
pub(crate) use usa::*;
pub(crate) use europe::*;
pub(crate) use osmpbf::{BlobDecode,PrimitiveBlock,TagIter,ElementReader,Element};
pub(crate) use export_magic::*;
pub(crate) use error_tree::*;
pub(crate) use md5::*;
pub(crate) use std::path::{Path,PathBuf};
pub(crate) use std::fmt::{self,Debug,Display};
pub(crate) use tokio::{io::{self,AsyncWriteExt,AsyncReadExt},fs::File};
pub(crate) use std::collections::{HashSet,HashMap,BTreeSet,BTreeMap};
pub(crate) use rocksdb::{DBIteratorWithThreadMode,DBCompressionType,DB,Options,SliceTransform};
pub(crate) use serde::{Serialize,Deserialize};
pub(crate) use getset::{MutGetters,Getters,Setters};
pub(crate) use futures_util::TryStreamExt; // for try_next()
pub(crate) use bytes::Bytes;
pub(crate) use postal_code::*;
pub(crate) use country::*;
pub(crate) use tracing::{error,trace,info,warn,debug};
pub(crate) use derive_builder::Builder;
pub(crate) use serde::de::DeserializeOwned;
pub(crate) use std::sync::{OnceLock,Mutex,Arc};
pub(crate) use traced_test::*;
pub(crate) use tracing_setup::*;
pub(crate) use tempfile::TempDir;
pub(crate) use structopt::*;
pub(crate) use file_downloader::*;
pub(crate) use file_downloader_derive::*;
pub(crate) use world_region::*;
pub(crate) use abbreviation_trait::{Abbreviation,TryFromAbbreviation};
pub(crate) use std::sync::atomic::AtomicBool;
pub(crate) use std::sync::atomic::Ordering;
pub(crate) use serial_test::serial;
pub(crate) use std::error::Error;
pub(crate) use std::io::{ErrorKind,Write,Read};
pub(crate) use std::os::fd::{FromRawFd,AsRawFd};
pub(crate) use tokio::runtime::Runtime;
pub(crate) use std::thread;
pub(crate) use std::sync::mpsc::{self,SyncSender};
pub(crate) use std::iter;
pub(crate) use fuzzy_matcher::skim::SkimMatcherV2;
pub(crate) use fuzzy_matcher::FuzzyMatcher;
pub(crate) use rustyline::{
    Editor, Context, Result as RlResult, 
    error::ReadlineError,
    completion::{Completer, Candidate, Pair}, 
    highlight::Highlighter,
    hint::{Hinter},
    validate::Validator,
    Helper,
    history::DefaultHistory,
};
pub(crate) use strum::IntoEnumIterator;
pub(crate) use disable_macro::disable;
pub(crate) use byteorder::{ByteOrder,BigEndian, WriteBytesExt}; // for writing the 4-byte length prefix
pub(crate) use protobuf::{Message,MessageField};
// ---------------- [ File: src/house_number_in_any_range.rs ]
// ---------------- [ File: src/house_number_in_any_range.rs ]
crate::ix!();

pub trait HouseNumberInAnyRange {

    fn house_number_in_any_range(
        &self,
        region:      &WorldRegion,
        street:      &StreetName,
        house_num:   u32,
    ) -> Result<bool, DataAccessError>;
}

impl HouseNumberInAnyRange for Database {

    /// Utility function to check if a given house number is contained
    /// in any of the sub-ranges for a region+street.
    fn house_number_in_any_range(
        &self,
        region:      &WorldRegion,
        street:      &StreetName,
        house_num:   u32,
    ) -> Result<bool, DataAccessError> {

        if let Some(ranges) = self.load_house_number_ranges(region, street)? {
            for rng in ranges {
                if rng.contains(house_num) {
                    return Ok(true);
                }
            }
            Ok(false)
        } else {
            // No entry found, so presumably no coverage
            Ok(false)
        }
    }
}

// ---------------- [ File: src/street_names_for_postal_code_in_region.rs ]
crate::ix!();

pub trait StreetNamesForPostalCodeInRegion {

    fn street_names_for_postal_code_in_region(
        &self, 
        region_name: &WorldRegion, 
        postal_code: &PostalCode
    ) -> Option<BTreeSet<StreetName>>;
}


impl<I:StorageInterface> StreetNamesForPostalCodeInRegion for DataAccess<I> {

    fn street_names_for_postal_code_in_region(
        &self, 
        region: &WorldRegion, 
        postal_code:    &PostalCode

    ) -> Option<BTreeSet<StreetName>> {

        let key = s_key(region,postal_code);
        self.get_street_set(&key)
    }
}

// ---------------- [ File: src/gather_pbf_files.rs ]
// ---------------- [ File: src/gather_pbf_files.rs ]
crate::ix!();

/// Reads the specified directory, returning a `Vec<PathBuf>` of all `.pbf` files found.
///
/// # Returns
///
/// * `Ok(Vec<PathBuf>)` if the directory is accessible.
/// * `Err(OsmPbfParseError)` if reading the directory fails.
pub fn gather_pbf_files(pbf_dir: &Path) -> Result<Vec<PathBuf>, OsmPbfParseError> {
    trace!("gather_pbf_files: scanning directory {:?}", pbf_dir);
    let entries = std::fs::read_dir(pbf_dir)
        .map_err(|io_err| OsmPbfParseError::IoError(io_err))?;

    let mut pbf_files = Vec::new();
    for entry_result in entries {
        let entry = match entry_result {
            Ok(e) => e,
            Err(e) => {
                error!("gather_pbf_files: error reading entry in {:?}: {}", pbf_dir, e);
                return Err(OsmPbfParseError::IoError(e));
            }
        };
        let path = entry.path();
        if path.extension().and_then(|ext| ext.to_str()) == Some("pbf") {
            debug!("gather_pbf_files: found PBF file {:?}", path);
            pbf_files.push(path);
        }
    }

    Ok(pbf_files)
}

// ---------------- [ File: src/try_resolve_country.rs ]
// ---------------- [ File: src/try_resolve_country.rs ]
crate::ix!();

/// Tries to convert the provided [`WorldRegion`] into a [`Country`].
/// Returns an [`OsmPbfParseError`] if the conversion is invalid.
///
/// This is a thin wrapper over `Country::try_from(...)` with extra tracing.
pub fn try_resolve_country(
    region: WorldRegion
) -> Result<Country, OsmPbfParseError> {
    trace!("try_resolve_country: Attempting to convert region={:?}", region);
    let country = Country::try_from(region)?;
    debug!("try_resolve_country: Successfully resolved to {:?}", country);
    Ok(country)
}

// ---------------- [ File: src/obtain_pbf_file_for_region.rs ]
crate::ix!();

pub async fn obtain_pbf_file_for_region(
    region:           &WorldRegion,
    target_dir:       impl AsRef<Path> + Send + Sync,
) -> Result<PathBuf, WorldCityAndStreetDbBuilderError> {
    Ok(region.find_file_locally_or_download_into(&target_dir).await?)
}

// ---------------- [ File: src/validate_street_for_postal_code.rs ]
crate::ix!();

/// Validates that the `[StreetName]` is present in the set of streets
/// associated with the `[PostalCode]` (i.e., `s_key(region, postal_code)`).
pub fn validate_street_for_postal_code<V:GetStreetSetForKey>(
    addr:      &WorldAddress,
    validator: &V,
) -> Result<(), InvalidWorldAddress> {
    let s_k = s_key(addr.region(), addr.postal_code());
    trace!("validate_street_for_postal_code: using key='{}'", s_k);

    match validator.get_street_set(&s_k) {
        Some(streets) => {
            if !streets.contains(addr.street()) {
                warn!(
                    "validate_street_for_postal_code: street='{:?}' not found for postal_code='{:?}' in region={:?}",
                    addr.street(),
                    addr.postal_code(),
                    addr.region()
                );
                return Err(InvalidWorldAddress::StreetNotFoundForPostalCodeInRegion {
                    street: addr.street().clone(),
                    postal_code: addr.postal_code().clone(),
                    region: *addr.region(),
                });
            }
        }
        None => {
            warn!(
                "validate_street_for_postal_code: no street set found for key='{}'",
                s_k
            );
            return Err(InvalidWorldAddress::PostalCodeToStreetKeyNotFoundForRegion {
                s_key: s_k,
                region: *addr.region(),
                postal_code: addr.postal_code().clone(),
            });
        }
    }
    Ok(())
}

// ---------------- [ File: src/open_database_at_path.rs ]
crate::ix!();

pub trait OpenDatabaseAtPath {
    fn open(path: impl AsRef<std::path::Path>) 
        -> Result<Arc<Mutex<Self>>, WorldCityAndStreetDbBuilderError>;
}

impl OpenDatabaseAtPath for Database {

    fn open(path: impl AsRef<std::path::Path>)
        -> Result<Arc<Mutex<Self>>, WorldCityAndStreetDbBuilderError>
    {
        let mut opts = Options::default();
        opts.create_if_missing(true);
        opts.set_compression_type(DBCompressionType::Zstd);

        // 1) Use the “colon prefix” transform so that RocksDB
        //    stores an extracted prefix up to the second colon.
        let st = create_colon_prefix_transform();
        opts.set_prefix_extractor(st);

        // Optionally enable prefix bloom filters
        opts.set_memtable_prefix_bloom_ratio(0.1);

        let db = DB::open(&opts, path).map_err(|e| DataAccessError::RocksDB(e))?;

        let db = DatabaseBuilder::default()
            .db(Arc::new(db))
            .build()
            .unwrap();

        Ok(Arc::new(Mutex::new(db)))
    }
}

// ---------------- [ File: src/house_number_ranges.rs ]
// [ File: src/house_number_ranges.rs ]
crate::ix!();

/// Represents a range of house numbers, e.g. from `start` up to `end` inclusive.
/// For instance, (1..=100), or (140..=260). 
///
/// In production you might also store:
///   - a "step" for even/odd-only sequences,
///   - explicit "skipped" sets,
///   - or subdivide partial ranges. 
/// This example keeps it simple: if you skip 101..139, 
/// just store multiple disjoint ranges. 
#[derive(Getters,Setters,Clone,Serialize,Deserialize,PartialEq,Eq)]
#[getset(get="pub",set="pub")]
pub struct HouseNumberRange {
    /// first house number in the sub-range (inclusive)
    start: u32,
    /// last house number in the sub-range (inclusive)
    end:   u32,
}

impl fmt::Debug for HouseNumberRange {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        write!(f, "[{}..={}]", self.start(), self.end())
    }
}


impl HouseNumberRange {

    pub fn new(start: u32, end: u32) -> Self {
        Self {
            start,
            end,
        }
    }

    /// Checks whether a given `house_num` is contained in this sub-range.
    pub fn contains(&self, house_num: u32) -> bool {
        house_num >= self.start && house_num <= self.end
    }
}

// ---------------- [ File: src/list_all_addresses_in_pbf_dir.rs ]
crate::ix!();

pub type WorldAddressIterator = impl Iterator<Item=Result<WorldAddress,OsmPbfParseError>>;

/// Produces an iterator of [`WorldAddress`] items by scanning a directory for
/// `.pbf` files and attempting to parse each one. Files are associated with
/// known regions and then processed in sequence.
///
/// # Arguments
///
/// * `pbf_dir` - A filesystem path to a directory containing `.pbf` files.
/// * `db`      - Shared database reference for storing or retrieving house number data.
///
/// # Returns
///
/// * `Ok(impl Iterator<Item = Result<WorldAddress, OsmPbfParseError>>)` on success.
/// * `Err(OsmPbfParseError)` if reading the directory or chaining file iterators fails.
pub fn list_all_addresses_in_pbf_dir<I:StorageInterface + 'static>(
    pbf_dir: impl AsRef<Path>,
    db: Arc<Mutex<I>>,
) -> Result<WorldAddressIterator, OsmPbfParseError> {
    trace!("list_all_addresses_in_pbf_dir: start for pbf_dir={:?}", pbf_dir.as_ref());

    // 1) Collect all `.pbf` files from the directory.
    let pbf_files = gather_pbf_files(pbf_dir.as_ref())?;
    debug!("list_all_addresses_in_pbf_dir: found {} PBF files", pbf_files.len());

    // 2) Identify known regions.
    let known_regions = dmv_regions();
    info!("list_all_addresses_in_pbf_dir: known regions: {:#?}", known_regions);

    // 3) Build a chained iterator of addresses from all recognized PBF files.
    let chained = chain_addresses_across_files(pbf_files, &known_regions, db, pbf_dir.as_ref())?;
    Ok(chained)
}

// ---------------- [ File: src/seriallize_osm_header_block.rs ]
crate::ix!();

use crate::proto::{fileformat,osmformat};

/// Serializes the given `HeaderBlock` into a `Blob` and `BlobHeader`.
pub fn serialize_osm_header_block(
    header_block: osmformat::HeaderBlock
) -> std::io::Result<(Vec<u8>, Vec<u8>)> {
    trace!("serialize_osm_header_block: serializing HeaderBlock");

    let header_block_bytes = header_block.write_to_bytes().map_err(|e| {
        error!("serialize_osm_header_block: protobuf error: {:?}", e);
        std::io::Error::new(std::io::ErrorKind::Other, "HeaderBlock serialization failed")
    })?;

    let mut blob = fileformat::Blob::new();
    blob.set_raw(header_block_bytes.clone());
    blob.set_raw_size(header_block_bytes.len() as i32);

    let blob_bytes = blob.write_to_bytes().map_err(|e| {
        error!("serialize_osm_header_block: blob error: {:?}", e);
        std::io::Error::new(std::io::ErrorKind::Other, "Blob serialization failed")
    })?;

    let mut blob_header = fileformat::BlobHeader::new();
    blob_header.set_type("OSMHeader".to_string());
    blob_header.set_datasize(blob_bytes.len() as i32);

    let blob_header_bytes = blob_header.write_to_bytes().map_err(|e| {
        error!("serialize_osm_header_block: blob header error: {:?}", e);
        std::io::Error::new(std::io::ErrorKind::Other, "BlobHeader serialization failed")
    })?;

    debug!("serialize_osm_header_block: Blob and BlobHeader ready");
    Ok((blob_header_bytes, blob_bytes))
}

// ---------------- [ File: src/regions.rs ]
crate::ix!();

/// Returns the regions of interest (DMV region in this example)
pub fn dmv_regions() -> Vec<WorldRegion> {
    vec![
        USRegion::UnitedState(UnitedState::Maryland).into(),
        USRegion::UnitedState(UnitedState::Virginia).into(),
        USRegion::USFederalDistrict(USFederalDistrict::DistrictOfColumbia).into(),
    ]
}

pub fn world_regions() -> Vec<WorldRegion> {
    WorldRegion::iter().collect()
}
// ---------------- [ File: src/create_tiny_osm_pbf.rs ]
/// Creates a very small .osm.pbf file with:
///   - A single OSMHeader blob
///   - A single OSMData blob that contains one node with two address tags
///
/// The resulting file should be enough for a test fixture in your integration tests.
///
/// Note: This uses the `osmpbf::proto::{fileformat,osmformat}` modules,
///       which `osmpbf` normally uses internally for reading. They’re not officially
///       documented for writing, but you can still access them in your own code.
/// ---------------- [ File: src/create_tiny_osm_pbf.rs ]
crate::ix!();

// Pull in the generated protobuf structs from the `osmpbf` crate
//
// TODO: pull request created on the upstream to expose these:
//
// ```rust
//use osmpbf::protos::fileformat;
//use osmpbf::protos::osmformat;
//```
use crate::proto::{fileformat, osmformat}; // our newly generated modules

/// Thin wrapper around [`create_small_osm_pbf_file`] producing a single Node
/// without an `addr:housenumber`.
///
/// # Bounding box: near Baltimore
/// # City: `"test city fixture"`, Street: `"test street fixture"`, lat/lon near 39.283/-76.616
pub async fn create_tiny_osm_pbf(path: impl AsRef<Path>) -> std::io::Result<()> {
    trace!("create_tiny_osm_pbf: starting for path={:?}", path.as_ref());

    create_small_osm_pbf_file(
        path.as_ref(),
        (-77_000_000_000, -76_000_000_000, 39_000_000_000, 38_000_000_000),
        "test city fixture",
        "test street fixture",
        "11111", //postcode
        None,
        39.283,
        -76.616,
        1001,
    ).await
}

// ---------------- [ File: src/store_merged_house_number_ranges.rs ]
crate::ix!();

/// Stores the merged list of house‐number ranges back into the database.
pub fn store_merged_house_number_ranges<I:StoreHouseNumberRanges>(
    db:     &mut I,
    region: &WorldRegion,
    street: &StreetName,
    merged: &[HouseNumberRange],
) -> Result<(), DatabaseConstructionError> {
    trace!(
        "store_merged_house_number_ranges: storing {} ranges for street='{}' in region={:?}",
        merged.len(),
        street,
        region
    );

    db.store_house_number_ranges(region, street, merged)?;
    debug!(
        "store_merged_house_number_ranges: successfully stored ranges for street='{}'",
        street
    );
    Ok(())
}

// ---------------- [ File: src/write_osm_pbf_file.rs ]
crate::ix!();

/// Asynchronously writes two sets of BlobHeader/Blob pairs
/// (header vs. data) to the target file in `.osm.pbf` order.
pub async fn write_osm_pbf_file(
    path: &Path,
    header_blobheader_bytes: &[u8],
    header_blob_bytes: &[u8],
    data_blobheader_bytes: &[u8],
    data_blob_bytes: &[u8]
) -> std::io::Result<()> {
    trace!("write_osm_pbf_file: creating file at {:?}", path);

    let mut file = match tokio::fs::File::create(path).await {
        Ok(f) => {
            debug!("write_osm_pbf_file: file opened at {:?}", path);
            f
        }
        Err(e) => {
            error!("write_osm_pbf_file: failed to create file {:?}: {:?}", path, e);
            return Err(e);
        }
    };

    // Write the OSMHeader portion
    trace!(
        "write_osm_pbf_file: writing header_blobheader={} bytes + header_blob={} bytes",
        header_blobheader_bytes.len(),
        header_blob_bytes.len()
    );
    crate::write_u32_be(&mut file, header_blobheader_bytes.len() as u32).await?;
    file.write_all(header_blobheader_bytes).await?;
    file.write_all(header_blob_bytes).await?;

    // Write the OSMData portion
    trace!(
        "write_osm_pbf_file: writing data_blobheader={} bytes + data_blob={} bytes",
        data_blobheader_bytes.len(),
        data_blob_bytes.len()
    );
    crate::write_u32_be(&mut file, data_blobheader_bytes.len() as u32).await?;
    file.write_all(data_blobheader_bytes).await?;
    file.write_all(data_blob_bytes).await?;

    debug!("write_osm_pbf_file: completed writing to {:?}", path);
    Ok(())
}

// ---------------- [ File: src/try_build_address_record_from_tags.rs ]
crate::ix!();

/// Attempts to construct an [`AddressRecord`] from a stream of OSM-style tags.
/// Returns an error if no address-related tags are found or if any field fails
/// to parse.
///
/// # Arguments
///
/// * `tags_iter`  - Iterator of key-value pairs representing OSM tags.
/// * `country`    - The country associated with the address record.
/// * `element_id` - Unique identifier (e.g., node id).
///
/// # Returns
///
/// * `Ok(AddressRecord)` if a valid record can be built.
/// * `Err(IncompatibleOsmPbfElement)` otherwise.
pub fn try_build_address_record_from_tags<'a>(
    tags_iter:  impl Iterator<Item = (&'a str, &'a str)>,
    country:    Country,
    element_id: i64,
) -> Result<AddressRecord, IncompatibleOsmPbfElement> {
    trace!("try_build_address_record_from_tags: Start for element_id={}", element_id);

    let tags = collect_tags(tags_iter);
    debug!(
        "try_build_address_record_from_tags: Collected {} tags for element_id={}",
        tags.len(),
        element_id
    );

    // 1. Extract city/street/postcode tags or return an error if all missing.
    let (city_raw, street_raw, postcode_raw) = try_extract_address_tags(&tags, element_id)?;

    // 2. Parse each tag into its strongly-typed representation.
    let city     = try_construct_city_name(city_raw, element_id)?;
    let street   = try_construct_street_name(street_raw, element_id)?;
    let postcode = try_construct_postal_code(country, postcode_raw, element_id)?;

    // 3. Assemble the final [`AddressRecord`].
    let record = try_assemble_address_record(city, street, postcode, element_id)?;

    trace!("try_build_address_record_from_tags: Successfully built AddressRecord for element_id={}", element_id);
    Ok(record)
}

// ---------------- [ File: src/filenames.rs ]
// ---------------- [ File: src/filenames.rs ]
crate::ix!();

crate::ix!();

use crate::proto::{osmformat, fileformat};

use std::io::Cursor;

// Disambiguate the byteorder trait methods so we don't conflict with tokio's `AsyncWriteExt`.
use byteorder::{BigEndian, WriteBytesExt as ByteOrderWriteExt};

use osmpbf::{
    BlobReader,
    BlobType,
    Element,
    PrimitiveBlock,
};

/// A helper struct for creating a single mocked Node in an `.osm.pbf`-like byte array.
/// That array is then parsed by `osmpbf::BlobReader`, producing a `PrimitiveBlock` you can
/// retrieve as `MockNode.block`.
///
/// The fix here: We ensure the `PrimitiveBlock` is fully initialized 
/// (granularity, lat_offset, lon_offset) and each Node has lat/lon fields set (even if 0).
///
/// If your code requires *real* lat/lon, change those from 0 to something valid.
#[derive(Debug)]
pub struct MockNode {
    block: PrimitiveBlock,
}

impl MockNode {
    /// Creates a single mocked Node with the given `id` and `(key,val)` tags.
    ///
    /// We fix the `MessageNotInitialized("PrimitiveBlock")` by:
    ///  - Setting `block.set_granularity(...)`
    ///  - Setting `block.set_lat_offset(...)`
    ///  - Setting `block.set_lon_offset(...)`
    ///  - Setting `node.lat` / `node.lon`
    ///  - Using minimal but valid string table references
    ///
    pub fn new(id: i64, tags: &[(&str, &str)]) -> Self {
        // 1) Build a minimal `.osm.pbf` in memory
        let data = build_mock_node_pbf_bytes(id, tags);

        // 2) Parse the array via osmpbf::BlobReader
        let mut reader = BlobReader::new(Cursor::new(data));
        while let Some(blob_res) = reader.next() {
            let blob = blob_res.expect("Error reading mock data blob");
            if let BlobType::OsmData = blob.get_type() {
                let block = blob
                    .to_primitiveblock()
                    .expect("Cannot decode mock data to PrimitiveBlock");
                return Self { block };
            }
        }
        panic!("No OSMData blob found in the mock data!");
    }

    /// Returns this single mocked node as `osmpbf::Element::Node(...)`.
    /// Valid while `MockNode` is in scope, since the `PrimitiveBlock` is owned here.
    pub fn as_element(&self) -> Element<'_> {
        self.block
            .elements()
            .next()
            .expect("PrimitiveBlock is empty? Should have 1 node.")
    }
}

/// Builds a minimal `.osm.pbf` byte array for a single Node with the given `id` and tags.
/// That byte array includes exactly one BlobHeader + Blob with type "OSMData".
fn build_mock_node_pbf_bytes(id: i64, tags: &[(&str, &str)]) -> Vec<u8> {
    // 1) Prepare a string table with all unique keys/values in `tags`.
    //    We'll store them in order: [ "", key1, val1, key2, val2, ... ]
    //    Then node.keys / node.vals are indices into that.
    let mut stringtable = osmformat::StringTable::new();
    let mut st_index_map = Vec::new(); // (k,v) => (k_idx, v_idx)

    // index 0 is always the empty string:
    stringtable.s.push(b"".to_vec());

    for &(k, v) in tags {
        let k_idx = stringtable.s.len() as u32;
        stringtable.s.push(k.as_bytes().to_vec());
        let v_idx = stringtable.s.len() as u32;
        stringtable.s.push(v.as_bytes().to_vec());
        st_index_map.push((k_idx, v_idx));
    }

    // 2) Create a Node
    let mut node = osmformat::Node::new();
    node.set_id(id);
    // lat/lon must be set for the node to be considered "initialized".
    // We'll do 0 for both. If you need real coords, convert them as needed.
    node.set_lat(0); 
    node.set_lon(0);

    // Fill out node.keys/vals from st_index_map
    for (k_i, v_i) in &st_index_map {
        node.keys.push(*k_i);
        node.vals.push(*v_i);
    }

    // 3) Put that Node in a PrimitiveGroup
    let mut group = osmformat::PrimitiveGroup::new();
    group.nodes.push(node);

    // 4) Build the PrimitiveBlock:
    let mut prim_block = osmformat::PrimitiveBlock::new();
    // The fix: set granularity & offsets so the block is "initialized".
    prim_block.set_granularity(100);
    prim_block.set_lat_offset(0);
    prim_block.set_lon_offset(0);
    prim_block.stringtable = protobuf::MessageField::some(stringtable);
    prim_block.primitivegroup.push(group);

    // 5) Serialize this block into a `fileformat::Blob`
    let block_bytes = prim_block
        .write_to_bytes()
        .expect("Could not serialize local PrimitiveBlock");

    let mut blob = fileformat::Blob::new();
    blob.set_raw(block_bytes);
    blob.set_raw_size(blob.raw().len() as i32);

    let blob_bytes = blob
        .write_to_bytes()
        .expect("Could not serialize local Blob");

    // 6) Build a BlobHeader with type = "OSMData"
    let mut header = fileformat::BlobHeader::new();
    header.set_type("OSMData".to_string());
    header.set_datasize(blob_bytes.len() as i32);

    let header_bytes = header
        .write_to_bytes()
        .expect("Could not serialize BlobHeader");

    // 7) Frame as <4-byte header-len><header><blob>
    use byteorder::{BigEndian, WriteBytesExt};
    let mut out = Vec::new();
    byteorder::WriteBytesExt::write_u32::<BigEndian>(&mut out, header_bytes.len() as u32);
    out.extend_from_slice(&header_bytes);
    out.extend_from_slice(&blob_bytes);

    out
}

// ---------------- [ File: src/gather_city_key_value_pairs.rs ]
crate::ix!();

/// Performs a prefix-based iteration in RocksDB to find all city keys matching the prefix.
/// Returns a vector of `(key_string, value_bytes)` tuples for further processing.
pub fn gather_city_key_value_pairs<I:StorageInterface>(db: &I, prefix: &str) 
-> Vec<(String, Vec<u8>)> 
{
    trace!(
        "gather_city_key_value_pairs: prefix='{}' => running prefix_iterator",
        prefix
    );

    let iter = db.prefix_iterator(prefix.as_bytes());
    let mut results = Vec::new();

    for item_result in iter {
        match item_result {
            Ok((key_bytes, val_bytes)) => {
                let key_str = String::from_utf8_lossy(&key_bytes).to_string();
                debug!(
                    "gather_city_key_value_pairs: found key='{}' (value: {} bytes)",
                    key_str,
                    val_bytes.len()
                );
                results.push((key_str, val_bytes.to_vec()));
            }
            Err(e) => {
                error!(
                    "gather_city_key_value_pairs: error reading from DB for prefix='{}': {}",
                    prefix, e
                );
            }
        }
    }

    results
}

// ---------------- [ File: src/try_assemble_address_record.rs ]
crate::ix!();

pub fn try_assemble_address_record(
    city: Option<CityName>,
    street: Option<StreetName>,
    postcode: Option<PostalCode>,
    element_id: i64,
) -> Result<AddressRecord, IncompatibleOsmPbfElement> {
    trace!(
        "try_assemble_address_record: Building AddressRecord for element_id={}",
        element_id
    );

    // (A) If city is None => treat it as a missing required field => produce a BuilderError.
    if city.is_none() {
        debug!(
            "try_assemble_address_record: city missing => failing for element_id={}",
            element_id
        );
        return Err(IncompatibleOsmPbfElement::IncompatibleOsmPbfNode(
            IncompatibleOsmPbfNode::AddressRecordBuilderError {
                id: element_id,
                source: AddressRecordBuilderError::UninitializedField(
                    "city was required but not provided".into()
                ),
            },
        ));
    }

    // (B) If street is None => same approach: missing required field => error.
    if street.is_none() {
        debug!(
            "try_assemble_address_record: street missing => failing for element_id={}",
            element_id
        );
        return Err(IncompatibleOsmPbfElement::IncompatibleOsmPbfNode(
            IncompatibleOsmPbfNode::AddressRecordBuilderError {
                id: element_id,
                source: AddressRecordBuilderError::UninitializedField(
                    "street was required but not provided".into()
                ),
            },
        ));
    }

    // (C) (Optional) If you also want *postcode* to be strictly required,
    // then do the same check for `postcode.is_none()` => produce error.
    // If you do *not* require it, you can skip this step.

    // (D) Contrived check: if city == "impostorcity", forcibly produce an error
    // (for that special test scenario).
    if let Some(ref c) = city {
        if c.name() == "impostorcity" {
            error!(
                "try_assemble_address_record: city='impostorcity' => forcing builder failure test"
            );
            return Err(IncompatibleOsmPbfElement::IncompatibleOsmPbfNode(
                IncompatibleOsmPbfNode::CityCannotBeImpostorCity,
            ));
        }
    }

    // (E) Now attempt the actual build. If your `AddressRecordBuilder`
    // *also* enforces city & street as required, this is somewhat redundant.
    // But it’s good to unify everything in one code path.
    let record = AddressRecordBuilder::default()
        .city(city)
        .street(street)
        .postcode(postcode) // or skip if optional
        .build()
        .map_err(|builder_error| {
            // If the builder fails for any reason, wrap it in your domain error:
            IncompatibleOsmPbfElement::IncompatibleOsmPbfNode(
                IncompatibleOsmPbfNode::AddressRecordBuilderError {
                    id: element_id,
                    source: builder_error,
                },
            )
        })?;

    Ok(record)
}

// ---------------- [ File: src/handle_pbf_house_number_extractor_in_thread.rs ]
crate::ix!();

/// Handles the actual I/O, parsing, aggregation, and DB storage in a worker thread.
/// Any errors in opening or parsing the file, or mid-way processing, are sent over
/// `tx` as an `Err(...)`. Aggregation results are eventually stored in the DB.
///
/// # Arguments
///
/// * `path`         - Path to the OSM PBF file.
/// * `country`      - The resolved country object.
/// * `world_region` - The original region indicator.
/// * `db`           - Database reference, protected by a mutex.
/// * `tx`           - A `SyncSender` for streaming [`WorldAddress`] results or errors.
pub fn handle_pbf_house_number_extractor_in_thread<I:LoadExistingStreetRanges + StoreHouseNumberRanges>(
    db:           Arc<Mutex<I>>,
    path:         PathBuf,
    country:      Country,
    world_region: WorldRegion,
    tx:           std::sync::mpsc::SyncSender<Result<WorldAddress, OsmPbfParseError>>,
) {
    trace!("handle_pbf_house_number_extractor_in_thread: Spawned for path={:?}", path);

    match open_pbf_reader_or_report_error(&path, &tx) {
        Some(reader) => {
            let mut aggregator = HouseNumberAggregator::new(&world_region);
            debug!(
                "handle_pbf_house_number_extractor_in_thread: Aggregator initialized (empty) for path={:?}",
                path
            );

            if let Err(parse_err) = aggregator.try_parse_and_aggregate_house_numbers(reader, &tx) {
                error!(
                    "handle_pbf_house_number_extractor_in_thread: Error parsing PBF or aggregating results for path={:?}: {:?}",
                    path, parse_err
                );
                let _ = tx.send(Err(parse_err));
            }

            aggregator.attempt_storing_in_db(db);
        }
        None => {
            trace!("handle_pbf_house_number_extractor_in_thread: Early return after open error for path={:?}", path);
            // We have already sent the error via tx and returned
        }
    }
}

crate::ix!();

/// A small helper to confirm whether the returned `AddressRecord` matches
/// our expected city/street/postcode, if any.
pub fn assert_address_record_matches(
    actual: &AddressRecord,
    expected_city: Option<&str>,
    expected_street: Option<&str>,
    expected_postcode: Option<&str>,
) {
    match (expected_city, actual.city()) {
        (Some(exp_city), Some(actual_city)) => {
            assert_eq!(*actual_city.name(), exp_city.to_lowercase());
        }
        (None, None) => {}
        (Some(_), None) | (None, Some(_)) => {
            panic!(
                "Mismatch in city presence. Expected: {:?}, got: {:?}",
                expected_city, actual.city()
            );
        }
    }

    match (expected_street, actual.street()) {
        (Some(exp_street), Some(actual_street)) => {
            assert_eq!(*actual_street.name(), exp_street.to_lowercase());
        }
        (None, None) => {}
        (Some(_), None) | (None, Some(_)) => {
            panic!(
                "Mismatch in street presence. Expected: {:?}, got: {:?}",
                expected_street, actual.street()
            );
        }
    }

    match (expected_postcode, actual.postcode()) {
        (Some(exp_postcode), Some(actual_code)) => {
            assert_eq!(actual_code.code(), exp_postcode);
        }
        (None, None) => {}
        (Some(_), None) | (None, Some(_)) => {
            panic!(
                "Mismatch in postcode presence. Expected: {:?}, got: {:?}",
                expected_postcode, actual.postcode()
            );
        }
    }
}
// ---------------- [ File: src/region_done_traits.rs ]
crate::ix!();

pub trait CheckIfRegionDone {
    fn region_done(&self, region: &WorldRegion) 
        -> Result<bool,DataAccessError>;
}

impl CheckIfRegionDone for Database {

    /// Check if region already done
    fn region_done(&self, region: &WorldRegion) -> Result<bool,DataAccessError> {
        Ok(self.db().get(MetaKeyForRegion::from(*region))?.is_some())
    }
}

//--------------------------------------
pub trait MarkRegionAsDone {
    fn mark_region_done(&mut self, region: &WorldRegion) 
        -> Result<(),DatabaseConstructionError>;
}

impl MarkRegionAsDone for Database {

    /// Mark region as done
    fn mark_region_done(&mut self, region: &WorldRegion) 
        -> Result<(),DatabaseConstructionError> 
    {
        self.db().put(&MetaKeyForRegion::from(*region), b"done")?;
        Ok(())
    }
}

// ---------------- [ File: src/putget.rs ]
crate::ix!();

pub trait DatabasePut {
    fn put(&mut self, key: impl AsRef<[u8]>, val: impl AsRef<[u8]>) 
        -> Result<(),DatabaseConstructionError>;
}

impl DatabasePut for Database {

    fn put(&mut self, key: impl AsRef<[u8]>, val: impl AsRef<[u8]>) -> Result<(),DatabaseConstructionError> {
        self.db().put(key, val)?;
        Ok(())
    }
}

//--------------------------------
pub trait DatabaseGet {
    fn get(&self, key: impl AsRef<[u8]>) 
        -> Result<Option<Vec<u8>>,DataAccessError>;
}

impl DatabaseGet for Database {

    fn get(&self, key: impl AsRef<[u8]>) -> Result<Option<Vec<u8>>,DataAccessError> {
        Ok(self.db().get(key)?)
    }
}

// ---------------- [ File: src/meta_key.rs ]
// ---------------- [ File: src/meta_key.rs ]
crate::ix!();

#[derive(Getters,Setters,Debug,Clone,PartialEq,Eq)]
#[getset(get="pub",set="pub")]
pub struct MetaKeyForRegion {
    region: WorldRegion,
    key:    String,
}

impl AsRef<[u8]> for MetaKeyForRegion {

    fn as_ref(&self) -> &[u8] { 
        self.key.as_bytes()
    }
}

impl From<WorldRegion> for MetaKeyForRegion {

    fn from(region: WorldRegion) -> Self {
        let region_name = region.abbreviation();
        Self {
            region,
            key: format!("META:REGION_DONE:{}", region_name),
        }
    }
}

// ---------------- [ File: src/build_all_region_data.rs ]
crate::ix!();

#[tracing::instrument(level = "trace", skip(db))]
pub fn build_all_region_data<I: StorageInterface>(
    db: &I,
    done_regions: &[WorldRegion]
) -> std::collections::HashMap<WorldRegion, RegionData> {
    use std::collections::HashMap;
    trace!(
        "build_all_region_data: invoked with {} done_regions: {:?}",
        done_regions.len(),
        done_regions
    );

    let mut map = HashMap::new();
    for region in done_regions {
        trace!("build_all_region_data: processing region={:?}", region);

        // 1) Load cities (prefix C2Z:)
        let mut city_vec = load_all_cities_for_region(db, region);
        // 2) Load streets (prefix S2C:)
        let mut street_vec = load_all_streets_for_region(db, region);

        trace!(
            "build_all_region_data: region={:?} => raw city_vec={:?}, raw street_vec={:?}",
            region,
            city_vec,
            street_vec
        );

        // Sort them
        city_vec.sort();
        street_vec.sort();

        trace!(
            "build_all_region_data: region={:?} => after sort => city_vec={:?}, street_vec={:?}",
            region,
            city_vec,
            street_vec
        );

        // 3) Build the RegionData
        let rd = RegionDataBuilder::default()
            .cities(city_vec.clone())
            .streets(street_vec.clone())
            .build()
            .expect("RegionData builder should never fail");

        trace!(
            "build_all_region_data: region={:?} => final city_count={}, street_count={}",
            region,
            rd.cities().len(),
            rd.streets().len()
        );

        // Insert into the map
        map.insert(*region, rd);
    }

    trace!(
        "build_all_region_data: done. returning map with {} entries",
        map.len()
    );
    map
}

// ---------------- [ File: src/serialize_primitive_block.rs ]
crate::ix!();

use crate::proto::{fileformat,osmformat};

/// Serializes a [`PrimitiveBlock`] into a `Blob` and `BlobHeader`.
pub fn serialize_primitive_block(
    primitive_block: osmformat::PrimitiveBlock
) -> std::io::Result<(Vec<u8>, Vec<u8>)> {
    trace!("serialize_primitive_block: converting PrimitiveBlock to Blob + BlobHeader");

    let block_bytes = primitive_block.write_to_bytes().map_err(|e| {
        error!("serialize_primitive_block: protobuf error: {:?}", e);
        std::io::Error::new(std::io::ErrorKind::Other, "PrimitiveBlock serialization failed")
    })?;

    let mut blob = fileformat::Blob::new();
    blob.set_raw(block_bytes.clone());
    blob.set_raw_size(block_bytes.len() as i32);

    let blob_bytes = blob.write_to_bytes().map_err(|e| {
        error!("serialize_primitive_block: Blob serialization error: {:?}", e);
        std::io::Error::new(std::io::ErrorKind::Other, "Data Blob serialization failed")
    })?;

    let mut blob_header = fileformat::BlobHeader::new();
    blob_header.set_type("OSMData".to_string());
    blob_header.set_datasize(blob_bytes.len() as i32);

    let blob_header_bytes = blob_header.write_to_bytes().map_err(|e| {
        error!("serialize_primitive_block: BlobHeader serialization error: {:?}", e);
        std::io::Error::new(std::io::ErrorKind::Other, "BlobHeader serialization failed")
    })?;

    debug!("serialize_primitive_block: Blob + BlobHeader ready");
    Ok((blob_header_bytes, blob_bytes))
}

// ---------------- [ File: src/write_indices.rs ]
crate::ix!();

pub trait WriteIndicesForRegion {

    fn write_indices_for_region(
        &mut self,
        region:  &WorldRegion,
        indexes: &InMemoryIndexes
    ) -> Result<(),DatabaseConstructionError>;
}

impl WriteIndicesForRegion for Database {

    /// Write a single region's indexes into DB
    fn write_indices_for_region(
        &mut self,
        region:  &WorldRegion,
        indexes: &InMemoryIndexes

    ) -> Result<(),DatabaseConstructionError> {

        info!("writing InMemoryIndexes for region {:?}", region);

        // State->PostalCode->Streets: S:{region}:{postal_code}
        if let Some(state_map) = indexes.postal_code_to_street_map_for_region(region) {
            for (postal_code, streets) in state_map {
                self.write_streets_to_region_and_postal_code(region,postal_code,streets)?;
            }
        }

        // PostalCode->Cities: Z2C:{region_name}:{postal_code}
        for (postal_code, cities) in indexes.postal_code_cities() {
            self.write_cities_to_region_and_postal_code(region,postal_code,cities)?;
        }

        // City->PostalCodes: C2Z:{region_name}:{city}
        for (city, postal_codes) in indexes.city_postal_codes() {
            self.write_postal_codes_to_region_and_city(region,city,postal_codes)?;
        }

        // City->Streets: C2S:{region_name}:{city}
        for (city, streets) in indexes.city_streets() {
            self.write_streets_to_region_and_city(region,city,streets)?;
        }

        // Street->PostalCodes: S2Z:{region_name}:{street}
        for (street, postal_codes) in indexes.street_postal_codes() {
            self.write_postal_codes_to_region_and_street(region,street,postal_codes)?;
        }

        // Street->Cities: S2C:{region_name}:{street}
        for (street, cities) in indexes.street_cities() {
            self.write_cities_to_region_and_street(region,street,cities)?;
        }

        Ok(())
    }
}

// ---------------- [ File: src/normalize.rs ]
crate::ix!();

pub fn normalize(s: &str) -> String {
    // 1. Trim leading/trailing whitespace
    let trimmed = s.trim();
    
    // 2. Convert to lowercase
    let lower = trimmed.to_lowercase();

    // 3. Replace punctuation with spaces.
    //    This ensures that something like "BALTIMORE---CITY" 
    //    becomes "baltimore   city" before we normalize spaces.
    let replaced: String = lower.chars()
        .map(|c| if c.is_ascii_punctuation() { ' ' } else { c })
        .collect();

    // 4. Convert all consecutive whitespace into a single space
    let parts: Vec<&str> = replaced.split_whitespace().collect();
    parts.join(" ")
}

// ---------------- [ File: src/download_and_parse_all_regions.rs ]
crate::ix!();

/// Download and parse all specified regions, skipping those already built.
pub async fn download_and_parse_regions<I:StorageInterface>(
    regions:          &[WorldRegion],
    target_dir:       impl AsRef<Path> + Send + Sync,
    db:               &mut I,
    write_to_storage: bool,
) -> Result<(), WorldCityAndStreetDbBuilderError> {
    for region in regions {
        download_and_parse_region(region,&target_dir,db,write_to_storage).await?;
    }
    Ok(())
}

/// Improved version of `download_and_parse_region` with extra debug logging
/// to show each step's progress. In your production code, you can merge these
/// log lines into the existing `download_and_parse_region(...)`.
pub async fn download_and_parse_region<I: StorageInterface>(
    region:           &WorldRegion,
    target_dir:       impl AsRef<Path> + Send + Sync,
    db:               &mut I,
    write_to_storage: bool,
) -> Result<(), WorldCityAndStreetDbBuilderError> {
    use tracing::{trace, debug, info, warn, error};
    
    info!("Processing region: {:?}", region);

    // 1) Check if region is already done
    match db.region_done(region) {
        Ok(true) => {
            info!("Region {:?} is already built. Skipping download & parse.", region);
            return Ok(());
        }
        Ok(false) => {
            debug!("Region {:?} not done yet => continuing.", region);
        }
        Err(e) => {
            warn!("Could not check if region done: {:?}", e);
            return Err(WorldCityAndStreetDbBuilderError::DataAccessError(e));
        }
    }

    // 2) Attempt to locate or download the region’s .pbf
    let pbf_file = match obtain_pbf_file_for_region(region, target_dir).await {
        Ok(path) => {
            debug!("PBF path for region {:?} => {:?}", region, path);
            path
        }
        Err(e) => {
            error!("Could not obtain PBF file for region {:?}: {:?}", region, e);
            return Err(e);
        }
    };

    // 3) Parse the .pbf, collecting addresses & aggregator
    info!("Parsing PBF file: {:?}", pbf_file);
    let regional_records = match RegionalRecords::from_osm_pbf_file(*region, pbf_file) {
        Ok(rr) => {
            debug!(
                "Successfully parsed {} records for region {:?}",
                rr.len(), region
            );
            rr
        }
        Err(parse_err) => {
            error!(
                "Failed to parse .pbf for region {:?}: {:?}",
                region, parse_err
            );
            return Err(WorldCityAndStreetDbBuilderError::OsmPbfParseError(parse_err));
        }
    };

    // 4) Optionally write data to storage
    if write_to_storage {
        info!(
            "Writing regional records to DB for region {:?} ...",
            region
        );
        if let Err(e) = regional_records.write_to_storage(db) {
            error!(
                "Could not store region {:?} data into DB: {:?}",
                region, e
            );
            return Err(WorldCityAndStreetDbBuilderError::DatabaseConstructionError(e));
        }
        debug!(
            "Done storing region {:?}; total address records: {}",
            region, regional_records.len()
        );
    } else {
        trace!(
            "write_to_storage=false => skipping DB writes for region {:?}",
            region
        );
    }

    info!("Done processing region {:?}.", region);
    Ok(())
}


crate::ix!();

// If put fails => returns DatabaseConstructionError::RocksDB
pub struct FailingDbStub;

impl StoreHouseNumberRanges for FailingDbStub {
    fn store_house_number_ranges(
        &mut self,
        region: &WorldRegion,
        street: &StreetName,
        _ranges: &[HouseNumberRange],
    ) -> Result<(), DatabaseConstructionError> 
    {
        let key = house_number_ranges_key(region, street);
        // We'll skip actual cbor logic for brevity
        let data = vec![1,2,3];
        self.put(key.as_bytes(), data)?;
        Ok(())
    }
}

impl DatabasePut for FailingDbStub {
    fn put(
        &mut self, 
        _key: impl AsRef<[u8]>, 
        _val: impl AsRef<[u8]>
    ) -> Result<(), DatabaseConstructionError> {
        Err(DatabaseConstructionError::SimulatedStoreFailure)
    }
}
// Combine with trait
impl OpenDatabaseAtPath for FailingDbStub {
    fn open(_p: impl AsRef<std::path::Path>) 
        -> Result<Arc<Mutex<Self>>, WorldCityAndStreetDbBuilderError> 
    {
        unimplemented!()
    }
}

impl WriteStreetsToRegionAndPostalCode for FailingDbStub {
    fn write_streets_to_region_and_postal_code(
        &mut self, 
        region: &WorldRegion, 
        postal_code: &PostalCode, 
        streets: &BTreeSet<StreetName>
    ) -> Result<(),DatabaseConstructionError> {
        let key = s_key(region, postal_code);
        let val = compress_set_to_cbor(streets);
        self.put(&key, val)?; // forcibly fails
        Ok(())
    }
}

impl WriteStreetsToRegionAndCity for FailingDbStub {
    fn write_streets_to_region_and_city(
        &mut self, 
        region: &WorldRegion, 
        city: &CityName, 
        streets: &BTreeSet<StreetName>
    ) -> Result<(), DatabaseConstructionError> {
        let key = c2s_key(region, city);
        let val = compress_set_to_cbor(streets);
        self.put(key, val)?; // forcibly fails
        Ok(())
    }
}

impl WritePostalCodesToRegionAndStreet for FailingDbStub {
    fn write_postal_codes_to_region_and_street(
        &mut self, 
        region: &WorldRegion, 
        street: &StreetName, 
        postal_codes: &BTreeSet<PostalCode>
    ) -> Result<(),DatabaseConstructionError> {
        let key = s2z_key(region, street);
        let val = compress_set_to_cbor(postal_codes);
        self.put(key, val)?; // forcibly fails
        Ok(())
    }
}

impl WritePostalCodesToRegionAndCity for FailingDbStub {
    fn write_postal_codes_to_region_and_city(
        &mut self, 
        region: &WorldRegion, 
        city: &CityName, 
        postal_codes: &BTreeSet<PostalCode>
    ) -> Result<(),DatabaseConstructionError> {
        let key = c2z_key(region, city);
        let val = compress_set_to_cbor(postal_codes);
        self.put(key, val)?;
        Ok(())
    }
}

// We only need this trait method:
impl WriteCitiesToRegionAndPostalCode for FailingDbStub {
    fn write_cities_to_region_and_postal_code(
        &mut self,
        region: &WorldRegion,
        postal_code: &PostalCode,
        cities: &BTreeSet<CityName>
    ) -> Result<(), DatabaseConstructionError> {
        let key = z2c_key(region, postal_code);
        let val = compress_set_to_cbor(cities);
        self.put(&key, val)?;
        Ok(())
    }
}

impl WriteCitiesToRegionAndStreet for FailingDbStub {
    fn write_cities_to_region_and_street(
        &mut self, 
        region: &WorldRegion, 
        street: &StreetName, 
        cities: &BTreeSet<CityName>
    ) -> Result<(),DatabaseConstructionError> {
        let key = s2c_key(region, street);
        let val = compress_set_to_cbor(cities);
        self.put(&key, val)?; // forcibly fails
        Ok(())
    }
}

impl WriteIndicesForRegion for FailingDbStub {
    fn write_indices_for_region(
        &mut self, 
        region: &WorldRegion, 
        indexes: &InMemoryIndexes
    ) -> Result<(), DatabaseConstructionError> {
        info!("Failing stub => calls each write method, but put always fails");
        // replicate the logic of the real function, or call it if you want a partial approach
        // We'll do the real logic:
        
        // if let Some(state_map) = indexes.postal_code_to_street_map_for_region(region) {
        //     for (postal_code, streets) in state_map {
        //         self.write_streets_to_region_and_postal_code(region, postal_code, streets)?;
        //     }
        // }
        // for (postal_code, cities) in indexes.postal_code_cities() {
        //     self.write_cities_to_region_and_postal_code(region, postal_code, cities)?;
        // }
        // ... etc for each

        // We'll skip the detail for brevity, but each call fails on put(...) => error
        Err(DatabaseConstructionError::SimulatedStoreFailure)
    }
}

// Minimal stub that updates the first street but fails on the second
pub struct FailingUpdateStub {
    pub(crate) calls: std::cell::RefCell<usize>,
}

impl FailingUpdateStub {
    pub fn new() -> Self {
        FailingUpdateStub {
            calls: std::cell::RefCell::new(0),
        }
    }
}

//--------------------------------------------------
// Define a custom DB type that simulates a load error.
pub struct FailingLoadDatabase {
    inner: Database,
}

impl FailingLoadDatabase {

    pub fn new() -> Result<Arc<Mutex<Self>>, WorldCityAndStreetDbBuilderError> 
    {
        let tmp = tempfile::TempDir::new().unwrap();
        Self::open(tmp.path())
    }
}

// Merge with `Database` or a minimal struct that the code calls:
impl OpenDatabaseAtPath for FailingLoadDatabase {

    fn open(path: impl AsRef<std::path::Path>) 
        -> Result<Arc<Mutex<Self>>, WorldCityAndStreetDbBuilderError> 
    {
        // Unwrap the Arc<Mutex<Database>> into a plain Database.
        let db_arc = Database::open(path).expect("Could not open DB");
        let db = Arc::try_unwrap(db_arc)
            .expect("Only one reference")
            .into_inner()
            .expect("Mutex poisoned");
        Ok(Arc::new(Mutex::new(Self { inner: db })))
    }
}

impl LoadExistingStreetRanges for FailingLoadDatabase {
    fn load_existing_street_ranges(
        &self,
        _r: &WorldRegion,
        _s: &StreetName,
    ) -> Result<Option<Vec<HouseNumberRange>>, DataAccessError> {
        Err(DataAccessError::Io(std::io::Error::new(
                    std::io::ErrorKind::Other,
                    "Simulated load error",
        )))
    }
}
impl StoreHouseNumberRanges for FailingLoadDatabase {
    fn store_house_number_ranges(
        &mut self,
        region: &WorldRegion,
        street: &StreetName,
        ranges: &[HouseNumberRange],
    ) -> Result<(), DatabaseConstructionError> {
        self.inner.store_house_number_ranges(region, street, ranges)
    }
}

// We'll define a partial stub that fails on `load_existing_house_number_ranges`.
// Then confirm update_street_house_numbers => DataAccessError.
impl LoadHouseNumberRanges for FailingLoadDatabase {
    fn load_house_number_ranges(
        &self, 
        _region: &WorldRegion, 
        _street: &StreetName
    ) -> Result<Option<Vec<HouseNumberRange>>, DataAccessError> {
        Err(DataAccessError::SimulatedReadError)
    }
}

//--------------------------------------------------
// Define a custom DB type that simulates a store error.
// If storing the final merged data fails => we see that error.
pub struct FailingStoreDatabase {
    inner: Database,
    // We'll hold a vector for existing data, so we can pass the load step
    existing: Vec<HouseNumberRange>,
}

impl FailingStoreDatabase {

    pub fn new() -> Result<Arc<Mutex<Self>>, WorldCityAndStreetDbBuilderError> 
    {
        let tmp = tempfile::TempDir::new().unwrap();
        Self::open(tmp.path())
    }

    pub fn set_existing(&mut self, existing: Vec<HouseNumberRange>) {
        self.existing = existing;
    }

    /// Allows us to store data directly into the underlying real DB
    /// without triggering the "SimulatedStoreFailure" override.
    pub fn store_ranges_via_inner(
        &mut self,
        region: &WorldRegion,
        street: &StreetName,
        ranges: &[HouseNumberRange],
    ) -> Result<(), DatabaseConstructionError> {
        // Use self.inner's store method, which is the real DB
        self.inner.store_house_number_ranges(region, street, ranges)
    }
}

impl OpenDatabaseAtPath for FailingStoreDatabase {

    fn open(path: impl AsRef<std::path::Path>) 
        -> Result<Arc<Mutex<Self>>, WorldCityAndStreetDbBuilderError> 
    {
        let db_arc = Database::open(path).expect("Could not open DB");

        let db = Arc::try_unwrap(db_arc)
            .expect("Only one reference")
            .into_inner()
            .expect("Mutex poisoned");

        Ok(Arc::new(Mutex::new(Self { inner: db, existing: vec![] })))
    }
}

impl LoadExistingStreetRanges for FailingStoreDatabase {
    fn load_existing_street_ranges(
        &self,
        region: &WorldRegion,
        street: &StreetName,
    ) -> Result<Option<Vec<HouseNumberRange>>, DataAccessError> {
        self.inner.load_existing_street_ranges(region, street)
    }
}

impl StoreHouseNumberRanges for FailingStoreDatabase {
    fn store_house_number_ranges(
        &mut self,
        _region: &WorldRegion,
        _street: &StreetName,
        _ranges: &[HouseNumberRange],
    ) -> Result<(), DatabaseConstructionError> {
        // Return a simulated error using the Other variant.
        Err(DatabaseConstructionError::SimulatedStoreFailure)
    }
}

impl LoadHouseNumberRanges for FailingStoreDatabase {
    fn load_house_number_ranges(
        &self, 
        _region: &WorldRegion, 
        _street: &StreetName
    ) -> Result<Option<Vec<HouseNumberRange>>, DataAccessError> {
        Ok(Some(self.existing.clone()))
    }
}
// ---------------- [ File: src/load_all_cities_for_region.rs ]
crate::ix!();

/// A tiny helper to gather all known city names for a given region.
/// Internally, it searches RocksDB for keys with the prefix `C2Z:<abbr>:`
/// and extracts the city substring after the second colon. It also decodes
/// CBOR values to confirm they're valid, though we discard the parsed data
/// by default.
///
/// # Arguments
///
/// * `db`     - The database reference used for iteration.
/// * `region` - The region whose city names we want to gather.
///
/// # Returns
///
/// * A vector of city names (e.g., `["baltimore", "frederick", ...]`).
pub fn load_all_cities_for_region<I:StorageInterface>(db: &I, region: &WorldRegion) -> Vec<String> {
    trace!("load_all_cities_for_region: start for region={:?}", region);

    let prefix = build_city_search_prefix(region);
    debug!(
        "load_all_cities_for_region: searching DB with prefix='{}'",
        prefix
    );

    // 1) Collect all (key, value) pairs matching "C2Z:<abbr>:".
    let kv_pairs = gather_city_key_value_pairs(db, &prefix);

    // 2) Parse city names from these pairs, optionally decoding CBOR to confirm validity.
    let all_cities = parse_city_names(kv_pairs);

    debug!(
        "load_all_cities_for_region: found {} cities for region={:?}",
        all_cities.len(),
        region
    );
    all_cities
}

// ---------------- [ File: src/validate_not_dir.rs ]
// ---------------- [ File: src/validate_not_dir.rs ]
crate::ix!();

/// Ensures the path does not point to an existing directory.
pub fn validate_not_dir(path: &Path) -> std::io::Result<()> {
    if path.is_dir() {
        let msg = format!("Refusing to create file at {:?}, path is a directory", path);
        error!("{}", msg);
        return Err(std::io::Error::new(std::io::ErrorKind::Other, msg));
    }
    Ok(())
}

// ---------------- [ File: src/parse_city_names.rs ]
crate::ix!();

/// Parses city names from the `(key, value)` pairs. Extracts the city substring
/// after the second colon (`C2Z:US:baltimore => "baltimore"`). Additionally,
/// this step can decode the CBOR values for sanity checks, if desired.
pub fn parse_city_names(kv_pairs: Vec<(String, Vec<u8>)>) -> Vec<String> {
    trace!(
        "parse_city_names: parsing city names from {} key-value pairs",
        kv_pairs.len()
    );

    let mut cities = Vec::new();

    for (key_str, val_bytes) in kv_pairs {
        match extract_city_from_key(&key_str) {
            Some(city) => {
                debug!("parse_city_names: extracted city='{}' from key='{}'", city, key_str);
                // Optionally decode the CBOR to confirm validity:
                if let Err(e) = try_decode_postal_codes(&val_bytes) {
                    // We ignore the contents, but we can log an error if decoding fails
                    warn!(
                        "parse_city_names: postal code decoding failed for city='{}': {}",
                        city, e
                    );
                }
                cities.push(city);
            }
            None => {
                debug!(
                    "parse_city_names: skipping unexpected key='{}' (cannot parse city)",
                    key_str
                );
            }
        }
    }

    cities
}

// ---------------- [ File: src/try_extract_address_tags.rs ]
crate::ix!();

/// Tries to extract address tags from the provided `tags` map.
/// If at least one of `addr:city`, `addr:street`, or `addr:postcode` is present,
/// returns a tuple of optional string slices corresponding to these tags.
/// Returns an error if none of these tags are present.
pub fn try_extract_address_tags(
    tags: &HashMap<String, String>,
    element_id: i64,
) -> Result<(Option<&str>, Option<&str>, Option<&str>), IncompatibleOsmPbfElement> {

    let city_opt     = tags.get("addr:city").map(|s| s.as_str());
    let street_opt   = tags.get("addr:street").map(|s| s.as_str());
    let postcode_opt = tags.get("addr:postcode").map(|s| s.as_str());

    // If none of the address tags are present, return an error.
    if city_opt.is_none() && street_opt.is_none() && postcode_opt.is_none() {
        Err(
            IncompatibleOsmPbfElement::IncompatibleOsmPbfNode(
                IncompatibleOsmPbfNode::Incompatible { id: element_id }
            )
        )
    } else {
        Ok((city_opt, street_opt, postcode_opt))
    }
}

// ---------------- [ File: src/get_cbor_set_typed.rs ]
// ---------------- [ File: src/get_cbor_set_typed.rs ]
crate::ix!();

pub trait GetCborSetTyped {

    /// INTERNAL HELPER: fetch a CBOR-encoded BTreeSet<T> from DB under `key`.
    /// If key not present or empty, returns None. If DB lock is poisoned,
    /// logs warning and returns None.
    fn get_cbor_set_typed<T>(&self, key: &str) -> Option<BTreeSet<T>>
    where
        T: Serialize + DeserializeOwned + Ord;
}

impl<I:StorageInterface> GetCborSetTyped for DataAccess<I> {

    /// INTERNAL HELPER: fetch a CBOR-encoded BTreeSet<T> from DB under `key`.
    /// If key not present or empty, returns None. If DB lock is poisoned,
    /// logs warning and returns None.
    fn get_cbor_set_typed<T>(&self, key: &str) -> Option<BTreeSet<T>>
    where
        T: Serialize + DeserializeOwned + Ord,
    {
        match self.db().lock() {
            Ok(db_guard) => {
                let val = match db_guard.get(key) {
                    Ok(opt) => opt,
                    Err(e) => {
                        warn!("DB get error for key {}: {}", key, e);
                        return None;
                    }
                };
                let bytes = val?;
                let list: Vec<T> = decompress_cbor_to_list(&bytes);
                if list.is_empty() {
                    None
                } else {
                    Some(list.into_iter().collect())
                }
            }
            Err(_) => {
                warn!("Could not get DB lock for key: {}", key);
                None
            },
        }
    }
}

// ---------------- [ File: src/lib.rs ]
#![feature(more_qualified_paths)]
#![feature(type_alias_impl_trait)]
#![allow(unused_imports)]
#![allow(unreachable_code)]
#![allow(unused_variables)]

#[macro_use] mod imports; use imports::*;

pub mod proto {
    include!(concat!(env!("OUT_DIR"), "/mod.rs"));
}

x!{mock_node}
x!{mock_data_access}
x!{mock_tag_iter}
x!{assert_address_record_matches_raw}
x!{assert_street_house_number_map_contains}
x!{mock_address}
x!{address_record_from_element_and_country}
x!{address_record}
x!{mock_failing_db}
x!{addresses_from_pbf_file_with_house_numbers}
x!{attempt_storing_house_number_aggregator_in_db}
x!{build_all_region_data}
x!{build_city_search_prefix}
x!{build_world_address_if_possible}
x!{build_world_address}
x!{capture_stdout}
x!{chain_addresses_across_files}
x!{city_names_for_postal_code_in_region}
x!{city_name}
x!{cli}
x!{cli_hooks}
x!{collect_address_and_housenumber_data}
x!{collect_tags}
x!{compressed_list}
x!{create_address_stream_channel}
x!{create_small_osm_pbf_file}
x!{create_tiny_osm_pbf_with_housenumber}
x!{create_tiny_osm_pbf}
x!{data_access}
x!{db_decoder}
x!{dmv}
x!{download_and_parse_all_regions}
x!{dump}
x!{errors}
x!{expected_filename_for_region}
x!{extract_city_from_key}
x!{extract_house_number_range_from_element}
x!{extract_house_number_range_from_tags}
x!{filenames_match}
x!{filenames}
x!{finalize_address_validation}
x!{find_region_for_file}
x!{gather_all_zips_in_region}
x!{gather_city_key_value_pairs}
x!{gather_pbf_files}
x!{get_cbor_set_typed}
x!{get_city_set_for_key}
x!{get_element_id}
x!{get_postal_code_set_for_key}
x!{get_prefix_iterator}
x!{get_street_set_for_key}
x!{handle_pbf_house_number_extractor_in_thread}
x!{house_number_in_any_range}
x!{house_number_parsing_and_storage}
x!{house_number_ranges}
x!{indexing}
x!{infer_country_from_region}
x!{integrate_house_number_subranges_for_street}
x!{keys}
x!{list_all_addresses_in_pbf_dir}
x!{load_all_cities_for_region}
x!{load_all_streets_for_region}
x!{load_done_regions}
x!{load_existing_street_ranges}
x!{load_house_number_ranges}
x!{merge_house_number_range}
x!{merge_new_subranges}
x!{meta_key}
x!{mock}
x!{normalize}
x!{obtain_pbf_file_for_region}
x!{open_database_at_path}
x!{open_osm_pbf_reader}
x!{open_pbf_reader_or_report_error}
x!{parse_address_record_if_any}
x!{parse_city_names}
x!{parse_housenumber_value}
x!{parse_integer}
x!{parse_osm_pbf_and_build_house_number_ranges}
x!{postal_codes_for_city_in_region}
x!{prefix_transform}
x!{prepare_osm_header_block}
x!{prepare_single_node_primitive_block}
x!{process_and_validate_addresses}
x!{process_single_osm_element}
x!{putget}
x!{region_data}
x!{region_done_traits}
x!{regional_records}
x!{regions}
x!{remote_data}
x!{retrieve_housenumber_value}
x!{serialize_primitive_block}
x!{seriallize_osm_header_block}
x!{stdout_backup}
x!{storage}
x!{store_house_number_ranges}
x!{store_merged_house_number_ranges}
x!{street_exists_globally}
x!{street_exists_in_city_in_region}
x!{street_exists_in_postal_code_in_region}
x!{street_names_for_city_in_region}
x!{street_names_for_postal_code_in_region}
x!{street_name}
x!{strip_leading_dot_slash}
x!{traits}
x!{try_assemble_address_record}
x!{try_build_address_record_from_tags}
x!{try_construct_city_name}
x!{try_construct_postal_code}
x!{try_construct_street_name}
x!{try_decode_postal_codes}
x!{try_extract_address_tags}
x!{try_resolve_country}
x!{unify_new_and_existing_ranges}
x!{update_aggregator_with_housenumber}
x!{update_street_house_numbers}
x!{validate_address}
x!{validate_all_addresses}
x!{validate_city_for_postal_code}
x!{validate_not_dir}
x!{validate_pbf_filename}
x!{validate_street_for_city}
x!{validate_street_for_postal_code}
x!{world_address}
x!{write_be_u32}
x!{write_cities_to_region_and_postal_code}
x!{write_cities_to_region_and_street}
x!{write_house_number_ranges_into_storage}
x!{write_indices}
x!{write_osm_pbf_file}
x!{write_postal_codes_to_region_and_city}
x!{write_postal_codes_to_region_and_street}
x!{write_streets_to_region_and_city}
x!{write_streets_to_region_and_postal_code}
x!{house_number_aggregator}
x!{pbf_creation}
x!{get_iterator}
x!{try_construct_multiple_postal_codes}
// ---------------- [ File: src/collect_tags.rs ]
crate::ix!();

/// Collect tags into a [`HashMap`], generic over any iterator of
/// `(&str, &str)`.  This allows both real `TagIter<'_>` from `osmpbf`
/// **and** test mocks to be used.
///
pub fn collect_tags<'a,I>(tags: I) -> HashMap<String, String>
where
    I: Iterator<Item = (&'a str, &'a str)>,
{
    tags.map(|(k,v)| (k.to_string(), v.to_string())).collect()
}

// ---------------- [ File: src/get_element_id.rs ]
// ---------------- [ File: src/get_element_id.rs ]
crate::ix!();

/// Retrieves the element ID (Node, Way, Relation, or DenseNode), or returns "?" if unknown.
/// Primarily used for logging.
pub fn get_element_id(element: &osmpbf::Element) -> String {
    match element {
        osmpbf::Element::Node(n)       => format!("{}", n.id()),
        osmpbf::Element::Way(w)        => format!("{}", w.id()),
        osmpbf::Element::Relation(r)   => format!("{}", r.id()),
        osmpbf::Element::DenseNode(dn) => format!("{}", dn.id()),
    }
}

// ---------------- [ File: src/try_construct_postal_code.rs ]
crate::ix!();

/// Try to parse the `postcode_raw` as one or more codes separated by `';'`.
/// Returns `Ok(Some(PostalCode))` if at least one is valid, `Ok(None)` if `postcode_raw` is `None`,
/// or `Err(...)` if *all* subcodes are invalid.
#[tracing::instrument(level = "trace", skip_all)]
pub fn try_construct_postal_code(
    country: Country,
    postcode_raw: Option<&str>,
    element_id: i64,
) -> Result<Option<PostalCode>, IncompatibleOsmPbfElement> {
    use tracing::{debug, error};

    if let Some(raw_value) = postcode_raw {
        // Split on semicolons to handle multiple codes like "23060;23233"
        let candidates: Vec<&str> = raw_value.split(';').map(|s| s.trim()).collect();

        // Try each sub‐code; keep the first one that parses successfully
        for candidate in &candidates {
            if candidate.is_empty() {
                continue; // skip empty piece
            }
            match PostalCode::new(country, candidate) {
                Ok(pc) => {
                    debug!(
                        "try_construct_postal_code: sub-code '{}' is valid => {}",
                        candidate, pc.code()
                    );
                    return Ok(Some(pc));
                }
                Err(err) => {
                    error!(
                        "try_construct_postal_code: sub-code '{}' failed parse => {:?}",
                        candidate, err
                    );
                    // but keep trying other sub‐codes
                }
            }
        }

        // If we reach here, *none* of the sub‐codes were valid
        error!(
            "try_construct_postal_code: all sub‐codes invalid. Original='{}' (element_id={})",
            raw_value, element_id
        );
        return Err(IncompatibleOsmPbfElement::IncompatibleOsmPbfNode(
            IncompatibleOsmPbfNode::PostalCodeConstructionError(
                crate::PostalCodeConstructionError::InvalidFormat {
                    attempted_code: raw_value.to_string(),
                    attempted_country: Some(country),
                }
            )
        ));
    } else {
        // If no postcode tag at all, this is not an error; just "None".
        Ok(None)
    }
}

// ---------------- [ File: src/address_record_from_element_and_country.rs ]
crate::ix!();

/// Implements conversion from an OSM PBF element and a `Country` into an `AddressRecord`.
/// Dispatches to one of the above converter functions based on the element variant.
impl<'a> TryFrom<(&osmpbf::Element<'a>, &Country)> for AddressRecord {
    type Error = IncompatibleOsmPbfElement;

    fn try_from((element, country): (&osmpbf::Element<'a>, &Country)) -> Result<Self, Self::Error> {
        match element {
            osmpbf::Element::Node(node)       => convert_osm_node_to_address_record(node, *country),
            osmpbf::Element::Way(way)         => convert_osm_way_to_address_record(way, *country),
            osmpbf::Element::Relation(rel)    => convert_osm_relation_to_address_record(rel, *country),
            osmpbf::Element::DenseNode(dense) => convert_osm_dense_node_to_address_record(dense, *country),
        }
    }
}

/// A macro to generate multiple OSM-element-to-AddressRecord converter functions
/// with minimal boilerplate. Each generated function:
///   1. Extracts an identifier (`id`).
///   2. Logs the element processing progress.
///   3. Invokes a shared `address_record_from_tags(...)`.
///   4. Transforms `IncompatibleOsmPbfElement::IncompatibleOsmPbfNode` into the
///      appropriate variant if needed.
///
/// The macro accepts a list of converters to generate. Each converter
/// is declared in the form:
///
/// ```text
///   fn_name, ElementType, "DescriptiveLabel", error_mapping
/// ```
///
/// - `fn_name` is the desired function identifier.
/// - `ElementType` is any type offering:
///      - `.id()` -> i64
///      - `.tags()` -> Iterator<(K, V)>
/// - `"DescriptiveLabel"` is a textual label included in log messages.
/// - `error_mapping` is a closure of the form:
///      `|id, node_err| { <transform> }`
///   which transforms `IncompatibleOsmPbfElement::IncompatibleOsmPbfNode(...)` into the desired variant.
///   If no transformation is needed (i.e. for Node), simply pass an identity closure.
///
/// Example usage for Node (identity):
/// ```text
/// |_, node_err| IncompatibleOsmPbfElement::IncompatibleOsmPbfNode(node_err)
/// ```
///
/// Example usage for Way (transform to IncompatibleOsmPbfWay):
/// ```text
/// |id, _| IncompatibleOsmPbfElement::IncompatibleOsmPbfWay(
///     IncompatibleOsmPbfWay::Incompatible { id }
/// )
/// ```
macro_rules! generate_osm_address_record_converters {
    ( $($fn_name:ident, $elem_ty:ty, $label:expr, $err_mapping:expr);+ $(;)?) => {
        $(
            #[doc = concat!("Converts an OSM ", $label, " element into an AddressRecord.")]
            ///
            /// # Arguments
            ///
            /// * `elem`    - Reference to the OSM element.
            /// * `country` - The associated `Country`.
            ///
            /// # Returns
            ///
            /// * `Ok(AddressRecord)` if successful.
            /// * `Err(IncompatibleOsmPbfElement)` if conversion fails.
            fn $fn_name(
                elem: &$elem_ty,
                country: Country
            ) -> Result<AddressRecord, IncompatibleOsmPbfElement> {
                let id = elem.id();
                trace!("{}: converting {} with id {}", stringify!($fn_name), $label, id);
                let tag_iter = elem.tags().map(|(k, v)| (k, v));

                match try_build_address_record_from_tags(tag_iter, country, id) {
                    Ok(record) => {
                        //trace!("Successfully converted {} (id={}) into AddressRecord", $label, id);
                        Ok(record)
                    }
                    Err(e) => {
                        //error!("Failed to convert {} (id={}): {:?}", $label, id, e);
                        Err(match e {
                            IncompatibleOsmPbfElement::IncompatibleOsmPbfNode(node_err) => {
                                $err_mapping(id, node_err)
                            }
                            other => other,
                        })
                    }
                }
            }
        )+
    };
}

// Generate all the converters in a single macro invocation.
generate_osm_address_record_converters!(
    convert_osm_node_to_address_record,
    osmpbf::Node,
    "Node",
    // Node just passes the node-specific error along (identity).
    |_, node_err| IncompatibleOsmPbfElement::IncompatibleOsmPbfNode(node_err);

    convert_osm_way_to_address_record,
    osmpbf::Way,
    "Way",
    // Convert IncompatibleOsmPbfNode(...) to IncompatibleOsmPbfWay(...).
    |id, _| IncompatibleOsmPbfElement::IncompatibleOsmPbfWay(
        IncompatibleOsmPbfWay::Incompatible { id }
    );

    convert_osm_relation_to_address_record,
    osmpbf::Relation,
    "Relation",
    // Convert IncompatibleOsmPbfNode(...) to IncompatibleOsmPbfRelation(...).
    |id, _| IncompatibleOsmPbfElement::IncompatibleOsmPbfRelation(
        IncompatibleOsmPbfRelation::Incompatible { id }
    );

    convert_osm_dense_node_to_address_record,
    osmpbf::DenseNode,
    "DenseNode",
    // Convert IncompatibleOsmPbfNode(...) to IncompatibleOsmPbfDenseNode(...).
    |id, _| IncompatibleOsmPbfElement::IncompatibleOsmPbfDenseNode(
        IncompatibleOsmPbfDenseNode::Incompatible { id }
    );
);

// ---------------- [ File: src/write_streets_to_region_and_postal_code.rs ]
crate::ix!();

pub trait WriteStreetsToRegionAndPostalCode {
    fn write_streets_to_region_and_postal_code(
        &mut self, 
        region:      &WorldRegion, 
        postal_code: &PostalCode, 
        streets:     &BTreeSet<StreetName>
    ) -> Result<(),DatabaseConstructionError> ;
}

impl WriteStreetsToRegionAndPostalCode for Database {

    fn write_streets_to_region_and_postal_code(&mut self, region: &WorldRegion, postal_code: &PostalCode, streets: &BTreeSet<StreetName>) 
        -> Result<(),DatabaseConstructionError> 
    {
        let key = s_key(region,postal_code);
        let val = compress_set_to_cbor(streets);
        self.put(&key, val)?;
        Ok(())
    }
}

// ---------------- [ File: src/prefix_transform.rs ]
crate::ix!();

/// Create a `SliceTransform` that extracts everything **up to and including** the second `':'`
/// in each key. If the key has fewer than two colons, we return the entire key.
pub fn create_colon_prefix_transform() -> SliceTransform {
    SliceTransform::create(
        "my_colon_prefix_transform",
        |key: &[u8]| {
            let mut colon_count = 0;
            for (i, &byte) in key.iter().enumerate() {
                if byte == b':' {
                    colon_count += 1;
                    if colon_count == 2 {
                        // return slice up to and including that second colon
                        return &key[..=i];
                    }
                }
            }
            // If fewer than 2 colons => the entire key is the “prefix”
            key
        },
        // The domain check is optional; at minimum we confirm it’s non-empty.
        Some(|k: &[u8]| !k.is_empty()),
    )
}

// ---------------- [ File: src/try_construct_city_name.rs ]
crate::ix!();

/// Attempts to create a `CityName` from a string (if present). Returns an error
/// if construction fails.
pub fn try_construct_city_name(
    city_raw: Option<&str>,
    element_id: i64,
) -> Result<Option<CityName>, IncompatibleOsmPbfElement> {
    if let Some(raw_value) = city_raw {
        trace!("try_construct_city_name: Parsing city for element_id={}", element_id);
        match CityName::new(raw_value) {
            Ok(city) => Ok(Some(city)),
            Err(e) => {
                error!("try_construct_city_name: CityName construction error for element_id={}: {:?}", element_id, e);
                Err(IncompatibleOsmPbfElement::IncompatibleOsmPbfNode(
                    IncompatibleOsmPbfNode::CityNameConstructionError(e),
                ))
            }
        }
    } else {
        debug!("try_construct_city_name: No city tag for element_id={}", element_id);
        Ok(None)
    }
}

// ---------------- [ File: src/process_single_osm_element.rs ]
crate::ix!();

/// For one OSM element, we:
///   1. Attempt to parse an [`AddressRecord`] via `AddressRecord::try_from(...)`.
///   2. Extract a [`HouseNumberRange`] if present.
///   3. If both a street name and house‐number range exist, store them in `street_hnr_map`.
pub fn process_single_osm_element(
    element:        &osmpbf::Element,
    country:        &Country,
    addresses:      &mut Vec<AddressRecord>,
    street_hnr_map: &mut HouseNumberAggregator,

) -> Result<(), OsmPbfParseError> {

    trace!("process_single_osm_element: analyzing an OSM element");

    // Attempt an AddressRecord
    let record_result = AddressRecord::try_from((element, country));
    if let Ok(addr) = &record_result {
        debug!("process_single_osm_element: got AddressRecord => pushing to addresses");
        addresses.push(addr.clone());
    }

    // Attempt a HouseNumberRange
    let hnr_result = extract_house_number_range_from_element(element);

    // If we found a HNR and we have a valid street, record it
    if let Ok(Some(hnr)) = hnr_result {
        let maybe_street = match &record_result {
            Ok(addr) => addr.street().clone(),  // If we already have an AddressRecord
            Err(_) => {
                // If the AddressRecord parse failed, we can try again or skip
                // Try again just to see if there's a street
                if let Ok(addr2) = AddressRecord::try_from((element, country)) {
                    addr2.street().clone()
                } else {
                    None
                }
            }
        };

        if let Some(street) = maybe_street {
            debug!(
                "process_single_osm_element: found HNR={:?} => adding to street='{}'",
                hnr,
                street
            );
            street_hnr_map.add_subrange_for_street(&street,&hnr);
        }
    }

    Ok(())
}

crate::ix!();

pub fn try_construct_multi_postal_codes(
    country: Country,
    raw_value: &str,
    element_id: i64,
) -> Result<Vec<PostalCode>, IncompatibleOsmPbfElement> {
    use tracing::{trace, debug, error};
    use crate::{PostalCode, OsmPbfParseError, IncompatibleOsmPbfElement, IncompatibleOsmPbfNode};

    trace!(
        "try_construct_multi_postal_codes: attempting to parse '{}' with semicolons (element_id={})",
        raw_value,
        element_id
    );

    // Split on semicolons (some data uses e.g. "23060;23233")
    let candidates: Vec<&str> = raw_value.split(';').map(|s| s.trim()).collect();
    if candidates.is_empty() {
        error!(
            "try_construct_multi_postal_codes: no substring found in '{}' (element_id={})",
            raw_value,
            element_id
        );
        return Err(IncompatibleOsmPbfElement::IncompatibleOsmPbfNode(
            IncompatibleOsmPbfNode::PostalCodeConstructionError(
                crate::PostalCodeConstructionError::InvalidFormat {
                    attempted_code: raw_value.to_string(),
                    attempted_country: Some(country),
                }
            )
        ));
    }

    let mut parsed_codes = Vec::new();
    for candidate in candidates {
        if candidate.is_empty() {
            // skip empty
            continue;
        }
        match PostalCode::new(country, candidate) {
            Ok(pc) => {
                debug!(
                    "try_construct_multi_postal_codes: parsed valid code '{}' => {:?}",
                    candidate, pc
                );
                parsed_codes.push(pc);
            }
            Err(e) => {
                // We log it, but keep trying to parse the others
                error!(
                    "try_construct_multi_postal_codes: error parsing '{}' => {:?}",
                    candidate, e
                );
            }
        }
    }

    if parsed_codes.is_empty() {
        // If *none* of the subcodes were valid, return an error
        Err(IncompatibleOsmPbfElement::IncompatibleOsmPbfNode(
            IncompatibleOsmPbfNode::PostalCodeConstructionError(
                crate::PostalCodeConstructionError::InvalidFormat {
                    attempted_code: raw_value.to_string(),
                    attempted_country: Some(country),
                }
            )
        ))
    } else {
        // At least one was good
        Ok(parsed_codes)
    }
}


// ---------------- [ File: src/validate_all_addresses.rs ]
crate::ix!();

/// Validates all addresses from `.pbf` files in a directory against the database.
/// Iterates through each [`WorldAddress`] discovered by `list_all_addresses_in_pbf_dir`,
/// checks validity via `DataAccess::validate_with(...)`, and logs any failures.
///
/// # Arguments
///
/// * `db`      - A shared `Database` reference wrapped in a `Mutex`.
/// * `pbf_dir` - Path to a directory containing `.pbf` files to parse.
///
/// # Returns
///
/// * `Ok(())` if all addresses are valid.
/// * `Err(WorldCityAndStreetDbBuilderError::NotAllAddressesValidatedSuccessfully)` if any address fails.
pub fn validate_all_addresses<I:StorageInterface + 'static>(
    db:      Arc<Mutex<I>>,
    pbf_dir: impl AsRef<Path> + Debug,
) -> Result<(), WorldCityAndStreetDbBuilderError> {

    trace!("validate_all_addresses: start for pbf_dir={:?}", pbf_dir.as_ref());

    info!("validate_all_addresses: validating all addresses in database");

    let address_iter = list_all_addresses_in_pbf_dir(
        pbf_dir.as_ref(),
        db.clone()
    )?;

    let data_access = DataAccess::with_db(db);

    let all_valid = process_and_validate_addresses(address_iter, &data_access)?;

    finalize_address_validation(all_valid)
}

// ---------------- [ File: src/dmv.rs ]
// ---------------- [ File: src/dmv.rs ]
crate::ix!();

/// Builds (or updates) a RocksDB database with DC/MD/VA data, downloading
/// each region’s OSM PBF into `pbf_dir` if necessary.
///
/// Returns the opened database handle upon success.
pub async fn build_dmv_database<I:StorageInterface>(
    db_path: impl AsRef<Path> + Send + Sync,
    pbf_dir: impl AsRef<Path> + Send + Sync,
) -> Result<Arc<Mutex<I>>, WorldCityAndStreetDbBuilderError> 
{
    // 1) Open (or create) the DB
    let db = I::open(db_path)?;

    // 2) For each DMV region, try to parse if not already done
    {
        let mut db_guard = match db.lock() {
            Ok(g) => g,
            Err(_) => {
                // Lock is poisoned
                return Err(WorldCityAndStreetDbBuilderError::DbLockError);
            }
        };

        // All DC/MD/VA
        let regions = dmv_regions();
        for region in regions {
            // This checks if region_done(...) first, so we can just always call it:
            download_and_parse_region(&region, &pbf_dir, &mut *db_guard, true).await?;
        }
    }

    Ok(db)
}

// ---------------- [ File: src/write_postal_codes_to_region_and_street.rs ]
// ---------------- [ File: src/write_postal_codes_to_region_and_street.rs ]
crate::ix!();

pub trait WritePostalCodesToRegionAndStreet {
    fn write_postal_codes_to_region_and_street(
        &mut self, 
        region:       &WorldRegion, 
        street:       &StreetName, 
        postal_codes: &BTreeSet<PostalCode>
    ) -> Result<(),DatabaseConstructionError>;
}

impl WritePostalCodesToRegionAndStreet for Database {
    fn write_postal_codes_to_region_and_street(&mut self, region: &WorldRegion, street: &StreetName, postal_codes: &BTreeSet<PostalCode>) 
        -> Result<(),DatabaseConstructionError> 
    {
        let key = s2z_key(region,street);
        self.put(&key, compress_set_to_cbor(postal_codes))?;
        Ok(())
    }
}

// ---------------- [ File: src/parse_address_record_if_any.rs ]
crate::ix!();

/// Parses an [`AddressRecord`] from the element if possible, returning `Some(AddressRecord)`
/// or `None` if the element doesn't contain valid city/street/postcode tags.
pub fn parse_address_record_if_any(
    element: &osmpbf::Element,
    country: &Country
) -> Option<AddressRecord> {
    match AddressRecord::try_from((element, country)) {
        Ok(rec) => {
            debug!(
                "parse_address_record_if_any: successfully built an AddressRecord, city={:?}, street={:?}, postcode={:?}",
                rec.city(),
                rec.street(),
                rec.postcode()
            );
            Some(rec)
        }
        Err(e) => {
            debug!("parse_address_record_if_any: element not a valid address => {:?}", e);
            None
        }
    }
}

crate::ix!();

pub trait GetIterator {

    fn iterator<'a: 'b, 'b>(
        &'a self,
        mode: rocksdb::IteratorMode,
    ) -> rocksdb::DBIteratorWithThreadMode<'b, rocksdb::DB>;
}

impl GetIterator for Database {

    fn iterator<'a: 'b, 'b>(
        &'a self,
        mode: rocksdb::IteratorMode,
    ) -> rocksdb::DBIteratorWithThreadMode<'b, rocksdb::DB> {
        self.db().iterator(mode)
    }
}

// ---------------- [ File: src/addresses_from_pbf_file_with_house_numbers.rs ]
crate::ix!();

/// The top-level function orchestrates:
/// 1) Converting a [`WorldRegion`] into a [`Country`].
/// 2) Creating a streaming channel.
/// 3) Spawning a background thread to:
///    - Open and parse the OSM PBF file.
///    - Accumulate house number ranges in memory.
///    - Send intermediate address results over the channel.
///    - Store aggregated house number ranges into the database.
/// 4) Returning the consumer side of that channel as an [`Iterator`].
///
/// # Arguments
///
/// * `path`         - Path to an OSM PBF file on disk.
/// * `world_region` - Geographic region used for country inference.
/// * `db`           - Shared mutable database handle.
///
/// # Returns
///
/// * `Ok(impl Iterator<Item = Result<WorldAddress, OsmPbfParseError>>)` on success.
/// * `Err(OsmPbfParseError)` if the country conversion fails immediately.
pub fn addresses_from_pbf_file_with_house_numbers<I:StorageInterface + 'static>(
    path:         PathBuf,
    world_region: WorldRegion,
    db:           Arc<Mutex<I>>,
) -> Result<impl Iterator<Item = Result<WorldAddress, OsmPbfParseError>>, OsmPbfParseError> {
    trace!("addresses_from_pbf_file_with_house_numbers: Invoked with path={:?}, region={:?}", path, world_region);

    let country = try_resolve_country(world_region)?;
    trace!("addresses_from_pbf_file_with_house_numbers: Resolved country={:?}", country);

    let (tx, rx) = create_address_stream_channel();
    trace!("addresses_from_pbf_file_with_house_numbers: Created sync_channel for address streaming");

    let dbc = db.clone();

    // Move ownership into background thread
    thread::spawn(move || {
        handle_pbf_house_number_extractor_in_thread(
            dbc, 
            path, 
            country, 
            world_region, 
            tx
        );
    });

    // Provide the consumer an iterator of results
    Ok(rx.into_iter())
}

crate::ix!();

/// Creates a minimal `WorldAddress` fixture for testing.
pub fn make_mock_address(
    postcode: &str,
    city: &str,
    street: &str
) -> WorldAddress {
    // We'll pick a region that can be validated. 
    let region: WorldRegion = USRegion::UnitedState(UnitedState::Maryland).into();
    WorldAddressBuilder::default()
        .region(region)
        .postal_code(PostalCode::new(Country::USA, postcode).unwrap())
        .city(CityName::new(city).unwrap())
        .street(StreetName::new(street).unwrap())
        .build()
        .unwrap()
}

/// A minimal helper for building an `AddressRecord` with a street,
/// ignoring city/postcode if not relevant for the aggregator usage.
pub fn make_address_record_with_street(street_name: &str) -> AddressRecord {
    AddressRecordBuilder::default()
        .street(Some(StreetName::new(street_name).unwrap()))
        .build()
        .expect("Should build a minimal AddressRecord with just a street")
}

/// Constructs a typical region object for your tests. 
/// In a real environment, pick the region that best matches your system (MD, VA, DC, etc.).
pub fn example_region() -> WorldRegion {
    USRegion::UnitedState(UnitedState::Maryland).into()
}

// ---------------- [ File: src/get_street_set_for_key.rs ]
// ---------------- [ File: src/get_street_set_for_key.rs ]
crate::ix!();

pub trait GetStreetSetForKey {

    /// Returns a set of StreetName objects for the given string key, if present.
    fn get_street_set(&self, key: &str) -> Option<BTreeSet<StreetName>>;
}

impl<I:StorageInterface> GetStreetSetForKey for DataAccess<I> {

    /// Returns a set of StreetName objects for the given string key, if present.
    fn get_street_set(&self, key: &str) -> Option<BTreeSet<StreetName>> {
        self.get_cbor_set_typed::<StreetName>(key)
    }
}

// ---------------- [ File: src/remote_data.rs ]
crate::ix!();

// ---------------- [ File: src/street_name.rs ]
crate::ix!();

/// StreetName struct
#[derive(Builder, Debug, Hash, Clone, Serialize, Deserialize, Getters, PartialEq, Eq, PartialOrd, Ord)]
#[builder(build_fn(error = "StreetNameConstructionError", validate = "Self::validate"))]
pub struct StreetName {
    #[getset(get = "pub")]
    name: String,
}

impl StreetNameBuilder {
    /// The `validate()` method is invoked automatically before the builder finalizes.
    /// We must ensure the final normalized string is not empty.  
    /// Now also checks if the raw string contains `***`, causing an error for your failing test.
    fn validate(&self) -> Result<(), StreetNameConstructionError> {
        if let Some(n) = &self.name {
            // 1) Normalize the input (trim, lowercase, remove punctuation, etc. -- up to you).
            let normed = normalize(n);

            // 2) Fail if the result is empty
            if normed.is_empty() {
                return Err(StreetNameConstructionError::InvalidName {
                    attempted_name: n.clone(),
                });
            }

            // 3) Additional rule so that "***InvalidStreet***" fails
            //    For example, forbid triple asterisks anywhere in the original string:
            if n.contains("***") {
                return Err(StreetNameConstructionError::InvalidName {
                    attempted_name: n.clone(),
                });
            }

            // All good => pass
            Ok(())
        } else {
            // No name provided => treat as invalid
            Err(StreetNameConstructionError::InvalidName {
                attempted_name: "<unset>".to_string(),
            })
        }
    }

    /// Called from your `StreetName::new(...)` to finalize building,
    /// ensuring we apply normalization to the internal field.
    fn finalize(&self) -> Result<StreetName, StreetNameConstructionError> {
        let mut s = self.build()?;
        // If you want to store the normalized version:
        s.name = normalize(&s.name);
        Ok(s)
    }
}

impl StreetName {
    /// Creates a new StreetName from a &str, applying normalization (e.g. lowercase).
    /// Returns an error if the resulting normalized name is empty or fails a custom rule.
    pub fn new(name: &str) -> Result<Self, StreetNameConstructionError> {
        StreetNameBuilder::default()
            .name(name.to_string())
            .finalize()
    }
}

impl fmt::Display for StreetName {
    fn fmt(&self, x: &mut std::fmt::Formatter<'_>) -> fmt::Result {
        write!(x, "{}", self.name)
    }
}


// ---------------- [ File: src/write_postal_codes_to_region_and_city.rs ]
// ---------------- [ File: src/write_postal_codes_to_region_and_city.rs ]
crate::ix!();

pub trait WritePostalCodesToRegionAndCity {
    fn write_postal_codes_to_region_and_city(
        &mut self, 
        region:       &WorldRegion, 
        city:         &CityName, 
        postal_codes: &BTreeSet<PostalCode>
    ) -> Result<(),DatabaseConstructionError>;
}

impl WritePostalCodesToRegionAndCity for Database {
    fn write_postal_codes_to_region_and_city(&mut self, region: &WorldRegion, city: &CityName, postal_codes: &BTreeSet<PostalCode>) 
        -> Result<(),DatabaseConstructionError> 
    {
        let key = c2z_key(region,city);
        self.put(&key, compress_set_to_cbor(postal_codes))?;
        Ok(())
    }
}

// ---------------- [ File: src/extract_city_from_key.rs ]
crate::ix!();

pub fn extract_city_from_key(key_str: &str) -> Option<String> {
    trace!("extract_city_from_key: analyzing key='{}'", key_str);

    let parts: Vec<&str> = key_str.splitn(3, ':').collect();
    if parts.len() < 3 {
        warn!(
            "extract_city_from_key: key='{}' does not contain at least 3 parts; ignoring",
            key_str
        );
        return None;
    }

    let city_part = parts[2];
    if city_part.is_empty() {
        warn!(
            "extract_city_from_key: key='{}' has empty city substring after second colon; ignoring",
            key_str
        );
        return None;
    }

    Some(city_part.to_string())
}

crate::ix!();

// ---------------- [ File: src/db_decoder.rs ]

/// A trait that encapsulates value-decoding logic based on key prefixes.
/// It provides a helper to decode CBOR-encoded sets into known types.
pub trait DatabaseValueDecoder {
    /// Given a `key` and its corresponding raw bytes `val`,
    /// attempt to decode the value into a known domain type
    /// if the key prefix matches. Otherwise, output an appropriate message.
    fn decode_value_for_key(&self, key: &str, val: &[u8]);

    /// Attempt to decode CBOR-encoded data as a `CompressedList<T>`.
    /// If successful, print the items. Otherwise, log a warning.
    fn try_decode_as<T>(&self, val: &[u8], label: &str)
    where
        T: Serialize + DeserializeOwned + Debug;
}

impl DatabaseValueDecoder for Database {
    fn decode_value_for_key(&self, key: &str, val: &[u8]) {
        trace!("decode_value_for_key: key={}", key);
        if key.starts_with("Z2C:") {
            self.try_decode_as::<CityName>(val, "Cities");
        } else if key.starts_with("C2Z:") {
            self.try_decode_as::<PostalCode>(val, "Postal codes");
        } else if key.starts_with("C2S:") {
            self.try_decode_as::<StreetName>(val, "Streets");
        } else if key.starts_with("S:") {
            self.try_decode_as::<StreetName>(val, "Streets");
        } else if key.starts_with("S2C:") {
            self.try_decode_as::<CityName>(val, "Cities");
        } else if key.starts_with("S2Z:") {
            self.try_decode_as::<PostalCode>(val, "Postal codes");
        } else if key.starts_with("META:REGION_DONE:") {
            println!("Value: REGION DONE MARKER");
        } else {
            println!("Value: [Unknown key pattern]");
        }
    }

    fn try_decode_as<T>(&self, val: &[u8], label: &str)
    where
        T: Serialize + DeserializeOwned + Debug,
    {
        trace!("try_decode_as: Attempting decode as '{}'", label);
        match serde_cbor::from_slice::<crate::CompressedList<T>>(val) {
            Ok(clist) => {
                let items = clist.items();
                println!("Decoded as {}: {:?}", label, items);
            }
            Err(e) => {
                println!("Failed to decode as {}: {}", label, e);
            }
        }
    }
}
// ---------------- [ File: src/open_pbf_reader_or_report_error.rs ]
crate::ix!();

/// Helper that attempts to open the OSM PBF file. If successful, returns the reader.
/// On failure, sends the error through `tx` and returns `None`.
pub fn open_pbf_reader_or_report_error(
    path: &PathBuf,
    tx:   &std::sync::mpsc::SyncSender<Result<WorldAddress, OsmPbfParseError>>,
) -> Option<osmpbf::ElementReader<std::io::BufReader<std::fs::File>>> {

    trace!("open_pbf_reader_or_report_error: Opening OSM PBF at {:?}", path);

    match open_osm_pbf_reader(path) {
        Ok(reader) => {
            debug!("open_pbf_reader_or_report_error: Successfully opened {:?}", path);
            Some(reader)
        }
        Err(e) => {
            error!("open_pbf_reader_or_report_error: Failed to open {:?}: {:?}", path, e);
            let _ = tx.send(Err(e));
            None
        }
    }
}

// ---------------- [ File: src/finalize_address_validation.rs ]
// ---------------- [ File: src/finalize_address_validation.rs ]
crate::ix!();

/// Inspects whether all addresses were valid, returning a success or a
/// `NotAllAddressesValidatedSuccessfully` error.
pub fn finalize_address_validation(all_valid: bool) -> Result<(), WorldCityAndStreetDbBuilderError> {
    trace!("finalize_address_validation: all_valid={}", all_valid);
    if !all_valid {
        warn!("finalize_address_validation: Not all addresses validated successfully");
        Err(WorldCityAndStreetDbBuilderError::NotAllAddressesValidatedSuccessfully)
    } else {
        info!("finalize_address_validation: all addresses validated successfully");
        Ok(())
    }
}

// ---------------- [ File: src/write_streets_to_region_and_city.rs ]
// ---------------- [ File: src/write_streets_to_region_and_city.rs ]
crate::ix!();

pub trait WriteStreetsToRegionAndCity {
    fn write_streets_to_region_and_city(
        &mut self, 
        region:  &WorldRegion, 
        city:    &CityName, 
        streets: &BTreeSet<StreetName>
    ) -> Result<(), DatabaseConstructionError>;
}

impl WriteStreetsToRegionAndCity for Database {
    fn write_streets_to_region_and_city(&mut self, region: &WorldRegion, city: &CityName, streets: &BTreeSet<StreetName>) -> Result<(), DatabaseConstructionError> {
        let key = c2s_key(region,city);
        self.put(&key, compress_set_to_cbor(streets))?;
        Ok(())
    }
}

// ---------------- [ File: src/update_aggregator_with_housenumber.rs ]
crate::ix!();

/// Extracts a [`HouseNumberRange`] (if any) from the element and, if found,
/// updates the aggregator entry for the element's street (taken from `record`).
pub fn update_aggregator_with_housenumber(
    element:    &osmpbf::Element,
    record:     &AddressRecord,
    aggregator: &mut HouseNumberAggregator,
) {
    match extract_house_number_range_from_element(element) {
        Ok(Some(range)) => {
            if let Some(street) = record.street() {
                trace!("update_aggregator_with_housenumber: found housenumber range={:?}, street={}", range, street);
                aggregator.entry(street.clone()).or_default().push(range);
            }
        }
        Ok(None) => {
            // No house-number => do nothing
        }
        Err(e) => {
            debug!("update_aggregator_with_housenumber: error extracting house number => {:?}", e);
        }
    }
}

// ---------------- [ File: src/write_be_u32.rs ]
crate::ix!();

/// Writes `value` as a 4-byte big-endian integer into `file`.
pub async fn write_u32_be(file: &mut tokio::fs::File, value: u32) -> std::io::Result<()> {
    let mut buf = [0u8; 4];
    byteorder::BigEndian::write_u32(&mut buf, value);
    file.write_all(&buf).await
}

// ---------------- [ File: src/write_house_number_ranges_into_storage.rs ]
crate::ix!();

/// Merges and writes all provided house‐number ranges into storage for the given region.
/// For each `(street, ranges)`, we load existing data from the DB, unify it with the new ranges,
/// and store the result. This function logs relevant steps and returns an error if
/// database operations fail.
///
/// # Arguments
///
/// * `house_number_ranges` - Map of `StreetName` to a list of new [`HouseNumberRange`] objects.
/// * `region` - The world region these house‐number ranges belong to.
/// * `db`     - Mutable reference to the `Database` to be updated.
///
/// # Returns
///
/// * `Ok(())` if all street data is successfully written.
/// * `Err(DatabaseConstructionError)` if a load or store operation fails.
pub fn write_house_number_ranges_into_storage<I:StorageInterface>(
    house_number_ranges: &HouseNumberAggregator,
    region:              &WorldRegion,
    db:                  &mut I,
) -> Result<(), DatabaseConstructionError> {
    trace!(
        "write_house_number_ranges_into_storage: storing house‐number data for region={:?}, streets_count={}",
        region,
        house_number_ranges.len()
    );

    for (street, new_ranges) in house_number_ranges.iter() {
        update_street_house_numbers(db, region, street, new_ranges)?;
    }

    info!("write_house_number_ranges_into_storage: done processing all streets for region={:?}", region);
    Ok(())
}

// ---------------- [ File: src/mock.rs ]
crate::ix!();

use osmpbf::{Blob,BlobHeader,BlobDecode,PrimitiveGroup,PrimitiveBlock};
use crate::proto::{osmformat,fileformat};

impl Mock for WorldAddress {

    fn mock() -> Self {

        let region: WorldRegion = USRegion::UnitedState(UnitedState::Virginia).into();

        WorldAddressBuilder::default()
            .region(region)
            .postal_code(PostalCode::new(Country::USA, "20138-9997").unwrap())
            .city(CityName::new("Calverton").unwrap())
            .street(StreetName::new("Catlett Road").unwrap())
            .build()
            .unwrap()
    }
}

impl MockForRegion for RegionalRecords {

    fn mock_for_region(region: &WorldRegion) -> Self {

        let md: WorldRegion = USRegion::UnitedState(UnitedState::Maryland).into();
        let va: WorldRegion = USRegion::UnitedState(UnitedState::Virginia).into();
        let dc: WorldRegion = USRegion::USFederalDistrict(USFederalDistrict::DistrictOfColumbia).into();

        let mock_records = match region {
            _ if *region == md => maryland_mock_records(),
            _ if *region == va => virginia_mock_records(),
            _ if *region == dc => dc_mock_records(),
            _ => unimplemented!("need to add mock data for region: {:#?}", region),
        };

        let x = RegionalRecordsBuilder::default()
            .region(*region)
            .records(mock_records)
            .build()
            .unwrap();

        info!("creating mock RegionalRecords for region {:?}: {:#?}", region, x);
        x
    }
}

/// Produce a set of mock AddressRecords for Maryland
fn maryland_mock_records() -> Vec<AddressRecord> {
    // Cover multiple Maryland locales:
    // Baltimore (21201): North Avenue, Greenmount Avenue, Howard Street
    // Bethesda (20814): Wisconsin Avenue, Old Georgetown Road
    // Rockville (20850): Rockville Pike, Veirs Mill Road

    let baltimore        = CityName::new("Baltimore").unwrap();
    let bethesda         = CityName::new("Bethesda").unwrap();
    let rockville        = CityName::new("Rockville").unwrap();

    let north_avenue     = StreetName::new("North Avenue").unwrap();
    let greenmount_avenue= StreetName::new("Greenmount Avenue").unwrap();
    let howard_street    = StreetName::new("Howard Street").unwrap();
    let wisconsin_avenue = StreetName::new("Wisconsin Avenue").unwrap();
    let old_georgetown   = StreetName::new("Old Georgetown Road").unwrap();
    let rockville_pike   = StreetName::new("Rockville Pike").unwrap();
    let veirs_mill_road  = StreetName::new("Veirs Mill Road").unwrap();

    let postalcode21201         = PostalCode::new(Country::USA,"21201").unwrap();
    let postalcode20814         = PostalCode::new(Country::USA,"20814").unwrap();
    let postalcode20850         = PostalCode::new(Country::USA,"20850").unwrap();

    vec![
        address_record!(baltimore, north_avenue     , postalcode21201), 
        address_record!(baltimore, greenmount_avenue, postalcode21201), 
        address_record!(baltimore, howard_street    , postalcode21201), 

        address_record!(bethesda , wisconsin_avenue , postalcode20814), 
        address_record!(bethesda , old_georgetown   , postalcode20814), 

        address_record!(rockville, rockville_pike   , postalcode20850), 
        address_record!(rockville, veirs_mill_road  , postalcode20850), 
    ]
}

/// Produce a set of mock AddressRecords for Virginia
fn virginia_mock_records() -> Vec<AddressRecord> {
    // Arlington (22201): Wilson Blvd, Clarendon Blvd
    // Alexandria (22301): King St, Mount Vernon Ave
    // Reston (20190): Reston Pkwy, Sunrise Valley Dr

    let arlington         = CityName::new("Arlington").unwrap();
    let alexandria        = CityName::new("Alexandria").unwrap();
    let reston            = CityName::new("Reston").unwrap();

    let wilson_blvd       = StreetName::new("Wilson Blvd").unwrap();
    let clarendon_blvd    = StreetName::new("Clarendon Blvd").unwrap();
    let king_st           = StreetName::new("King St").unwrap();
    let mount_vernon_ave  = StreetName::new("Mount Vernon Ave").unwrap();
    let reston_pkwy       = StreetName::new("Reston Pkwy").unwrap();
    let sunrise_valley    = StreetName::new("Sunrise Valley Dr").unwrap();

    let postalcode22201          = PostalCode::new(Country::USA,"22201").unwrap();
    let postalcode22301          = PostalCode::new(Country::USA,"22301").unwrap();
    let postalcode20190          = PostalCode::new(Country::USA,"20190").unwrap();

    let calverton       = CityName::new("Calverton").unwrap();
    let catlett_road = StreetName::new("Catlett Road").unwrap();
    let pc20138_9997       = PostalCode::new(Country::USA, "20138-9997").unwrap();

    vec![
        address_record!(calverton, catlett_road, pc20138_9997),

        address_record!(arlington , wilson_blvd     , postalcode22201), 
        address_record!(arlington , clarendon_blvd  , postalcode22201), 

        address_record!(alexandria, king_st         , postalcode22301), 
        address_record!(alexandria, mount_vernon_ave, postalcode22301), 

        address_record!(reston    , reston_pkwy     , postalcode20190), 
        address_record!(reston    , sunrise_valley  , postalcode20190), 
    ]
}

/// Produce a set of mock AddressRecords for Washington, DC
fn dc_mock_records() -> Vec<AddressRecord> {
    // Washington, DC (20001): Maryland Ave, Pennsylvania Ave
    // Washington, DC (20007): Wisconsin Avenue, M St NW

    let washington_dc    = CityName::new("Washington, DC").unwrap();

    let maryland_ave     = StreetName::new("Maryland Ave").unwrap();
    let pennsylvania_ave = StreetName::new("Pennsylvania Ave").unwrap();
    let wisconsin_avenue = StreetName::new("Wisconsin Avenue").unwrap();
    let m_st_nw          = StreetName::new("M St NW").unwrap();

    let postalcode20001         = PostalCode::new(Country::USA,"20001").unwrap();
    let postalcode20007         = PostalCode::new(Country::USA,"20007").unwrap();

    vec![
        address_record!(washington_dc, maryland_ave    , postalcode20001),
        address_record!(washington_dc, pennsylvania_ave, postalcode20001),

        address_record!(washington_dc, wisconsin_avenue, postalcode20007),
        address_record!(washington_dc, m_st_nw         , postalcode20007),
    ]
}

// ---------------- [ File: src/filenames_match.rs ]
// ---------------- [ File: src/filenames_match.rs ]
crate::ix!();

/// Returns `true` if `actual` matches the `expected` ignoring ASCII case,
/// and possibly including an optional “.<md5>” insertion before `.osm.pbf`.
/// 
/// Example:
/// - expected = "maryland-latest.osm.pbf"
/// - actual   = "MaRyLaNd-LaTeSt.1c2d3f4g.oSm.PbF"
/// => returns true
pub fn filenames_match(expected: &str, actual: &str) -> bool {
    // Because of the possibility that `expected` is "./maryland-latest.osm.pbf"
    // if someone tried something else, do a quick strip leading "./" from both.
    let expected = strip_leading_dot_slash(expected);
    let actual   = strip_leading_dot_slash(actual);

    // Quick check: if ignoring ASCII case they match exactly, done.
    if actual.eq_ignore_ascii_case(&expected) {
        return true;
    }

    // Both must end with ".osm.pbf" ignoring case
    const SUFFIX: &str = ".osm.pbf";
    // For easy checks ignoring ASCII case, let's do a lowercase version
    let expected_lc = expected.to_ascii_lowercase();
    let actual_lc   = actual.to_ascii_lowercase();
    if !expected_lc.ends_with(SUFFIX) || !actual_lc.ends_with(SUFFIX) {
        return false;
    }

    // Trim off ".osm.pbf"
    let expected_base = &expected_lc[..expected_lc.len() - SUFFIX.len()];
    let actual_base   = &actual_lc[..actual_lc.len() - SUFFIX.len()];

    // actual might be something like "maryland-latest.<md5>"
    // expected might be "maryland-latest"
    if !actual_base.starts_with(expected_base) {
        return false;
    }

    // The remainder after "maryland-latest"
    let remainder = &actual_base[expected_base.len()..];
    // If remainder is empty, we already did the eq_ignore_ascii_case() check above,
    // so presumably that would have matched. If remainder starts with '.' and more stuff,
    // that's presumably the MD5. So let's check that:
    if remainder.starts_with('.') && remainder.len() > 1 {
        // e.g. ".abc1234"
        true
    } else {
        false
    }
}

crate::ix!();

use crate::proto::osmformat;

/// Creates a minimal `.osm.pbf` file whose bounding box definitely includes
/// the given `lat`/`lon`, **and** includes a postal code. This ensures the
/// aggregator will see city/street/postal_code/housenumber and emit
/// a `WorldAddress`.
///
/// # Arguments
///
/// * `pbf_path`    - Path to the output `.osm.pbf`.
/// * `city`        - The `addr:city` tag.
/// * `street`      - The `addr:street` tag.
/// * `housenumber` - An optional `addr:housenumber` like `"5-10"`.
/// * `postal_code` - An optional `addr:postcode` like `"21201"`.
/// * `lat`/`lon`   - Node coordinates in floating degrees.
/// * `node_id`     - The Node's OSM ID.
pub async fn create_small_osm_pbf_file_in_bbox(
    pbf_path: &std::path::Path,
    city: &str,
    street: &str,
    housenumber: Option<&str>,
    postal_code: Option<&str>,
    lat: f64,
    lon: f64,
    node_id: i64
) -> std::io::Result<()> {
    // Use a bounding box in 1e7 “nano‐degrees” that covers about 38..40 N, 77..76 W.
    // That definitely includes lat≈39.283, lon≈-76.616.
    let bounding_box = (
        -770_000_000, // left   (≈ -77.0)
        -760_000_000, // right  (≈ -76.0)
         400_000_000, // top    (≈  40.0)
         380_000_000, // bottom (≈  38.0)
    );

    // We extend our lower-level creation function to accept a postal code param.
    // That function must embed `addr:postcode` in the node if `postal_code` is Some(...).
    create_small_osm_pbf_file_with_postcode(
        pbf_path,
        bounding_box,
        city,
        street,
        housenumber,
        postal_code,
        lat,
        lon,
        node_id
    ).await
}

/// Creates a single-node `.osm.pbf` while optionally including `addr:housenumber`
/// and `addr:postcode`. This is just a fork of your existing `create_small_osm_pbf_file`,
/// augmented to handle `postal_code`.
pub async fn create_small_osm_pbf_file_with_postcode(
    path: &std::path::Path,
    bbox: (i64, i64, i64, i64),
    city: &str,
    street: &str,
    housenumber: Option<&str>,
    postal_code: Option<&str>,
    lat: f64,
    lon: f64,
    node_id: i64,
) -> std::io::Result<()> {
    // 1) Validate path
    validate_not_dir(path)?;

    // 2) Build OSMHeader + Blob
    let header_block = prepare_osm_header_block(bbox);
    let (header_blobheader_bytes, header_blob_bytes) = serialize_osm_header_block(header_block)?;

    // 3) Prepare PrimitiveBlock with a single node. We modify the function that
    // actually sets up the node's tags so it can also embed `addr:postcode`.
    let primitive_block = prepare_single_node_primitive_block_with_postcode(
        city,
        street,
        housenumber,
        postal_code,
        lat,
        lon,
        node_id,
    );
    let (data_blobheader_bytes, data_blob_bytes) = serialize_primitive_block(primitive_block)?;

    // 4) Write it out
    write_osm_pbf_file(
        path,
        &header_blobheader_bytes,
        &header_blob_bytes,
        &data_blobheader_bytes,
        &data_blob_bytes,
    )
    .await?;

    Ok(())
}

/// Same as `prepare_single_node_primitive_block` but also includes `addr:postcode` if provided.
pub fn prepare_single_node_primitive_block_with_postcode(
    city: &str,
    street: &str,
    housenumber: Option<&str>,
    postal_code: Option<&str>,
    lat_f64: f64,
    lon_f64: f64,
    node_id: i64,
) -> osmformat::PrimitiveBlock {
    use crate::proto::osmformat;

    let mut block = osmformat::PrimitiveBlock::new();

    // We store our needed strings in a known order:
    // index 0 => ""
    // index 1 => "addr:city"
    // index 2 => city
    // index 3 => "addr:street"
    // index 4 => street
    // index 5 => "addr:housenumber" (only if `housenumber.is_some()`)
    // index 6 => housenumber        (same condition)
    // index 7 => "addr:postcode"    (only if `postal_code.is_some()`)
    // index 8 => postal_code        (same condition)
    let mut stringtable = osmformat::StringTable::new();
    stringtable.s.push(b"".to_vec());              // 0
    stringtable.s.push(b"addr:city".to_vec());     // 1
    stringtable.s.push(city.as_bytes().to_vec());  // 2
    stringtable.s.push(b"addr:street".to_vec());   // 3
    stringtable.s.push(street.as_bytes().to_vec()); // 4

    let mut tag_pairs = Vec::new();

    // city
    tag_pairs.push((1, 2)); // key=1 => "addr:city", val=2 => city

    // street
    tag_pairs.push((3, 4)); // key=3 => "addr:street", val=4 => street

    // housenumber
    let mut next_idx = 5;
    if let Some(hn) = housenumber {
        stringtable.s.push(b"addr:housenumber".to_vec()); // index=5
        stringtable.s.push(hn.as_bytes().to_vec());       // index=6
        tag_pairs.push((5, 6));
        next_idx = 7;
    }

    // postal_code
    if let Some(pc) = postal_code {
        stringtable.s.push(b"addr:postcode".to_vec()); // index=7 or next_idx
        stringtable.s.push(pc.as_bytes().to_vec());    // index=8 or next_idx + 1
        tag_pairs.push((next_idx, next_idx + 1));
    }

    block.stringtable = protobuf::MessageField::from_option(Some(stringtable));

    // Now create the Node and store lat/lon
    let mut group = osmformat::PrimitiveGroup::new();
    let mut node = osmformat::Node::new();
    node.set_id(node_id);

    // For OSM PBF, lat/lon are stored as "integer degrees * 1e7", minus any offset,
    // then further divided by the granularity. We'll do a simpler approach:
    //   lat_nano = (lat_f64 * 1e7) as i64
    //   node.lat = lat_nano / granularity
    //   etc.
    block.set_granularity(100);
    block.set_lat_offset(0);
    block.set_lon_offset(0);

    let lat_scaled = (lat_f64 * 10_000_000.0) as i64; // *1e7
    let lon_scaled = (lon_f64 * 10_000_000.0) as i64;
    node.set_lat(lat_scaled / 100);  // integer division
    node.set_lon(lon_scaled / 100);

    // Add the tag pairs
    for (k_idx, v_idx) in tag_pairs {
        node.keys.push(k_idx);
        node.vals.push(v_idx);
    }

    group.nodes.push(node);
    block.primitivegroup.push(group);
    block
}
// ---------------- [ File: src/strip_leading_dot_slash.rs ]
crate::ix!();

/// Helper to remove leading "./" from a &str
pub fn strip_leading_dot_slash(s: &str) -> &str {
    if let Some(stripped) = s.strip_prefix("./") {
        stripped
    } else {
        s
    }
}
// ---------------- [ File: src/retrieve_housenumber_value.rs ]
crate::ix!();

/// Retrieves the `addr:housenumber` value from the collected tags, if present and non-empty.
///
/// # Returns
///
/// * `Ok(None)` if the housenumber key is absent or empty.
/// * `Ok(Some(&str))` containing a trimmed housenumber string otherwise.
/// * `Err(...)` if the data is invalid in a way that must produce an error.
pub fn retrieve_housenumber_value(
    tags: &HashMap<String, String>,
    element_id: i64,
) -> Result<Option<&str>, IncompatibleOsmPbfElement> {
    trace!(
        "retrieve_housenumber_value: checking for addr:housenumber (element_id={})",
        element_id
    );

    match tags.get("addr:housenumber") {
        None => Ok(None),
        Some(val) if val.trim().is_empty() => Ok(None),
        Some(val) => {
            debug!(
                "retrieve_housenumber_value: found housenumber='{}' (element_id={})",
                val, element_id
            );
            Ok(Some(val.trim()))
        }
    }
}

// ---------------- [ File: src/address_record.rs ]
crate::ix!();

/// A simple structure to hold address info extracted from OSM.
/// Not all OSM ways/nodes have addresses, we only store those that do.
#[derive(PartialEq,Eq,Clone, Default, Builder, Getters, Setters, Debug)]
#[getset(get = "pub", set = "pub")]
#[builder(default, setter(into))]
pub struct AddressRecord {
    city:     Option<CityName>,
    street:   Option<StreetName>,
    postcode: Option<PostalCode>,
}

/// Helper to create an AddressRecord easily
#[macro_export]
macro_rules! address_record {
    ($city:ident, $street:ident, $postcode:ident) => {
        AddressRecord::new($city.clone(), $street.clone(), $postcode.clone())
    };
}

impl AddressRecord {
    pub fn new(city: CityName, street: StreetName, postcode: PostalCode) -> AddressRecord {
        AddressRecordBuilder::default()
            .city(Some(city))
            .street(Some(street))
            .postcode(Some(postcode))
            .build()
            .unwrap()
    }

    pub fn is_empty(&self) -> bool {
        self.city.is_none() && self.street.is_none() && self.postcode.is_none()
    }
}

crate::ix!();

// A quick helper for mocking an iterator over (&str, &str).
pub fn mock_tag_iter<'a>(pairs: Vec<(&'a str, &'a str)>) -> impl Iterator<Item = (&'a str, &'a str)> {
    pairs.into_iter()
}
// ---------------- [ File: src/chain_addresses_across_files.rs ]
crate::ix!();

/// A revised version of `chain_addresses_across_files` that adds more
/// fine-grained debug/info logs about which files match which region.
///
/// Builds a single chained iterator of [`WorldAddress`] across all `.pbf` files.
/// For each file, we attempt to determine the region and parse the file, skipping
/// those with unknown regions.
///
/// # Returns
///
/// * `Ok(Box<dyn Iterator<Item = Result<WorldAddress, OsmPbfParseError>>>)` on success.
/// * `Err(OsmPbfParseError)` if an error arises parsing a given file.
///
pub fn chain_addresses_across_files<I: StorageInterface + 'static>(
    pbf_files:     Vec<PathBuf>,
    known_regions: &[WorldRegion],
    db:            Arc<Mutex<I>>,
    pbf_dir:       &Path,
) -> Result<Box<dyn Iterator<Item = Result<WorldAddress, OsmPbfParseError>>>, OsmPbfParseError> {
    use std::iter;
    use tracing::{info, debug, warn, trace};

    trace!(
        "chain_addresses_across_files_with_logging: building iterator for {} pbf files",
        pbf_files.len()
    );

    let mut chained_iter = Box::new(iter::empty()) as Box<dyn Iterator<Item = _>>;
    let mut recognized_count = 0usize;
    let mut unrecognized_count = 0usize;

    for file_path in pbf_files {
        match find_region_for_file(&file_path, known_regions, pbf_dir)? {
            Some(region) => {
                recognized_count += 1;
                debug!(
                    "chain_addresses_across_files_with_logging: associating {:?} with region={:?}",
                    file_path, region
                );
                // build the file_iter
                let file_iter = addresses_from_pbf_file_with_house_numbers(
                    file_path.clone(),
                    region,
                    db.clone(),
                )?;
                // chain it
                chained_iter = Box::new(chained_iter.chain(file_iter));
            }
            None => {
                unrecognized_count += 1;
                warn!(
                    "chain_addresses_across_files_with_logging: could not determine region for file {:?}; skipping",
                    file_path
                );
            }
        }
    }

    info!(
        "chain_addresses_across_files_with_logging: recognized {} files, skipped {} unknown region files",
        recognized_count, unrecognized_count
    );

    Ok(chained_iter)
}

// ---------------- [ File: src/indexing.rs ]
// ---------------- [ File: src/indexing.rs ]
crate::ix!();

pub type RegionToPostalCodeToStreetsMap = BTreeMap<WorldRegion, BTreeMap<PostalCode, BTreeSet<StreetName>>>;
pub type PostalCodeToStreetMap          = BTreeMap<PostalCode, BTreeSet<StreetName>>;
pub type PostalCodeToCityMap            = BTreeMap<PostalCode, BTreeSet<CityName>>;
pub type CityToPostalCodeMap            = BTreeMap<CityName, BTreeSet<PostalCode>>;
pub type CityToStreetMap                = BTreeMap<CityName, BTreeSet<StreetName>>;
pub type StreetToPostalCodeMap          = BTreeMap<StreetName, BTreeSet<PostalCode>>;
pub type StreetToCitiesMap              = BTreeMap<StreetName, BTreeSet<CityName>>;

#[derive(MutGetters,Getters,Builder,Setters)]
#[getset(get="pub",set="pub",get_mut="pub")]
#[builder(setter(into))]
pub struct InMemoryIndexes {
    #[builder(default)] region_postal_code_streets: RegionToPostalCodeToStreetsMap, // State -> PostalCode -> Streets
    #[builder(default)] postal_code_cities:         PostalCodeToCityMap,            // PostalCode -> Cities
    #[builder(default)] city_postal_codes:          CityToPostalCodeMap,            // City -> PostalCodes
    #[builder(default)] city_streets:               CityToStreetMap,                // City -> Streets
    #[builder(default)] street_postal_codes:        StreetToPostalCodeMap,          // Street -> PostalCodes
    #[builder(default)] street_cities:              StreetToCitiesMap,              // Street -> Cities
}

impl InMemoryIndexes {

    pub fn postal_code_to_street_map_for_region(&self, region: &WorldRegion) -> Option<&PostalCodeToStreetMap> {
        self.region_postal_code_streets.get(region)
    }
}

impl From<&RegionalRecords> for InMemoryIndexes {

    /// Build indexes given a set of address records and a region name.
    fn from(regional_records: &RegionalRecords) -> InMemoryIndexes 
    {
        let region  = regional_records.region();
        let records = regional_records.records();

        tracing::info!("building indices with {} records",records.len());

        let mut region_postal_code_streets = BTreeMap::new();
        let mut postal_code_cities         = BTreeMap::new();
        let mut city_postal_codes          = BTreeMap::new();
        let mut city_streets               = BTreeMap::new();
        let mut street_postal_codes        = BTreeMap::new();
        let mut street_cities              = BTreeMap::new();

        region_postal_code_streets.insert(region.clone(), BTreeMap::new());

        let country = regional_records.country();

        for rec in records {

            if rec.is_empty() {
                continue;
            }

            // Construct typed objects if possible
            let city_obj        = rec.city();
            let street_obj      = rec.street();
            let postal_code_obj = rec.postcode();

            // State->PostalCode->Street
            if let (Some(postal_code), Some(st)) = (postal_code_obj.clone(), street_obj.clone()) {
                region_postal_code_streets
                    .get_mut(&region).unwrap()
                    .entry(postal_code)
                    .or_insert_with(BTreeSet::new)
                    .insert(st);
            }

            // PostalCode->Cities
            if let (Some(postal_code), Some(ct)) = (postal_code_obj.clone(), city_obj.clone()) {
                postal_code_cities
                    .entry(postal_code)
                    .or_insert_with(BTreeSet::new)
                    .insert(ct);
            }

            // City->PostalCode
            if let (Some(ct), Some(postal_code)) = (city_obj.clone(), postal_code_obj.clone()) {
                city_postal_codes
                    .entry(ct)
                    .or_insert_with(BTreeSet::new)
                    .insert(postal_code);
            }

            // City->Streets
            if let (Some(ct), Some(st)) = (city_obj.clone(), street_obj.clone()) {
                city_streets
                    .entry(ct)
                    .or_insert_with(BTreeSet::new)
                    .insert(st);
            }

            // Street->PostalCodes
            if let (Some(st), Some(postal_code)) = (street_obj.clone(), postal_code_obj.clone()) {
                street_postal_codes
                    .entry(st)
                    .or_insert_with(BTreeSet::new)
                    .insert(postal_code);
            }

            // Street->Cities
            if let (Some(st), Some(ct)) = (street_obj.clone(), city_obj.clone()) {
                street_cities
                    .entry(st)
                    .or_insert_with(BTreeSet::new)
                    .insert(ct);
            }
        }

        InMemoryIndexes {
            region_postal_code_streets,
            postal_code_cities,
            city_postal_codes,
            city_streets,
            street_postal_codes,
            street_cities,
        }
    }
}

// ---------------- [ File: src/try_construct_street_name.rs ]
crate::ix!();

/// Attempts to create a `StreetName` from a string (if present). Returns an error
/// if construction fails.
pub fn try_construct_street_name(
    street_raw: Option<&str>,
    element_id: i64,
) -> Result<Option<StreetName>, IncompatibleOsmPbfElement> {
    if let Some(raw_value) = street_raw {
        trace!("try_construct_street_name: Parsing street for element_id={}", element_id);
        match StreetName::new(raw_value) {
            Ok(street) => Ok(Some(street)),
            Err(e) => {
                error!("try_construct_street_name: StreetName construction error for element_id={}: {:?}", element_id, e);
                Err(IncompatibleOsmPbfElement::IncompatibleOsmPbfNode(
                    IncompatibleOsmPbfNode::StreetNameConstructionError(e),
                ))
            }
        }
    } else {
        debug!("try_construct_street_name: No street tag for element_id={}", element_id);
        Ok(None)
    }
}

// ---------------- [ File: src/merge_house_number_range.rs ]
crate::ix!();

/// Merges `new_range` into the existing set of subranges, **unifying both
/// overlapping and adjacent** subranges.  
///
/// e.g. if existing has `[1..5]` and `new_range` is `[6..7]`, we now unify  
/// them into `[1..7]`.  
///
/// # Note
///
/// If you intended disjoint-but-adjacent subranges to remain separate,
/// do *not* use the “<= last.end() + 1” check below. But the test_adjacent_ranges
/// scenario wants them merged, so we unify adjacency.
pub fn merge_house_number_range(
    mut existing: Vec<HouseNumberRange>,
    new_range: &HouseNumberRange
) -> Vec<HouseNumberRange> 
{
    // Insert new range, then sort by start
    existing.push(new_range.clone());
    existing.sort_by_key(|r| *r.start());

    let mut merged = Vec::with_capacity(existing.len());
    for rng in existing {
        if merged.is_empty() {
            merged.push(rng);
        } else {
            let last = merged.last_mut().unwrap();

            // For adjacency or overlap, check if rng.start() <= last.end() + 1
            // so that [1..10] & [11..15] => unify => [1..15].
            if *rng.start() <= *last.end() + 1 {
                // unify => extend last.end if needed
                if rng.end() > last.end() {
                    last.set_end(*rng.end());
                }
            } else {
                // truly disjoint => push new subrange
                merged.push(rng);
            }
        }
    }
    merged
}

// ---------------- [ File: src/build_city_search_prefix.rs ]
crate::ix!();

/// Constructs the RocksDB key prefix for city => postal code data.
pub fn build_city_search_prefix(region: &WorldRegion) -> String {
    trace!("build_city_search_prefix: building prefix for region={:?}", region);
    format!("C2Z:{}:", region.abbreviation())
}

// ---------------- [ File: src/find_region_for_file.rs ]
// ---------------- [ File: src/find_region_for_file.rs ]
crate::ix!();

/// Attempts to deduce which known region a given PBF file corresponds to by comparing its
/// actual filename with the canonical filename pattern for each region.
///
/// # Arguments
///
/// * `file_path`     - The path to the PBF file whose region we wish to identify.
/// * `known_regions` - A slice of all regions we currently track.
/// * `base_dir`      - A base directory used when computing the expected filename.
///
/// # Returns
///
/// * `Some(WorldRegion)` if we find a match
/// * `None` otherwise
pub fn find_region_for_file(
    file_path:     &Path,
    known_regions: &[WorldRegion],
    base_dir:      impl AsRef<Path>,
) -> Result<Option<WorldRegion>,ExpectedFilenameError> {
    let filename = match file_path.file_name().and_then(|f| f.to_str()) {
        Some(s) => s,
        None => return Ok(None),
    };

    for candidate_region in known_regions {
        // Build the expected full path in the provided base directory.
        let expected_path = expected_filename_for_region(&base_dir, candidate_region.download_link())?;
        // Extract just the final filename component of that path (e.g. "maryland-latest.osm.pbf").
        let expected_filename = match expected_path.file_name().and_then(|f| f.to_str()) {
            Some(s) => s,
            None => continue,
        };

        // Compare them (case-insensitive and allowing optional MD5 in the actual filename).
        if filenames_match(expected_filename, filename) {
            return Ok(Some(*candidate_region));
        }
    }

    Ok(None)
}

// ---------------- [ File: src/region_data.rs ]
crate::ix!();

/// (2) For each region, we store city+street lists in memory for fast fuzzy completion.
#[derive(Builder,Getters,Setters,Clone)]
#[getset(get="pub",set="pub")]
#[builder(setter(into))]
pub struct RegionData {
    cities:  Vec<String>,
    streets: Vec<String>,
}
crate::ix!();

/// Asserts that `street_hnr_map` has exactly one entry under the given street name,
/// and that the list of ranges matches `expected_ranges`.
pub fn assert_street_house_number_map_contains(
    street_hnr_map: &HouseNumberAggregator,
    street_name: &str,
    expected_ranges: &[[u32; 2]],
) {
    let found = street_hnr_map.iter().find(|(st, _)| st.name() == street_name);
    assert!(found.is_some(), "Expected a street name '{}' in the map", street_name);
    let (street_key, ranges_vec) = found.unwrap();

    // Convert expected_ranges into HouseNumberRange for easy comparison
    let expected_vec: Vec<HouseNumberRange> = expected_ranges
        .iter()
        .map(|[start, end]| HouseNumberRange::new(*start, *end))
        .collect();

    assert_eq!(
        ranges_vec, &expected_vec,
        "Mismatch in house number subranges for street '{}'",
        street_key.name()
    );
}
// ---------------- [ File: src/validate_city_for_postal_code.rs ]
crate::ix!();

/// Validates that the `[CityName]` is present in the set of cities associated
/// with the `[PostalCode]` (i.e., `z2c_key(region, postal_code)`).
pub fn validate_city_for_postal_code<V:GetCitySetForKey>(
    addr:      &WorldAddress,
    validator: &V,
) -> Result<(), InvalidWorldAddress> {
    let z2c_k = z2c_key(addr.region(), addr.postal_code());
    trace!("validate_city_for_postal_code: using key='{}'", z2c_k);

    match validator.get_city_set(&z2c_k) {
        Some(city_set) => {
            if !city_set.contains(addr.city()) {
                warn!(
                    "validate_city_for_postal_code: city='{:?}' not found for postal_code='{:?}' in region={:?}",
                    addr.city(),
                    addr.postal_code(),
                    addr.region()
                );
                return Err(InvalidWorldAddress::CityNotFoundForPostalCodeInRegion {
                    city: addr.city().clone(),
                    postal_code: addr.postal_code().clone(),
                    region: *addr.region(),
                });
            }
        }
        None => {
            warn!(
                "validate_city_for_postal_code: no city set found for key='{}'",
                z2c_k
            );
            return Err(InvalidWorldAddress::PostalCodeToCityKeyNotFoundForRegion {
                z2c_key: z2c_k,
                region: *addr.region(),
                postal_code: addr.postal_code().clone(),
            });
        }
    }
    Ok(())
}

// ---------------- [ File: src/street_exists_globally.rs ]
crate::ix!();

pub trait StreetExistsGlobally {

    fn street_exists_globally(
        &self, 
        region_name: &WorldRegion, 
        street:      &StreetName
    ) -> bool;
}

impl<I:StorageInterface> StreetExistsGlobally for DataAccess<I> {

    // street_exists_globally in a region:
    fn street_exists_globally(&self, region: &WorldRegion, street: &StreetName) -> bool {

        // If S2C or S2Z keys exist for this street, it's known:
        let key_cities       = s2c_key(region,street);
        let key_postal_codes = s2z_key(region,street);

        self.get_city_set(&key_cities).is_some() || self.get_postal_code_set(&key_postal_codes).is_some()
    }
}

// ---------------- [ File: src/errors.rs ]
crate::ix!();

error_tree!{

    #[derive(PartialEq)]
    pub enum ExpectedFilenameError {
        #[display("Download link was empty or ends with slash, no valid filename found")]
        NoValidFilename,
    }

    #[derive(PartialEq)]
    pub enum DataAccessError {
        SimulatedReadError,
        MockDbAlwaysFailsOnLoad,
        #[cmp_neq]
        Io(io::Error),
        LockPoisoned,
        PostalCodeError(PostalCodeConstructionError),
        RocksDB(rocksdb::Error),
        OsmPbfParseError(OsmPbfParseError),
    }

    pub enum AddressValidationError {
        #[cmp_neq]
        IoError(io::Error),
        DatabaseConstructionError(DatabaseConstructionError),
        LockPoisoned,
    }

    #[derive(PartialEq)]
    pub enum ListAllAddressesError {
        #[cmp_neq]
        IoError(io::Error),
        OsmPbfParseError(OsmPbfParseError),
    }

    #[derive(PartialEq)]
    pub enum InvalidWorldAddress {
        CityNotFoundForPostalCodeInRegion {
            city:        CityName,
            region:      WorldRegion,
            postal_code: PostalCode,
        },
        PostalCodeToCityKeyNotFoundForRegion {
            z2c_key:     String,
            region:      WorldRegion,
            postal_code: PostalCode,
        },
        StreetNotFoundForPostalCodeInRegion {
            street:      StreetName,
            region:      WorldRegion,
            postal_code: PostalCode,
        },
        PostalCodeToStreetKeyNotFoundForRegion {
            s_key:       String,
            region:      WorldRegion,
            postal_code: PostalCode,
        },
        StreetNotFoundForCityInRegion {
            street:      StreetName,
            city:        CityName,
            region:      WorldRegion,
        },
        CityToStreetsKeyNotFoundForCityInRegion {
            c_key:       String,
            region:      WorldRegion,
            city:        CityName,
        }
    }

    #[derive(PartialEq)]
    pub enum OsmPbfParseError {
        SimulatedParseFail,
        ExpectedFilenameError(ExpectedFilenameError),

        #[cmp_neq]
        WorldRegionConversionError(WorldRegionConversionError),

        #[cmp_neq]
        OsmPbf(osmpbf::Error),

        InvalidInputFile { reason: String },

        #[cmp_neq]
        WorldAddressBuilderError(WorldAddressBuilderError),

        #[cmp_neq]
        IoError(io::Error),

        HouseNumberRangeSerdeError {
            msg: String,
        },
    }

    #[derive(PartialEq)]
    pub enum DatabaseConstructionError {
        MockDbAlwaysFailsOnStore,
        SimulatedStoreFailure,
        SimulatedReadError,
        DataAccessError(DataAccessError),
        OsmPbfParseError(OsmPbfParseError),
        RocksDB(rocksdb::Error),
    }

    #[derive(PartialEq)]
    pub enum WorldCityAndStreetDbBuilderError {

        SimulatedDownloadFailure,
        SimulatedUnknownRegionError,

        #[cmp_neq]
        DownloadError(DownloadError),

        DatabaseConstructionError(DatabaseConstructionError),
        OsmPbfParseError(OsmPbfParseError),
        DataAccessError(DataAccessError),
        DbLockError,
        NotAllAddressesValidatedSuccessfully,
    }

    /// Error types for city and street name construction
    #[derive(PartialEq)]
    pub enum CityNameConstructionError {
        InvalidName { attempted_name: String }

        #[cmp_neq]
        UninitializedField(derive_builder::UninitializedFieldError),
    }

    #[derive(PartialEq)]
    pub enum StreetNameConstructionError {
        InvalidName { attempted_name: String }

        #[cmp_neq]
        UninitializedField(derive_builder::UninitializedFieldError),
    }

    #[derive(PartialEq)]
    pub enum IncompatibleOsmPbfElement {
        MaybeTodoUnhandledOsmPbfRelationElement,
        MaybeTodoUnhandledOsmPbfDenseNode,
        IncompatibleOsmPbfNode(IncompatibleOsmPbfNode),
        IncompatibleOsmPbfWay(IncompatibleOsmPbfWay),
        IncompatibleOsmPbfRelation(IncompatibleOsmPbfRelation),
        IncompatibleOsmPbfDenseNode(IncompatibleOsmPbfDenseNode),
    }

    #[derive(PartialEq)]
    pub enum IncompatibleOsmPbfDenseNode {
        Incompatible {
            id: i64,
        },
        CityNameConstructionError(CityNameConstructionError),
        StreetNameConstructionError(StreetNameConstructionError),
        PostalCodeConstructionError(PostalCodeConstructionError),
    }

    #[derive(PartialEq)]
    pub enum IncompatibleOsmPbfRelation {
        Incompatible {
            id: i64,
        },
        CityNameConstructionError(CityNameConstructionError),
        StreetNameConstructionError(StreetNameConstructionError),
        PostalCodeConstructionError(PostalCodeConstructionError),
    }

    #[derive(PartialEq)]
    pub enum IncompatibleOsmPbfNode {
        CityCannotBeImpostorCity,
        Incompatible {
            id: i64,
        },
        CityNameConstructionError(CityNameConstructionError),
        StreetNameConstructionError(StreetNameConstructionError),
        PostalCodeConstructionError(PostalCodeConstructionError),

        #[cmp_neq]
        AddressRecordBuilderError {
            id: i64,
            source: AddressRecordBuilderError,
        }
    }

    #[derive(PartialEq)]
    pub enum IncompatibleOsmPbfWay {
        Incompatible {
            id: i64,
        },
        CityNameConstructionError(CityNameConstructionError),
        StreetNameConstructionError(StreetNameConstructionError),
        PostalCodeConstructionError(PostalCodeConstructionError),
    }
}
// ---------------- [ File: src/store_house_number_ranges.rs ]
crate::ix!();

pub trait StoreHouseNumberRanges {
    fn store_house_number_ranges(
        &mut self,
        region: &WorldRegion,
        street: &StreetName,
        ranges: &[HouseNumberRange],
    ) -> Result<(), DatabaseConstructionError>;
}

impl StoreHouseNumberRanges for Database {

    /// Stores a set of house number sub-ranges for a given region/street into RocksDB.
    ///
    /// This overwrites any existing data for that region+street. 
    /// If you want to merge or append, load first, modify, then store again.
    fn store_house_number_ranges(
        &mut self,
        region: &WorldRegion,
        street: &StreetName,
        ranges: &[HouseNumberRange],
    ) -> Result<(), DatabaseConstructionError> {
        // 1) Key = "HNR:REGION_ABBR:street"
        let key = house_number_ranges_key(region, street);

        // 2) We'll store in CBOR. We can store it as a vector of HouseNumberRange 
        //    inside the standard CompressedList container or just directly. 
        //    For consistency with the rest of the code, let's store it in a CompressedList.
        let clist = crate::compressed_list::CompressedList::from(ranges.to_vec());
        let serialized = match serde_cbor::to_vec(&clist) {
            Ok(bytes) => bytes,
            Err(e) => {
                // Convert to OsmPbfParseError
                let msg = format!("Failed to serialize HouseNumberRanges for street '{}': {}", street.name(), e);
                return Err(OsmPbfParseError::HouseNumberRangeSerdeError { msg }.into());
            }
        };

        // 3) Put into RocksDB
        self.put(key.as_bytes(), serialized)?;
        Ok(())
    }
}

// ---------------- [ File: src/city_names_for_postal_code_in_region.rs ]
crate::ix!();

pub trait CityNamesForPostalCodeInRegion {

    fn cities_for_postal_code(
        &self, 
        region_name: &WorldRegion, 
        postal_code: &PostalCode
    ) -> Option<BTreeSet<CityName>>;
}

impl<I:StorageInterface> CityNamesForPostalCodeInRegion for DataAccess<I> {

    fn cities_for_postal_code(&self, region: &WorldRegion, postal_code: &PostalCode) -> Option<BTreeSet<CityName>> {
        let key = z2c_key(region,postal_code);
        self.get_city_set(&key)
    }
}

// ---------------- [ File: src/build_world_address.rs ]
crate::ix!();

/// Helper that builds a `WorldAddress` from region, city, street, postal.
/// Returns an error if the builder fails.
pub fn build_world_address(
    region: &WorldRegion,
    city: &CityName,
    street: &StreetName,
    postal_code: &crate::PostalCode,
) -> Result<WorldAddress, InvalidWorldAddress>
{
    trace!("build_world_address: city={}, street={}, postal={}", city.name(), street.name(), postal_code.code());
    // For brevity, we assume the builder might only fail on unusual data
    // (your real code might store city/region in the error).
    WorldAddressBuilder::default()
        .region(*region)
        .city(city.clone())
        .street(street.clone())
        .postal_code(postal_code.clone())
        .build()
        .map_err(|_| {
            // Construct any suitable `InvalidWorldAddress` variant or a custom error.
            // For demonstration, we just do a placeholder:
            InvalidWorldAddress::CityNotFoundForPostalCodeInRegion {
                city: city.clone(),
                postal_code: postal_code.clone(),
                region: *region,
            }
        })
}

// ---------------- [ File: src/street_exists_in_city_in_region.rs ]
crate::ix!();

pub trait StreetExistsInCityInRegion {

    fn street_exists_in_city(
        &self, 
        region_name: &WorldRegion, 
        city:        &CityName, 
        street:      &StreetName
    ) -> bool;
}

impl<I:StorageInterface> StreetExistsInCityInRegion for DataAccess<I> {

    fn street_exists_in_city(
        &self, 
        region: &WorldRegion, 
        city:   &CityName, 
        street: &StreetName

    ) -> bool {

        if let Some(sts) = self.street_names_for_city_in_region(region, city) {
            sts.contains(street)
        } else {
            false
        }
    }
}

// ---------------- [ File: src/attempt_storing_house_number_aggregator_in_db.rs ]
crate::ix!();

// ---------------- [ File: src/house_number_aggregator.rs ]
crate::ix!();

#[derive(Clone, Debug)]
pub struct HouseNumberAggregator {
    world_region: WorldRegion,
    country:      Country,
    map:          HashMap<StreetName, Vec<HouseNumberRange>>,
}

impl Default for HouseNumberAggregator {

    fn default() -> Self {
        HouseNumberAggregator {
            world_region: USRegion::UnitedState(UnitedState::Maryland).into(),
            country:      Country::USA,
            map:          HashMap::new(),
        }
    }
}

impl HouseNumberAggregator {
    //-------------------------------------------------
    // Constructors
    //-------------------------------------------------
    pub fn new(world_region: &WorldRegion) -> Self {
        trace!("HouseNumberAggregator::new => constructing empty aggregator");
        Self {
            world_region: world_region.clone(),
            country: Country::try_from(*world_region)
                .expect("expected a valid Country from WorldRegion"),
            map: HashMap::new(),
        }
    }

    pub fn new_with_map(
        world_region: &WorldRegion,
        map: HashMap<StreetName, Vec<HouseNumberRange>>
    ) -> Self {
        Self {
            world_region: world_region.clone(),
            country: Country::try_from(*world_region)
                .expect("expected a valid Country"),
            map,
        }
    }

    //-------------------------------------------------
    // HashMap-like convenience methods
    //-------------------------------------------------

    /// Returns `Some(&Vec<HouseNumberRange>)` if street is present.
    pub fn get(&self, street: &StreetName) -> Option<&Vec<HouseNumberRange>> {
        self.map.get(street)
    }

    /// Inserts (overwrites) the Vec of HouseNumberRange for `street`.
    /// Returns the old Vec if present.
    pub fn insert(
        &mut self,
        street: StreetName,
        ranges: Vec<HouseNumberRange>
    ) -> Option<Vec<HouseNumberRange>> {
        self.map.insert(street, ranges)
    }

    /// Like `HashMap::entry`.
    pub fn entry(
        &mut self,
        street: StreetName
    ) -> std::collections::hash_map::Entry<StreetName, Vec<HouseNumberRange>> {
        self.map.entry(street)
    }

    /// Iterate all (StreetName, Vec<HouseNumberRange>) pairs.
    pub fn iter(&self) -> std::collections::hash_map::Iter<StreetName, Vec<HouseNumberRange>> {
        self.map.iter()
    }

    /// Just the keys (i.e. the StreetNames).
    pub fn keys(&self) -> std::collections::hash_map::Keys<StreetName, Vec<HouseNumberRange>> {
        self.map.keys()
    }

    pub fn as_map(&self) -> &HashMap<StreetName, Vec<HouseNumberRange>> {
        &self.map
    }

    pub fn as_map_mut(&mut self) -> &mut HashMap<StreetName, Vec<HouseNumberRange>> {
        &mut self.map
    }

    /// For direct usage: aggregator.add_subrange_for_street(&my_street, &my_range).
    pub fn add_subrange_for_street(
        &mut self,
        street: &StreetName,
        subrange: &HouseNumberRange
    ) {
        self.map.entry(street.clone())
            .or_default()
            .push(subrange.clone());
    }

    //-------------------------------------------------
    // Aggregator stats
    //-------------------------------------------------

    pub fn len(&self) -> usize {
        self.map.len()
    }

    pub fn is_empty(&self) -> bool {
        self.map.is_empty()
    }

    //-------------------------------------------------
    // The OSM parsing logic
    //-------------------------------------------------

    /// Orchestrates reading from an OSM PBF, storing any discovered subranges in `self`,
    /// and sending each [`WorldAddress`] to `tx`.
    pub fn try_parse_and_aggregate_house_numbers<R: Read + Send + Sync>(
        &mut self,
        reader: ElementReader<R>,
        tx: &SyncSender<Result<WorldAddress, OsmPbfParseError>>,
    ) -> Result<(), OsmPbfParseError> {
        trace!(
            "try_parse_and_aggregate_house_numbers: region={:?}, country={:?}, before={}",
            self.world_region,
            self.country,
            self.map.len()
        );
        self.parse_and_aggregate_osm(reader, tx)
    }

    /// Does the `.for_each` loop on `reader`.
    pub fn parse_and_aggregate_osm<R: Read + Send + Sync>(
        &mut self,
        reader: ElementReader<R>,
        tx: &SyncSender<Result<WorldAddress, OsmPbfParseError>>,
    ) -> Result<(), OsmPbfParseError> {
        let parse_result = reader.for_each(|element| {
            self.process_element_and_add_subrange(element, tx);
        });

        if let Err(e) = parse_result {
            error!("parse_and_aggregate_osm: error reading pbf => {:?}", e);
            return Err(OsmPbfParseError::OsmPbf(e));
        }
        Ok(())
    }

    /// For each element, parse an [`AddressRecord`], build a [`WorldAddress`],
    /// send it, and store subranges if any.
    fn process_element_and_add_subrange(
        &mut self,
        element: Element,
        tx: &SyncSender<Result<WorldAddress, OsmPbfParseError>>,
    ) {
        // 1) Attempt an AddressRecord
        let record_opt = parse_address_record_if_any(&element, &self.country);
        if let Some(record) = record_opt {
            // 2) Attempt a full WorldAddress
            if let Some(world_address) = build_world_address_if_possible(&self.world_region, &record) {
                // 3) send
                if tx.send(Ok(world_address)).is_err() {
                    debug!("process_element_and_add_subrange: receiver closed => stop");
                    return;
                }
                // 4) gather subrange
                self.add_subrange_from_element(&element, &record);
            }
        } else {
            // fallback partial parse
            self.try_infer_subrange_without_full_record(element);
        }
    }

    /// If partial parse reveals a street & subrange => store.
    fn try_infer_subrange_without_full_record(&mut self, element: Element) {
        match extract_house_number_range_from_element(&element) {
            Ok(Some(rng)) => {
                if let Ok(partial_rec) = AddressRecord::try_from((&element, &self.country)) {
                    if let Some(street) = partial_rec.street() {
                        self.map.entry(street.clone())
                            .or_default()
                            .push(rng);
                    }
                }
            }
            Ok(None) => { /* no subrange => skip */ }
            Err(e) => debug!("try_infer_subrange_without_full_record: error => {:?}", e),
        }
    }

    /// Called if we have a real `Element` plus an [`AddressRecord`].
    /// If `addr:housenumber` => store it in aggregator.
    fn add_subrange_from_element(&mut self, element: &Element, record: &AddressRecord) {
        match extract_house_number_range_from_element(element) {
            Ok(Some(rng)) => {
                if let Some(street_name) = record.street() {
                    self.map.entry(street_name.clone())
                        .or_default()
                        .push(rng);
                }
            }
            Ok(None) => {}
            Err(e) => debug!("add_subrange_from_element: error => {:?}", e),
        }
    }

    //-------------------------------------------------
    // "storing in DB" logic
    //-------------------------------------------------

    /// Merges aggregator subranges into the DB for each street
    pub fn store_results_in_db<I: LoadExistingStreetRanges + StoreHouseNumberRanges>(
        &self,
        db: &mut I
    ) -> Result<(), OsmPbfParseError> {
        for (street, subranges) in &self.map {
            integrate_house_number_subranges_for_street(db, &self.world_region, street, subranges)?;
        }
        Ok(())
    }

    /// Locks DB and stores. 
    pub fn attempt_storing_in_db<I: LoadExistingStreetRanges + StoreHouseNumberRanges>(
        &mut self,
        db: Arc<Mutex<I>>,
    ) {
        match db.lock() {
            Ok(mut db_guard) => {
                if let Err(e) = self.store_results_in_db(&mut *db_guard) {
                    warn!("Failed storing aggregator => {:?}", e);
                }
            }
            Err(_) => {
                warn!("DB lock poisoned, aggregator not stored");
            }
        }
    }
}

// ---------------- [ File: src/gather_all_zips_in_region.rs ]
// ---------------- [ File: src/gather_all_zips_in_region.rs ]
crate::ix!();

pub trait GatherAllZipsInRegion {

    fn gather_all_zips_in_region(&self, region: &WorldRegion) -> Vec<PostalCode>;
}

impl<I:StorageInterface> GatherAllZipsInRegion for DataAccess<I> {

    // -----------------------------------------------------------
    // (B) The integrated function to gather ALL zips in a region.
    // -----------------------------------------------------------
    //
    // This iterates over the DB keys that start with `Z2C:<region_abbr>:` 
    // and extracts the postal code substring from each key. 
    // If the code is valid, we add it to a Vec.
    //
    fn gather_all_zips_in_region(&self, region: &WorldRegion) -> Vec<PostalCode> {
        let prefix = format!("Z2C:{}:", region.abbreviation());
        match self.db().lock() {
            Ok(db_guard) => {
                let iter = db_guard.prefix_iterator(prefix.as_bytes());
                let mut out = Vec::new();
                for kv in iter {
                    if let Ok((key_bytes, _val_bytes)) = kv {
                        let key_str = String::from_utf8_lossy(&key_bytes);
                        // e.g. "Z2C:US:21201"
                        let parts: Vec<&str> = key_str.splitn(3, ':').collect();
                        if parts.len() < 3 {
                            continue;
                        }
                        let zip_str = parts[2];
                        if let Ok(pc) = PostalCode::new(Country::USA, zip_str) {
                            out.push(pc);
                        }
                    }
                }
                out
            },
            Err(_) => {
                warn!("Could not lock DB in gather_all_zips_in_region");
                Vec::new()
            }
        }
    }
}

// ---------------- [ File: src/main.rs ]
use world_city_and_street_db_builder::*;

// ---------------- [ File: src/main.rs ]
use tracing_setup::*;
use structopt::*;

#[tokio::main]
async fn main() -> Result<(),WorldCityAndStreetDbBuilderError> {
    configure_tracing();
    let cli = Cli::from_args();
    cli.run().await
}
// ---------------- [ File: src/street_names_for_city_in_region.rs ]
crate::ix!();

pub trait StreetNamesForCityInRegion {

    fn street_names_for_city_in_region(
        &self, 
        region_name: &WorldRegion, 
        city:        &CityName

    ) -> Option<BTreeSet<StreetName>>;
}

impl<I:StorageInterface> StreetNamesForCityInRegion for DataAccess<I> {

    // Similarly for other queries:
    fn street_names_for_city_in_region(&self, region: &WorldRegion, city: &CityName) -> Option<BTreeSet<StreetName>> {
        let key = c2s_key(region,city);
        self.get_street_set(&key)
    }
}

// ---------------- [ File: src/try_decode_postal_codes.rs ]
crate::ix!();

/// Illustrates a hypothetical decode of postal codes from the RocksDB value bytes.
/// Currently, this just checks if the value is valid CBOR without storing or returning
/// the data. This can be extended to parse a `CompressedList<PostalCode>` if needed.
pub fn try_decode_postal_codes(val_bytes: &[u8]) -> Result<(), String> {
    trace!("try_decode_postal_codes: attempting decode of {} bytes", val_bytes.len());
    if val_bytes.is_empty() {
        debug!("try_decode_postal_codes: empty value => ignoring");
        return Ok(());
    }

    // Example: We'll pretend to decode, ignoring the actual type for demonstration.
    match serde_cbor::from_slice::<serde_cbor::Value>(val_bytes) {
        Ok(_) => {
            debug!("try_decode_postal_codes: successfully decoded CBOR data");
            Ok(())
        }
        Err(e) => {
            // Return an error string, or a specialized error type in real code.
            Err(format!("CBOR decode error: {:?}", e))
        }
    }
}

// ---------------- [ File: src/integrate_house_number_subranges_for_street.rs ]
crate::ix!();

/// Integrates a list of new house‐number ranges into existing DB data for the given street,
/// then writes the merged result back to the DB. Logs warnings if load/store operations fail.
///
/// # Arguments
///
/// * `db`           - Database to update.
/// * `world_region` - Region context (used in key derivation).
/// * `street`       - The street whose house‐number ranges are being updated.
/// * `new_ranges`   - A list of new [`HouseNumberRange`] values to be merged.
///
/// # Returns
///
/// * `Ok(())` on success, or if partial failures occurred but we can continue.
/// * `Err(OsmPbfParseError)` if a critical error prevents further processing.
pub fn integrate_house_number_subranges_for_street<I: StoreHouseNumberRanges + LoadExistingStreetRanges>(
    db:           &mut I,
    world_region: &WorldRegion,
    street:       &StreetName,
    new_ranges:   &Vec<HouseNumberRange>,
) -> Result<(), OsmPbfParseError> {

    trace!(
        "integrate_house_number_subranges_for_street: street='{}', merging {} new ranges",
        street,
        new_ranges.len()
    );

    // Step 1) Load existing ranges (if any)
    let existing_opt = match db.load_existing_street_ranges(world_region, street) {
        Ok(v) => v,
        Err(e) => {
            warn!(
                "integrate_house_number_subranges_for_street: could not load existing ranges for street='{}': {:?}",
                street,
                e
            );
            None
        }
    };

    // Step 2) Merge
    let merged = merge_new_subranges(existing_opt.unwrap_or_default(), new_ranges);

    // Step 3) Store
    match db.store_house_number_ranges(world_region, street, &merged) {
        Ok(_) => {
            debug!(
                "integrate_house_number_subranges_for_street: successfully stored merged ranges for street='{}'",
                street
            );
        }
        Err(e) => {
            warn!(
                "integrate_house_number_subranges_for_street: could not store updated ranges for street='{}': {:?}",
                street, e
            );
        }
    }

    Ok(())
}

// ---------------- [ File: src/load_existing_street_ranges.rs ]
crate::ix!();

pub trait LoadExistingStreetRanges {

    fn load_existing_street_ranges(
        &self,
        world_region: &WorldRegion,
        street:       &StreetName,
    ) -> Result<Option<Vec<HouseNumberRange>>, DataAccessError>;
}

impl LoadExistingStreetRanges for Database {

    /// Loads existing house‐number ranges for the specified street from the DB.
    fn load_existing_street_ranges(
        &self,
        world_region: &WorldRegion,
        street:       &StreetName,
    ) -> Result<Option<Vec<HouseNumberRange>>, DataAccessError> {
        trace!(
            "load_existing_street_ranges: loading for street='{}' in region={:?}",
            street,
            world_region
        );
        let existing = self.load_house_number_ranges(world_region, street)?;
        Ok(existing)
    }
}

// ---------------- [ File: src/world_address.rs ]
// ---------------- [ File: src/world_address.rs ]
crate::ix!();

#[derive(Builder,Setters,Getters,Debug,Clone,PartialEq,Eq,PartialOrd,Ord)]
#[getset(get="pub",set="pub")]
#[builder(setter(into))]
pub struct WorldAddress {
    region:      WorldRegion,
    postal_code: PostalCode,
    city:        CityName,
    street:      StreetName,
}

/// Implements a validation process that checks whether the
/// `[WorldAddress]` is consistent with the underlying data structures
/// in the provided `[DataAccess]`.
impl<V:GetCitySetForKey + GetStreetSetForKey> ValidateWith<V> for WorldAddress {
    type Error     = InvalidWorldAddress;

    fn validate_with(&self, validator: &V) -> Result<(), Self::Error> {
        trace!("WorldAddress::validate_with: begin validation for {:?}", self);

        validate_city_for_postal_code(self, validator)?;
        validate_street_for_postal_code(self, validator)?;
        validate_street_for_city(self, validator)?;

        debug!("WorldAddress::validate_with: validation succeeded for {:?}", self);
        Ok(())
    }
}

// ---------------- [ File: tests/world_address_tests.rs ]

// ---------------- [ File: src/merge_new_subranges.rs ]
crate::ix!();

/// Merges newly extracted subranges into the existing list, returning a consolidated list.
/// This example calls an existing helper (like `merge_house_number_range`) for each range.
///
/// # Returns
///
/// * A new `Vec<HouseNumberRange>` containing the merged results.
pub fn merge_new_subranges(
    mut current: Vec<HouseNumberRange>,
    new_ranges: &Vec<HouseNumberRange>,
) -> Vec<HouseNumberRange> {
    trace!(
        "merge_new_subranges: current={} existing ranges, new={} ranges",
        current.len(),
        new_ranges.len()
    );

    for rng in new_ranges {
        current = merge_house_number_range(current, rng);
    }
    current
}

// ---------------- [ File: src/storage.rs ]
crate::ix!();

/// A simple "Database" wrapper that sets up the dynamic prefix transform.
#[derive(Builder,Getters)]
#[getset(get="pub(crate)")]
#[builder(setter(into))]
pub struct Database {
    db: Arc<rocksdb::DB>,
}

impl fmt::Debug for Database {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        // Try to obtain a useful property from the DB.
        // "rocksdb.stats" returns a string with various configuration and runtime statistics.
        let stats = self.db
            .property_value("rocksdb.stats")
            .unwrap_or_else(|_| Some("Unavailable".to_string()));
        
        // You can include other properties similarly:
        // let num_levels = self.db
        //     .property_value("rocksdb.num-files-at-level0")
        //     .unwrap_or_else(|_| "Unavailable".to_string());

        f.debug_struct("Database")
            .field("rocksdb.stats", &stats)
            // .field("num-files-at-level0", &num_levels)
            .finish()
    }
}

impl StorageInterface for Database {}
unsafe impl Send for Database {}
unsafe impl Sync for Database {}

pub trait StorageInterface
: CheckIfRegionDone
+ Send
+ Sync
+ Debug
+ DatabaseDump
+ GetIterator
+ DatabaseGet
+ DatabasePut
+ GetPrefixIterator
+ HouseNumberInAnyRange
+ LoadHouseNumberRanges
+ LoadExistingStreetRanges
+ LoadHouseNumberRanges
+ LoadHouseNumberRanges 
+ MarkRegionAsDone
+ OpenDatabaseAtPath
+ StoreHouseNumberRanges
+ WriteCitiesToRegionAndPostalCode
+ WriteCitiesToRegionAndStreet
+ WriteIndicesForRegion
+ WritePostalCodesToRegionAndCity
+ WritePostalCodesToRegionAndStreet
+ WriteStreetsToRegionAndCity
+ WriteStreetsToRegionAndPostalCode
{}

// ---------------- [ File: src/build_world_address_if_possible.rs ]
crate::ix!();

/// If the [`AddressRecord`] has non-empty (city, street, postcode), build a [`WorldAddress`].
/// Otherwise returns `None`. This allows skipping elements without a complete address.
pub fn build_world_address_if_possible(
    region: &WorldRegion,
    record: &AddressRecord
) -> Option<WorldAddress> {
    let (city_opt, street_opt, postcode_opt) = (record.city(), record.street(), record.postcode());

    if let (Some(city), Some(street), Some(postcode)) = (city_opt, street_opt, postcode_opt) {
        match build_world_address(region, &city, &street, &postcode) {
            Ok(addr) => {
                debug!(
                    "build_world_address_if_possible: built WorldAddress => {:?}",
                    addr
                );
                Some(addr)
            }
            Err(e) => {
                debug!("build_world_address_if_possible: failed => {:?}", e);
                None
            }
        }
    } else {
        debug!("build_world_address_if_possible: record missing city/street/postcode => skipping");
        None
    }
}

// ---------------- [ File: src/get_postal_code_set_for_key.rs ]
// ---------------- [ File: src/get_postal_code_set_for_key.rs ]
crate::ix!();

pub trait GetPostalCodeSetForKey {

    /// Returns a set of PostalCode objects for the given string key, if present.
    fn get_postal_code_set(&self, key: &str) -> Option<BTreeSet<PostalCode>>;
}

impl<I:StorageInterface> GetPostalCodeSetForKey for DataAccess<I> {

    /// Returns a set of PostalCode objects for the given string key, if present.
    fn get_postal_code_set(&self, key: &str) -> Option<BTreeSet<PostalCode>> {
        self.get_cbor_set_typed::<PostalCode>(key)
    }
}

// ---------------- [ File: src/validate_street_for_city.rs ]
crate::ix!();

/// Validates that the `[StreetName]` is present in the set of streets
/// associated with the `[CityName]` (i.e., `c_key(region, city)`).
pub fn validate_street_for_city<V:GetStreetSetForKey>(
    addr:      &WorldAddress,
    validator: &V,
) -> Result<(), InvalidWorldAddress> {

    let c_k = c_key(addr.region(), addr.city());
    trace!("validate_street_for_city: using key='{}'", c_k);

    match validator.get_street_set(&c_k) {
        Some(streets) => {
            if !streets.contains(addr.street()) {
                warn!(
                    "validate_street_for_city: street='{:?}' not found for city='{}' in region={:?}",
                    addr.street(),
                    addr.city(),
                    addr.region()
                );
                return Err(InvalidWorldAddress::StreetNotFoundForCityInRegion {
                    street: addr.street().clone(),
                    city:   addr.city().clone(),
                    region: *addr.region(),
                });
            }
        }
        None => {
            warn!(
                "validate_street_for_city: no street set found for key='{}'",
                c_k
            );
            return Err(InvalidWorldAddress::CityToStreetsKeyNotFoundForCityInRegion {
                c_key: c_k,
                region: *addr.region(),
                city: addr.city().clone(),
            });
        }
    }
    Ok(())
}

// ---------------- [ File: src/unify_new_and_existing_ranges.rs ]
crate::ix!();

/// Merges newly provided house‐number ranges with the existing set.
/// Uses `merge_house_number_range` for each new range.
pub fn unify_new_and_existing_ranges(
    mut current: Vec<HouseNumberRange>,
    new_ranges: &[HouseNumberRange],
) -> Vec<HouseNumberRange> {
    trace!(
        "unify_new_and_existing_ranges: merging {} new ranges into {} existing",
        new_ranges.len(),
        current.len()
    );

    for rng in new_ranges {
        current = merge_house_number_range(current, rng);
    }
    current
}

// ---------------- [ File: src/write_cities_to_region_and_postal_code.rs ]
// ---------------- [ File: src/write_cities_to_region_and_postal_code.rs ]
crate::ix!();

pub trait WriteCitiesToRegionAndPostalCode {
    fn write_cities_to_region_and_postal_code(
        &mut self, 
        region:      &WorldRegion, 
        postal_code: &PostalCode, 
        cities:      &BTreeSet<CityName>
    ) -> Result<(),DatabaseConstructionError> ;
}

impl WriteCitiesToRegionAndPostalCode for Database {

    fn write_cities_to_region_and_postal_code(
        &mut self, 
        region:      &WorldRegion, 
        postal_code: &PostalCode, 
        cities:      &BTreeSet<CityName>

    ) -> Result<(),DatabaseConstructionError> {

        let key = z2c_key(region,postal_code);
        let val = compress_set_to_cbor(cities);
        self.put(&key, val)?;
        Ok(())
    }
}

// ---------------- [ File: src/prepare_osm_header_block.rs ]
crate::ix!();

use crate::proto::osmformat;

/// Builds an OSM header block with given bounding box and required features.
pub fn prepare_osm_header_block(bbox: (i64, i64, i64, i64)) -> osmformat::HeaderBlock {
    trace!("prepare_osm_header_block: using bbox={:?}", bbox);

    let (left, right, top, bottom) = bbox;
    let mut headerblock = osmformat::HeaderBlock::new();

    let mut hbbox = osmformat::HeaderBBox::new();
    hbbox.set_left(left);
    hbbox.set_right(right);
    hbbox.set_top(top);
    hbbox.set_bottom(bottom);

    headerblock.bbox = protobuf::MessageField::from_option(Some(hbbox));
    headerblock.required_features.push("OsmSchema-V0.6".to_string());
    headerblock.required_features.push("DenseNodes".to_string());

    debug!("prepare_osm_header_block: HeaderBlock created");
    headerblock
}

// ---------------- [ File: src/extract_house_number_range_from_tags.rs ]
crate::ix!();

/// Attempts to parse a house number or house‐number range from typical OSM tags:
///   - `addr:housenumber = "123"`        => returns Range(123..=123)
///   - `addr:housenumber = "100-150"`    => returns Range(100..=150)
///   - If none is found or unparseable, returns `Ok(None)`.
///
/// # Arguments
///
/// * `tags_iter`  - An iterator over (key, value) tag pairs.
/// * `element_id` - The ID of the OSM element from which the tags are drawn.
///
/// # Returns
///
/// * `Ok(Some(HouseNumberRange))` if a valid range was found.
/// * `Ok(None)` if no parseable house number is present.
/// * `Err(IncompatibleOsmPbfElement)` if an error prevents us from parsing.
pub fn extract_house_number_range_from_tags<'a, I>(
    tags_iter: I,
    element_id: i64,
) -> Result<Option<HouseNumberRange>, IncompatibleOsmPbfElement>
where
    I: Iterator<Item = (&'a str, &'a str)>,
{
    trace!(
        "extract_house_number_range_from_tags: start (element_id={})",
        element_id
    );

    let tags = collect_tags(tags_iter);
    debug!(
        "extract_house_number_range_from_tags: collected {} tags (element_id={})",
        tags.len(),
        element_id
    );

    match retrieve_housenumber_value(&tags, element_id)? {
        None => {
            debug!(
                "extract_house_number_range_from_tags: no housenumber tag found (element_id={})",
                element_id
            );
            Ok(None)
        }
        Some(raw_value) => parse_housenumber_value(raw_value, element_id),
    }
}

// ---------------- [ File: src/traits.rs ]
crate::ix!();

pub trait ValidateWith<V> {

    type Error;

    fn validate_with(
        &self, 
        validator: &V,
    ) -> Result<(),Self::Error>;
}

pub trait Mock {

    fn mock() -> Self;
}

pub trait MockI {

    fn mock(i:usize) -> Self;
}

pub trait MockForRegion {

    fn mock_for_region(region: &WorldRegion) -> Self;
}
// ---------------- [ File: src/capture_stdout.rs ]
crate::ix!();

/// Captures everything printed to stdout within a closure `f()`, returning
/// it as a `String`. We lock a global mutex so no other test thread can 
/// manipulate or write to stdout concurrently.
///
/// **NOTE**: If your entire test suite is run with `--test-threads=1` or
/// each test using `#[serial]`, you can omit this global lock. But the lock
/// is a safe extra layer in case other code touches stdout in parallel.
///
/// # Safety
/// - We do an `unsafe` call to `libc::dup2(...)`. This is safe only if no other
///   threads are using stdout concurrently (which is why we lock).
pub fn capture_stdout<F: FnOnce()>(f: F) -> io::Result<String> {

    /// Initialize the global lock on first use.
    fn capture_stdout_global_lock() -> &'static Mutex<()> {
        /// A global lock ensuring that only one `capture_stdout` call runs at a time.
        /// We use `OnceLock` so it’s lazily initialized and a `static Mutex`.
        static STDOUT_CAPTURE_LOCK: OnceLock<Mutex<()>> = OnceLock::new();

        eprintln!("locking global lock");
        STDOUT_CAPTURE_LOCK.get_or_init(|| Mutex::new(()))
    }

    // Acquire the global lock so no other thread manipulates stdout:
    //
    // Instead of .expect(...) which fails on poison, we recover from poison:
    let _lock_guard = match capture_stdout_global_lock().lock() {
        Ok(guard) => guard,
        Err(poisoned) => {
            warn!("capture_stdout: global lock was poisoned; continuing anyway.");
            poisoned.into_inner() // recover guard from the poisoned lock
        }
    };

    eprintln!("Backing up original stdout");
    let backup = StdoutBackup::new()?;

    eprintln!("Creating an os_pipe so we can read what’s written");
    let (mut reader, writer) = os_pipe::pipe()?;

    eprintln!("Redirecting stdout to the pipe's writer");
    let stdout_fd = io::stdout().as_raw_fd();
    if unsafe { libc::dup2(writer.as_raw_fd(), stdout_fd) } == -1 {
        error!("dup2 call returned -1");
        return Err(io::Error::last_os_error());
    }

    eprintln!("Running the user closure");
    f();

    eprintln!("Flushing stdout so that everytihgn is definitely in the pipe");
    std::io::stdout().flush()?;

    eprintln!("Restoring stdout");
    backup.restore()?;

    eprintln!("Dropping the writer so the read end sees EOF once data is read");
    drop(writer);

    eprintln!("Reading the entire pipe");
    let mut buffer = Vec::new();
    reader.read_to_end(&mut buffer)?;

    eprintln!("Converting from possibly non-utf8 to a string using .from_utf8_lossy()");
    Ok(String::from_utf8_lossy(&buffer).to_string())
}

// ---------------- [ File: src/load_all_streets_for_region.rs ]
crate::ix!();

/// Corrected variant that decodes a CompressedList<CityName> from S2C:{region} keys.
/// For each decoded city entry, we push the street name (from the key) into `results`.
/// This resolves the "invalid type: map, expected a sequence" error.
pub fn load_all_streets_for_region<I: StorageInterface>(
    db: &I,
    region: &WorldRegion,
) -> Vec<String> {
    use std::string::String;
    use crate::compressed_list::CompressedList; // The struct with `items: Vec<T>`
    use serde_cbor; // for from_slice
    use tracing::{trace, debug, warn, error};

    trace!("load_all_streets_for_region_corrected: start for region={:?}", region);

    // Our known prefix: S2C:<region_abbr>:
    let prefix = format!("S2C:{}:", region.abbreviation());
    debug!("searching DB with prefix='{}'", prefix);

    let iter = db.prefix_iterator(prefix.as_bytes());
    let mut results = Vec::new();

    for item_result in iter {
        match item_result {
            Ok((key_bytes, val_bytes)) => {
                let key_str = String::from_utf8_lossy(&key_bytes).to_string();
                debug!(
                    "found key='{}' ({} bytes of value)",
                    key_str,
                    val_bytes.len()
                );

                // Example: "S2C:MD:some_street_name"
                // Split into 3 parts: ["S2C", "MD", "some_street_name"]
                let parts: Vec<&str> = key_str.splitn(3, ':').collect();
                if parts.len() < 3 {
                    trace!("skipping malformed key='{}'", key_str);
                    continue;
                }

                let street_name = parts[2].to_string();

                // Decode the CBOR *CompressedList<CityName>* rather than Vec<String>.
                match serde_cbor::from_slice::<CompressedList<CityName>>(&val_bytes) {
                    Ok(compressed_list) => {
                        // Each item is a city, but for the aggregator's test scenario,
                        // we simply push `street_name` for each sub-value.
                        for _city in compressed_list.items() {
                            results.push(street_name.clone());
                        }
                    }
                    Err(decode_err) => {
                        warn!(
                            "Ignoring decode error for key='{}': {}. Pushing street_name once.",
                            key_str, decode_err
                        );
                        // At least push once to mimic the old code’s fallback.
                        results.push(street_name.clone());
                    }
                }
            }
            Err(e) => {
                error!(
                    "error reading DB for prefix='{}': {}",
                    prefix,
                    e
                );
            }
        }
    }

    trace!(
        "load_all_streets_for_region_corrected: end for region={:?}, total={} streets found",
        region,
        results.len()
    );
    results
}


// ---------------- [ File: src/compressed_list.rs ]
crate::ix!();

/// A simple wrapper for a list of strings that can be compressed.
/// In real code, implement a front-coding scheme here.
#[derive(Getters,Setters,Serialize,Deserialize)]
#[getset(get="pub",set="pub")]
#[serde(bound = "T: Serialize + DeserializeOwned")]
pub struct CompressedList<T> {
    /// The items stored in a compressed list.
    items: Vec<T>,
}

impl<T> From<Vec<T>> for CompressedList<T> 
where 
    T: Serialize + DeserializeOwned,
{
    fn from(items: Vec<T>) -> Self {
        Self { items }
    }
}

pub fn compress_set_to_cbor<T>(set: &std::collections::BTreeSet<T>) -> Vec<u8> 
where 
    T: Serialize + DeserializeOwned + Clone,
{
    let list: Vec<T> = set.iter().cloned().collect();
    let clist = CompressedList::from(list);
    // Handle errors explicitly rather than `unwrap_or_else` with empty Vec
    match serde_cbor::to_vec(&clist) {
        Ok(bytes) => bytes,
        Err(_) => Vec::new(),
    }
}

pub fn decompress_cbor_to_list<T>(bytes: &[u8]) -> Vec<T> 
where 
    T: Serialize + DeserializeOwned,
{
    match serde_cbor::from_slice::<CompressedList<T>>(bytes) {
        Ok(clist) => clist.items,
        Err(_) => Vec::new(),
    }
}

// ---------------- [ File: src/extract_house_number_range_from_element.rs ]
// ---------------- [ File: src/extract_house_number_range_from_element.rs ]
crate::ix!();

/// A macro that generates specialized extraction functions for each OSM element variant
/// (Node, Way, Relation, DenseNode) plus a unifying
/// `extract_house_number_range_from_element(...)` top‐level function.
///
/// For each variant, you supply:
/// 1) A name for the generated extraction function.
/// 2) The concrete element type (e.g. `osmpbf::Node`).
/// 3) The variant name (e.g. `Node`, `Way`, `Relation`, `DenseNode`).
/// 4) A closure that transforms a node‐specific error into the variant’s corresponding error.
///
#[macro_export]
macro_rules! generate_house_number_extractors {
    (
        $(
            $fn_name:ident,
            $elem_ty:ty,
            $elem_variant:ident,
            $error_transform:expr
        );+ $(;)?
    ) => {
        $(
            /// Generated function to extract a [`HouseNumberRange`] (if any) from an `$elem_variant`.
            /// Converts node‐specific errors using the supplied closure.
            pub fn $fn_name(elem: &$elem_ty) -> Result<Option<HouseNumberRange>, IncompatibleOsmPbfElement> {
                let id = elem.id();
                trace!(
                    "{}: extracting house number range for {} with id={}",
                    stringify!($fn_name),
                    stringify!($elem_variant),
                    id
                );

                let tag_iter = elem.tags().map(|(k, v)| (k, v));
                let result = extract_house_number_range_from_tags(tag_iter, id)
                    .map_err(|err| match err {
                        IncompatibleOsmPbfElement::IncompatibleOsmPbfNode(node_err) => {
                            // Apply the variant‐specific transformation closure
                            let new_err = $error_transform(id, node_err);
                            error!(
                                "{}: converting node‐specific error into {} error for id={}",
                                stringify!($fn_name),
                                stringify!($elem_variant),
                                id
                            );
                            new_err
                        }
                        other => other,
                    });

                match &result {
                    Ok(Some(_)) => {
                        debug!(
                            "{}: found house‐number range for {} with id={}",
                            stringify!($fn_name),
                            stringify!($elem_variant),
                            id
                        );
                    }
                    Ok(None) => {
                        debug!(
                            "{}: no house‐number range for {} with id={}",
                            stringify!($fn_name),
                            stringify!($elem_variant),
                            id
                        );
                    }
                    Err(e) => {
                        error!(
                            "{}: error extracting range for {} with id={}: {:?}",
                            stringify!($fn_name),
                            stringify!($elem_variant),
                            id,
                            e
                        );
                    }
                }

                result
            }
        )+

        /// A unified function that dispatches to the appropriate
        /// extractor depending on the element variant.
        pub fn extract_house_number_range_from_element<'a>(
            element: &'a osmpbf::Element<'a>
        ) -> Result<Option<HouseNumberRange>, IncompatibleOsmPbfElement> {
            match element {
                $(
                    osmpbf::Element::$elem_variant(e) => $fn_name(e),
                )+
            }
        }
    }
}

/// Example usage of the macro. Here we define four specialized
/// extraction functions plus the unified `extract_house_number_range_from_element`.
generate_house_number_extractors!(
    extract_house_number_range_from_node,
    osmpbf::Node,
    Node,
    // Node has no special error mapping; we pass the node error through unchanged.
    |_, node_err| IncompatibleOsmPbfElement::IncompatibleOsmPbfNode(node_err);

    extract_house_number_range_from_way,
    osmpbf::Way,
    Way,
    // Convert node‐specific error => way‐specific error
    |id, _| IncompatibleOsmPbfElement::IncompatibleOsmPbfWay(
        IncompatibleOsmPbfWay::Incompatible { id }
    );

    extract_house_number_range_from_relation,
    osmpbf::Relation,
    Relation,
    // Convert node‐specific error => relation‐specific error
    |id, _| IncompatibleOsmPbfElement::IncompatibleOsmPbfRelation(
        IncompatibleOsmPbfRelation::Incompatible { id }
    );

    extract_house_number_range_from_dense_node,
    osmpbf::DenseNode,
    DenseNode,
    // Convert node‐specific error => dense‐node‐specific error
    |id, _| IncompatibleOsmPbfElement::IncompatibleOsmPbfDenseNode(
        IncompatibleOsmPbfDenseNode::Incompatible { id }
    );
);

// ---------------- [ File: src/postal_codes_for_city_in_region.rs ]
crate::ix!();

pub trait PostalCodesForCityInRegion {

    fn postal_codes_for_city_in_region(
        &self, 
        region: &WorldRegion, 
        city:   &CityName
    ) -> Option<BTreeSet<PostalCode>>;
}

impl<I:StorageInterface> PostalCodesForCityInRegion for DataAccess<I> {

    // Example query: given city name, get associated PostalCode codes
    fn postal_codes_for_city_in_region(&self, region: &WorldRegion, city: &CityName) -> Option<BTreeSet<PostalCode>> {
        let key = c2z_key(region,city);
        if let Some(postal_codes) = self.get_postal_code_set(&key) {
            Some(postal_codes)
        } else {
            None
        }
    }
}

// ---------------- [ File: src/load_done_regions.rs ]
crate::ix!();

/// (5) Helper function to load the set of “done” regions by scanning for `META:REGION_DONE:<abbrev>`.
pub fn load_done_regions<I:StorageInterface>(db: &I) -> Vec<WorldRegion> {
    let prefix = b"META:REGION_DONE:";
    let mut out = Vec::new();

    let it = db.prefix_iterator(prefix);
    for kv in it {
        if let Ok((k, _v)) = kv {
            let key_str = String::from_utf8_lossy(&k).to_string();
            // key_str might be "META:REGION_DONE:US" or "META:REGION_DONE:MD", etc.
            // We parse after the 2nd colon
            if let Some(abbr) = key_str.splitn(3, ':').nth(2) {
                // Attempt to convert abbreviation -> WorldRegion
                // If your code can do `WorldRegion::from_abbreviation(abbr)`, do so.
                // If not, you might store it in your DB or do a custom match. 
                // Here’s a pseudo approach:
                match WorldRegion::try_from_abbreviation(abbr) {
                    Ok(r) => out.push(r),
                    Err(e) => {
                        eprintln!("Could not parse region from abbr '{}': {:?}", abbr, e);
                    }
                }
            }
        }
    }
    out
}

// ---------------- [ File: src/update_street_house_numbers.rs ]
crate::ix!();

/// Loads existing house‐number ranges for a street, merges new data, and stores the result.
pub fn update_street_house_numbers<I:LoadHouseNumberRanges + StoreHouseNumberRanges>(
    db:         &mut I,
    region:     &WorldRegion,
    street:     &StreetName,
    new_ranges: &[HouseNumberRange],
) -> Result<(), DatabaseConstructionError> {

    trace!(
        "update_street_house_numbers: street='{}', merging {} new ranges",
        street,
        new_ranges.len()
    );

    let existing = db.load_house_number_ranges(region, street)?;

    let merged = unify_new_and_existing_ranges(existing.unwrap_or(vec![]), new_ranges);

    db.store_house_number_ranges(region, street, &merged)?;

    Ok(())
}

// ---------------- [ File: src/get_city_set_for_key.rs ]
// ---------------- [ File: src/get_city_set_for_key.rs ]
crate::ix!();

pub trait GetCitySetForKey {

    /// Returns a set of CityName objects for the given string key, if present.
    fn get_city_set(&self, key: &str) -> Option<BTreeSet<CityName>>;
}

impl<I:StorageInterface> GetCitySetForKey for DataAccess<I> {

    fn get_city_set(&self, key: &str) -> Option<BTreeSet<CityName>> {
        self.get_cbor_set_typed::<CityName>(key)
    }
}

// ---------------- [ File: src/validate_pbf_filename.rs ]
crate::ix!();

/// Validates that `pbf_path` has a filename matching what we'd expect for `region`.
/// It also checks for an optional MD5 insertion in the filename.
/// Returns an error if mismatched or if filename is invalid/unreadable.
///
/// Specifically:
/// 1. If `pbf_path.is_dir()` => error with "Invalid filename: <path> is a directory".
/// 2. If `pbf_path.file_name()` is None or non‐UTF8 => error "Invalid filename".
/// 3. Otherwise, generate the expected name for this region and compare with `filenames_match(...)`.
pub fn validate_pbf_filename(
    region:   &WorldRegion,
    pbf_path: &Path,
) -> Result<(), OsmPbfParseError> {

    // (1) If the path is actually a directory, fail with "Invalid filename".
    if pbf_path.is_dir() {
        return Err(OsmPbfParseError::InvalidInputFile {
            reason: format!("Invalid filename: {:?} is a directory", pbf_path),
        });
    }

    // (2) Attempt to extract the actual filename
    let actual_filename = pbf_path
        .file_name()
        .and_then(|f| f.to_str())
        .ok_or_else(|| OsmPbfParseError::InvalidInputFile {
            reason: format!("Invalid filename: {:?}", pbf_path),
        })?;

    // (3) Generate the “expected” filename (e.g. "maryland-latest.osm.pbf") using "." as a base dir
    let expected_path = expected_filename_for_region(Path::new("."), region.download_link())?;
    let expected_filename_str = expected_path.to_str().unwrap_or_default();

    // (4) Compare using filenames_match(...).
    if filenames_match(expected_filename_str, actual_filename) {
        Ok(())
    } else {
        Err(OsmPbfParseError::InvalidInputFile {
            reason: format!(
                "Provided PBF file '{:?}' does not match expected filename '{:?}' for region {:?}",
                actual_filename,
                expected_filename_str,
                region
            ),
        })
    }
}

// ---------------- [ File: src/open_osm_pbf_reader.rs ]
crate::ix!();

pub fn open_osm_pbf_reader(
    path: impl AsRef<std::path::Path>
) -> Result<ElementReader<std::io::BufReader<std::fs::File>>, OsmPbfParseError> {
    let p = path.as_ref();

    // If `p` is a directory => produce an IO error wrapped in an OsmPbf(...) variant
    if p.is_dir() {
        let io_err = std::io::Error::new(
            std::io::ErrorKind::Other,
            format!("{:?} is a directory, not a file", p),
        );
        // Then return OsmPbfParseError::OsmPbf(...)
        return Err(OsmPbfParseError::IoError(io_err));
    }

    // Otherwise, proceed to open
    match osmpbf::ElementReader::from_path(p) {
        Ok(reader) => Ok(reader),
        Err(e) => Err(OsmPbfParseError::OsmPbf(e)),
    }
}

// ---------------- [ File: src/load_house_number_ranges.rs ]
crate::ix!();

pub trait LoadHouseNumberRanges {
    fn load_house_number_ranges(
        &self, 
        region: &WorldRegion, 
        street_obj: &StreetName
    ) -> Result<Option<Vec<HouseNumberRange>>, DataAccessError>;
}

impl<I:StorageInterface> LoadHouseNumberRanges for DataAccess<I> {

    fn load_house_number_ranges(
        &self, 
        region: &WorldRegion, 
        street_obj: &StreetName
    ) -> Result<Option<Vec<HouseNumberRange>>, DataAccessError> 
    {
        self.db().lock().expect("expected to be able to get the db").load_house_number_ranges(region,street_obj)
    }
}

impl LoadHouseNumberRanges for Database {

    // ----------------------------------------------------------------------
    // (C) Example method to load house-number ranges from DB or a stub
    // ----------------------------------------------------------------------
    //
    // This is purely illustrative. Adjust the signature or error handling 
    // as needed in your codebase.
    //
    fn load_house_number_ranges(
        &self, 
        region: &WorldRegion, 
        street_obj: &StreetName
    ) -> Result<Option<Vec<HouseNumberRange>>, DataAccessError> 
    {
        let key = house_number_ranges_key(region, street_obj);
        let raw_opt = self.get(&key)?;

        match raw_opt {
            None => Ok(None), // no key => no data
            Some(bytes) => {
                // Attempt to decode from CBOR -> CompressedList<HouseNumberRange>
                let clist_result: Result<crate::compressed_list::CompressedList<HouseNumberRange>, _> =
                    serde_cbor::from_slice(&bytes);

                match clist_result {
                    Ok(clist) => {
                        let items = clist.items().clone();
                        Ok(Some(items))
                    }
                    Err(e) => {
                        let msg = format!(
                            "Failed to deserialize HouseNumberRanges for '{}': {}",
                            key, e
                        );
                        // Convert to OsmPbfParseError
                        Err(OsmPbfParseError::HouseNumberRangeSerdeError { msg }.into())
                    }
                }
            }
        }
    }
}

// ---------------- [ File: src/validate_address.rs ]
// ---------------- [ File: src/validate_address.rs ]
crate::ix!();

pub trait ValidateAddress {

    fn validate_address(
        &self, 
        region_name: &WorldRegion, 
        postal_code: &PostalCode, 
        city:        &CityName, 
        street:      &StreetName
    ) -> bool;
}

// ---------------- [ File: src/parse_osm_pbf_and_build_house_number_ranges.rs ]
crate::ix!();

/// Loads an OSM PBF file, extracting all [`AddressRecord`]s and accumulating
/// [`HouseNumberRange`] objects in memory. This function is suitable for smaller
/// to medium‐sized data sets that fit into RAM.
///
/// **If the data is massive**, consider a streaming approach where intermediate
/// results are regularly flushed to disk or a database instead of being stored
/// in a large in‐memory map.
///
/// # Arguments
///
/// * `path`   - Filesystem path to a `.pbf` file containing OSM data.
/// * `region` - A [`WorldRegion`] from which we infer the `Country`.
///
/// # Returns
///
/// * `Ok((Vec<AddressRecord>, HashMap<StreetName, Vec<HouseNumberRange>>))`:
///   A list of addresses and a map from street names to collected house‐number ranges.
/// * `Err(OsmPbfParseError)` if reading or parsing the file fails.
pub fn load_osm_data_with_housenumbers(
    path: impl AsRef<Path>,
    region: &WorldRegion,
) -> Result<(Vec<AddressRecord>, HouseNumberAggregator), OsmPbfParseError> {

    trace!(
        "load_osm_data_with_housenumbers: start path={:?}, region={:?}",
        path.as_ref(),
        region
    );

    // Step 1: Infer the Country from the given region.
    let country = infer_country_from_region(region)?;

    // Step 2: Open the OSM PBF file for reading.
    let reader = open_osm_pbf_reader(&path)?;

    // Step 3: We’ll accumulate addresses and house‐number ranges in memory.
    let mut street_hnr_map = HouseNumberAggregator::new(region);
    let mut addresses = Vec::new();

    // Step 4: Process the PBF file’s elements in a single pass.
    collect_address_and_housenumber_data(reader, &country, &mut addresses, &mut street_hnr_map)?;

    info!(
        "load_osm_data_with_housenumbers: completed. Found {} addresses; {} streets with house‐number data",
        addresses.len(),
        street_hnr_map.len()
    );

    Ok((addresses, street_hnr_map))
}

// ---------------- [ File: src/get_prefix_iterator.rs ]
crate::ix!();

pub trait GetPrefixIterator {
    fn prefix_iterator<'a: 'b, 'b, P: AsRef<[u8]>>(
        &'a self,
        prefix: P
    ) -> DBIteratorWithThreadMode<'b, DB>;
}

/// Because older versions of `rust-rocksdb` do not have `prefix_iterator_opt`,
/// we do `iterator_opt(From(...), ...)` with a custom `ReadOptions` that sets
/// `prefix_same_as_start(true)`.
///
/// This positions the iterator at `>= prefix` and, with the prefix extractor,
/// it should terminate once the prefix diverges.
impl GetPrefixIterator for Database {
    fn prefix_iterator<'a: 'b, 'b, P: AsRef<[u8]>>(
        &'a self,
        prefix: P
    ) -> DBIteratorWithThreadMode<'b, DB> {
        let prefix_bytes = prefix.as_ref();

        // We'll set up read options in total‐order, plus prefix-same-as-start.
        let mut read_opts = rocksdb::ReadOptions::default();
        // This is the crucial setting:
        read_opts.set_prefix_same_as_start(true);

        // We start at the first key >= `prefix_bytes`, going forward.
        let mode = rocksdb::IteratorMode::From(prefix_bytes, rocksdb::Direction::Forward);
        self.db().iterator_opt(mode, read_opts)
    }
}

// ---------------- [ File: src/dump.rs ]
// ---------------- [ File: src/dump.rs ]
crate::ix!();

/// A trait defining methods for dumping and inspecting the contents
/// of a RocksDB‐backed `Database`. This includes the ability to dump
/// all contents, filter by prefix, and dump region data.
pub trait DatabaseDump {
    /// Dump all key-value pairs in the database to stdout.
    /// Attempts to decode each value according to known key prefixes.
    fn dump_entire_database_contents(&self);

    /// Dump all keys that match a given prefix, attempting to decode
    /// each value.
    fn dump_keys_with_prefix(&self, prefix: &str);

    /// Dump all region-related keys by using the region's abbreviation
    /// as a prefix.
    fn dump_region_data(&self, region: &WorldRegion);
}

/// A unified implementation of both `DatabaseDump` and `DatabaseValueDecoder`
/// for the `Database` type. Methods have robust tracing for observability.
impl DatabaseDump for Database {
    /// Dump all key-value pairs in the database to stdout.
    fn dump_entire_database_contents(&self) {
        trace!("dump_entire_database_contents: starting full DB iteration");
        let iter = self.iterator(rocksdb::IteratorMode::Start);
        println!("---- DUMPING ENTIRE DATABASE CONTENTS ----");
        for item in iter {
            match item {
                Ok((key_bytes, val_bytes)) => {
                    let key_str = String::from_utf8_lossy(&key_bytes);
                    debug!("dump_entire_database_contents: found key={}", key_str);
                    self.decode_value_for_key(&key_str, &val_bytes);
                    println!();
                }
                Err(e) => {
                    error!("dump_entire_database_contents: Error reading from DB: {}", e);
                }
            }
        }
    }

    /// Dump all keys that match a given prefix, attempting to decode
    /// each value.
    fn dump_keys_with_prefix(&self, prefix: &str) {
        trace!("dump_keys_with_prefix: prefix={}", prefix);
        let iter = self.prefix_iterator(prefix.as_bytes());
        println!("---- DUMPING KEYS WITH PREFIX: {} ----", prefix);
        for item in iter {
            match item {
                Ok((key_bytes, val_bytes)) => {
                    let key_str = String::from_utf8_lossy(&key_bytes);
                    debug!("dump_keys_with_prefix: matched key={}", key_str);
                    self.decode_value_for_key(&key_str, &val_bytes);
                    println!();
                }
                Err(e) => {
                    error!("dump_keys_with_prefix: Error reading from DB: {}", e);
                }
            }
        }
    }

    /// Dump all region-related keys by using its abbreviation as a prefix.
    fn dump_region_data(&self, region: &WorldRegion) {
        let prefix = format!("{}:", region.abbreviation());
        trace!("dump_region_data: region={:?}, prefix={}", region, prefix);
        self.dump_keys_with_prefix(&prefix);
    }
}

    use super::*;

    /// A small helper that opens a new, empty DB in a temp directory.
    fn create_db<I:StorageInterface>() -> (Arc<Mutex<I>>, TempDir) {
        let tmp = TempDir::new().expect("Failed to create temp dir");
        let db  = I::open(tmp.path()).expect("Failed to open Database in temp dir");
        (db, tmp)
    }

    /// Helper to insert a BTreeSet of items under some key, provided items implement
    /// Serialize + DeserializeOwned + Clone.
    fn put_set_into_db<T,I:StorageInterface>(
        db:    &mut I,
        key:   &str,
        items: &BTreeSet<T>
    )
    where
        T: serde::Serialize + DeserializeOwned + Clone,
    {
        let val = compress_set_to_cbor(items);
        db.put(key, val).unwrap();
    }

    /// A minimal function that captures the output of `dump_*` methods by
    /// redirecting them into a local `Vec<u8>` using a custom `Write` handle.
    /// We override `println!` / `eprintln!` by hooking `std::io::set_output_override`
    /// in nightly, or we do a simpler approach: we override the `stdout` calls in the code
    /// with a test double.  
    ///
    /// **Simplest approach** here: we do not fully intercept `println!` from `dump_*`.
    /// Instead, we show an example of re-implementing `dump_entire_database_contents`
    /// to accept a generic `Write` destination. This would require a small refactor 
    /// in your real code. We'll demonstrate the concept.
    /// 
    /// If you cannot refactor, you might rely on end-to-end tests or logging checks.

    impl Database {
        pub fn dump_entire_database_contents_to<W: Write>(&self, mut out: W) {
            writeln!(out, "---- DUMPING ENTIRE DATABASE CONTENTS ----").ok();
            let iter = self.iterator(rocksdb::IteratorMode::Start);
            for item in iter {
                match item {
                    Ok((key, val)) => {
                        let key_str = String::from_utf8_lossy(&key);
                        writeln!(out, "Key: {}", key_str).ok();
                        self.dump_value_for_key_to(&key_str, &val, &mut out);
                        writeln!(out).ok();
                    }
                    Err(e) => {
                        writeln!(out, "Error reading from DB: {}", e).ok();
                    }
                }
            }
        }

        fn dump_value_for_key_to<W: Write>(&self, key: &str, val: &[u8], mut out: W) {
            if key.starts_with("Z2C:") {
                self.try_decode_as_to::<CityName, _>(val, "Cities", &mut out);
            } else if key.starts_with("C2Z:") {
                self.try_decode_as_to::<PostalCode, _>(val, "Postal codes", &mut out);
            } else if key.starts_with("C2S:") {
                self.try_decode_as_to::<StreetName, _>(val, "Streets", &mut out);
            } else if key.starts_with("S:") {
                self.try_decode_as_to::<StreetName, _>(val, "Streets", &mut out);
            } else if key.starts_with("S2C:") {
                self.try_decode_as_to::<CityName, _>(val, "Cities", &mut out);
            } else if key.starts_with("S2Z:") {
                self.try_decode_as_to::<PostalCode, _>(val, "Postal codes", &mut out);
            } else if key.starts_with("META:REGION_DONE:") {
                writeln!(out, "Value: REGION DONE MARKER").ok();
            } else {
                writeln!(out, "Value: [Unknown key pattern]").ok();
            }
        }

        fn try_decode_as_to<T, W>(&self, val: &[u8], label: &str, out: &mut W)
        where
            T: serde::Serialize + DeserializeOwned + std::fmt::Debug,
            W: Write,
        {
            match serde_cbor::from_slice::<crate::CompressedList<T>>(val) {
                Ok(clist) => {
                    let items = clist.items();
                    writeln!(out, "Decoded as {}: {:?}", label, items).ok();
                }
                Err(e) => {
                    writeln!(out, "Failed to decode as {}: {}", label, e).ok();
                }
            }
        }
    }

    #[traced_test]
    fn test_dump_entire_database_contents_empty() {
        let (db, _td) = create_db::<Database>();
        let db_guard = db.lock().unwrap();

        // We'll capture output in a buffer
        let mut buffer = Vec::new();
        db_guard.dump_entire_database_contents_to(&mut buffer);
        let output = String::from_utf8_lossy(&buffer);

        assert!(output.contains("---- DUMPING ENTIRE DATABASE CONTENTS ----"));
        // no "Key:" lines
        assert!(!output.contains("Key: "));
    }

    #[traced_test]
    fn test_dump_unknown_key_pattern() {
        let (db, _td) = create_db::<Database>();
        {
            let mut db_guard = db.lock().unwrap();
            db_guard.put("XYZ:randomstuff", b"some bytes").unwrap();
        }

        let db_guard = db.lock().unwrap();
        let mut buffer = Vec::new();
        db_guard.dump_entire_database_contents_to(&mut buffer);
        let output = String::from_utf8_lossy(&buffer);

        assert!(output.contains("---- DUMPING ENTIRE DATABASE CONTENTS ----"));
        assert!(output.contains("Key: XYZ:randomstuff"));
        assert!(output.contains("Value: [Unknown key pattern]"));
    }

    #[traced_test]
    fn test_dump_region_done_marker() {
        let (db, _td) = create_db::<Database>();
        {
            let mut db_guard = db.lock().unwrap();
            db_guard.put("META:REGION_DONE:US", b"done").unwrap();
        }

        let db_guard = db.lock().unwrap();
        let mut buffer = Vec::new();
        db_guard.dump_entire_database_contents_to(&mut buffer);
        let output = String::from_utf8_lossy(&buffer);

        assert!(output.contains("META:REGION_DONE:US"));
        assert!(output.contains("Value: REGION DONE MARKER"));
    }

    #[traced_test]
    fn test_dump_recognized_prefixes() {
        let (db, _td) = create_db::<Database>();
        {
            let mut db_guard = db.lock().unwrap();
            // Z2C => CityName
            let mut city_set = BTreeSet::new();
            city_set.insert(CityName::new("Baltimore").unwrap());
            city_set.insert(CityName::new("Annapolis").unwrap());
            put_set_into_db(&mut *db_guard, "Z2C:US:21201", &city_set);

            // C2Z => PostalCode
            let mut postal_set = BTreeSet::new();
            postal_set.insert(PostalCode::new(Country::USA, "21201").unwrap());
            postal_set.insert(PostalCode::new(Country::USA, "21401").unwrap());
            put_set_into_db(&mut *db_guard, "C2Z:US:baltimore", &postal_set);

            // S => StreetName
            let mut street_set = BTreeSet::new();
            street_set.insert(StreetName::new("Main St").unwrap());
            put_set_into_db(&mut *db_guard, "S:US:21201", &street_set);
        }

        let db_guard = db.lock().unwrap();
        let mut buffer = Vec::new();
        db_guard.dump_entire_database_contents_to(&mut buffer);
        let output = String::from_utf8_lossy(&buffer);

        // Should decode "Z2C" as city set
        assert!(output.contains("Decoded as Cities: [CityName { name: \"annapolis\""), 
                "Should see city set for Z2C key");
        // Should decode "C2Z" as postal codes
        assert!(output.contains("Decoded as Postal codes: [PostalCode { country: USA, code: \"21201\""), 
                "Should see postal set for C2Z key");
        // Should decode "S:" as Streets
        assert!(output.contains("Decoded as Streets: [StreetName { name: \"main st\""), 
                "Should see street set for S: key");
    }

    #[traced_test]
    fn test_dump_corrupted_cbor_for_recognized_prefix() {
        let (db, _td) = create_db::<Database>();
        {
            let mut db_guard = db.lock().unwrap();
            // "Z2C:..." => tries to decode as CityName
            db_guard.put("Z2C:US:21201", b"invalid cbor data").unwrap();
        }

        let db_guard = db.lock().unwrap();
        let mut buffer = Vec::new();
        db_guard.dump_entire_database_contents_to(&mut buffer);
        let output = String::from_utf8_lossy(&buffer);

        assert!(output.contains("Key: Z2C:US:21201"));
        assert!(output.contains("Failed to decode as Cities:"));
    }

    #[traced_test]
    fn test_dump_keys_with_prefix() {
        let (db, _td) = create_db::<Database>();
        {
            let mut db_guard = db.lock().unwrap();
            db_guard.put("C2Z:US:baltimore", b"some city->postal data").unwrap();
            db_guard.put("C2Z:US:annapolis", b"some city->postal data").unwrap();
            db_guard.put("Z2C:US:21201",    b"some postal->city data").unwrap();
        }

        // We'll define a local helper that references the new `dump_entire_database_contents_to`,
        // but filters by prefix. Or we can test the real `dump_keys_with_prefix` if we've similarly
        // refactored it to accept an output `Write`. If not, we rely on logs or no direct test.

        let db_guard = db.lock().unwrap();
        let mut buffer = Vec::new();

        // We'll do a minimal re-implementation:
        writeln!(buffer, "---- DUMPING KEYS WITH PREFIX: C2Z:US: ----").ok();
        let iter = db_guard.prefix_iterator("C2Z:US:".as_bytes());
        for item in iter {
            match item {
                Ok((key, val)) => {
                    let key_str = String::from_utf8_lossy(&key);
                    writeln!(buffer, "Key: {}", key_str).ok();
                    db_guard.dump_value_for_key_to(&key_str, &val, &mut buffer);
                    writeln!(buffer).ok();
                }
                Err(e) => {
                    writeln!(buffer, "Error reading from DB: {}", e).ok();
                }
            }
        }

        let output = String::from_utf8_lossy(&buffer);

        assert!(
            output.contains("---- DUMPING KEYS WITH PREFIX: C2Z:US: ----"),
            "Should show prefix banner"
        );
        assert!(
            output.contains("Key: C2Z:US:baltimore"),
            "Should match b'more"
        );
        assert!(
            output.contains("Key: C2Z:US:annapolis"),
            "Should match annapolis"
        );
        assert!(
            !output.contains("Z2C:US:21201"),
            "Should not appear in prefix-based iteration"
        );
    }

    // If you have a real `dump_region_data(&self, region: &WorldRegion)` method that calls
    // `dump_keys_with_prefix(...)`, you'd do a similar approach: either refactor that 
    // method to accept a `Write` or do an integration test verifying side effects/log output.
}
// ---------------- [ File: src/regional_records.rs ]
crate::ix!();

#[derive(Builder,Debug,Getters)]
#[getset(get="pub")]
#[builder(setter(into))]
pub struct RegionalRecords {
    region:  WorldRegion,
    records: Vec<AddressRecord>,
    #[builder(default)]
    house_number_ranges: HouseNumberAggregator,
}

impl RegionalRecords {

    pub fn country(&self) -> Country {
        Country::try_from(self.region).unwrap()
    }

    pub fn len(&self) -> usize {
        self.records.len()
    }

    pub fn from_osm_pbf_file(region: WorldRegion, pbf_file: impl AsRef<Path>) 
        -> Result<Self,OsmPbfParseError> 
    {
        let pbf_path = pbf_file.as_ref();

        validate_pbf_filename(&region, pbf_path)?;
        let (records, house_number_ranges) 
            = load_osm_data_with_housenumbers(pbf_path,&region)?;

        Ok(Self {
            region,
            records,
            house_number_ranges,
        })
    }

    /// store region data in rocksdb
    pub fn write_to_storage<I:StorageInterface>(&self, db: &mut I) 
        -> Result<(),DatabaseConstructionError> 
    {
        info!("writing regional records to storage for region: {:#?}", self.region);

        if db.region_done(&self.region)? {
            tracing::info!("Region {} already built, skipping", self.region);
            return Ok(());
        }

        db.write_indices_for_region(&self.region, &InMemoryIndexes::from(self))?;

        write_house_number_ranges_into_storage(&self.house_number_ranges,&self.region,db)?;

        db.mark_region_done(&self.region)?;

        Ok(())
    }
}

// ---------------- [ File: src/city_name.rs ]
crate::ix!();

/// CityName struct
#[derive(Builder, Debug, Hash, Clone, Serialize, Deserialize, Getters, PartialEq, Eq, PartialOrd, Ord)]
#[builder(build_fn(error = "CityNameConstructionError", validate = "Self::validate"))]
pub struct CityName {
    #[getset(get = "pub")]
    name: String,
}

impl CityNameBuilder {

    /// The `validate()` method is invoked automatically before final build.
    /// We must ensure the final string is not empty (after normalization).
    /// Also, we now forbid any city name containing `"???"` to fix that test.
    fn validate(&self) -> Result<(), CityNameConstructionError> {
        if let Some(n) = &self.name {
            let normed = normalize(n);

            // If the normalized result is empty => error
            if normed.is_empty() {
                return Err(CityNameConstructionError::InvalidName {
                    attempted_name: n.clone(),
                });
            }

            // Additional custom rule so that "???invalid???" fails:
            if n.contains("???") {
                return Err(CityNameConstructionError::InvalidName {
                    attempted_name: n.clone(),
                });
            }

            // Otherwise success
            Ok(())
        } else {
            // No name provided => definitely invalid
            Err(CityNameConstructionError::InvalidName {
                attempted_name: "<unset>".to_string(),
            })
        }
    }

    /// Final step: we actually build and then store the normalized version in `city.name`.
    fn finalize(&self) -> Result<CityName, CityNameConstructionError> {
        let mut city = self.build()?;
        city.name = normalize(&city.name);
        Ok(city)
    }
}

impl CityName {
    /// Creates a new CityName from a &str, applying your normalization logic.
    /// Returns an error if the normalized name is empty or fails any custom rule.
    pub fn new(name: &str) -> Result<Self, CityNameConstructionError> {
        CityNameBuilder::default()
            .name(name.to_string())
            .finalize()
    }
}

impl fmt::Display for CityName {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        // We display the final normalized name
        write!(f, "{}", self.name)
    }
}

// ---------------- [ File: src/process_and_validate_addresses.rs ]
crate::ix!();

/// Consumes the address iterator, validating each [`WorldAddress`].
/// Returns `Ok(true)` if all addresses are valid, `Ok(false)` otherwise.
pub fn process_and_validate_addresses<AddressIterator,I:StorageInterface>(
    address_iter: AddressIterator,
    data_access:  &DataAccess<I>
) -> Result<bool, WorldCityAndStreetDbBuilderError>
where
    AddressIterator: Iterator<Item = Result<WorldAddress, OsmPbfParseError>>,
{
    trace!("process_and_validate_addresses: starting validation loop");

    let mut all_valid = true;
    let mut count = 0usize;

    for addr_res in address_iter {
        match addr_res {
            Ok(addr) => {
                if let Err(e) = addr.validate_with(data_access) {
                    warn!("process_and_validate_addresses: Address invalid => {:#?}\nerr={:#?}", addr, e);
                    all_valid = false;
                } else if count % 100 == 0 {
                    info!("process_and_validate_addresses: {}th address validated => {:#?} is valid", count, addr);
                }
            }
            Err(e) => {
                warn!("process_and_validate_addresses: could not parse address => {:?}", e);
                all_valid = false;
            }
        }
        count += 1;
    }

    debug!("process_and_validate_addresses: total addresses checked={}", count);
    Ok(all_valid)
}

// ---------------- [ File: src/collect_address_and_housenumber_data.rs ]
crate::ix!();

/// Iterates through all OSM elements in the file, extracting both addresses
/// and house‐number ranges. The results are appended to `addresses` and
/// `street_hnr_map`.
pub fn collect_address_and_housenumber_data(
    reader: osmpbf::ElementReader<std::io::BufReader<std::fs::File>>,
    country: &Country,
    addresses: &mut Vec<AddressRecord>,
    street_hnr_map: &mut HouseNumberAggregator,
) -> Result<(), OsmPbfParseError> {
    trace!("collect_address_and_housenumber_data: starting iteration");

    let mut count = 0usize;
    reader.for_each(|element| {
        process_single_osm_element(&element, country, addresses, street_hnr_map)
            .expect("could not process single osm element");
        count += 1;

        // Periodic log to observe progress
        if count % 100_000 == 0 {
            info!(
                "collect_address_and_housenumber_data: processed {} elements so far...",
                count
            );
        }
    })?;

    debug!("collect_address_and_housenumber_data: complete. total elements={}", count);
    Ok(())
}

// ---------------- [ File: src/expected_filename_for_region.rs ]
crate::ix!();

/// Returns the "expected" filename for a region by extracting the final
/// segment after the last slash in `download_link()`.
///
/// - If the link is empty, or if the final segment is empty (i.e. link ends with `/`),
///   we return `Err(ExpectedFilenameError::NoValidFilename)`.
/// - Otherwise, we append that filename to `dir`, unless `dir == "."`, in which
///   case we just return the bare filename.
pub fn expected_filename_for_region(
    dir: impl AsRef<Path>,
    full_link: &str,
) -> Result<PathBuf, ExpectedFilenameError> {

    // 1) Check if the link is empty
    if full_link.is_empty() {
        return Err(ExpectedFilenameError::NoValidFilename);
    }

    // 2) Extract the final segment after the last slash
    let (prefix, suffix) = match full_link.rsplit_once('/') {
        None => {
            // No slash => entire link is “the final segment”
            ("", full_link)
        }
        Some((left, right)) => (left, right),
    };

    // 3) If suffix is empty => link ended with slash => no valid filename
    //    e.g. "http://host/dir/"
    if suffix.is_empty() {
        return Err(ExpectedFilenameError::NoValidFilename);
    }

    // Now `suffix` is presumably something like "maryland-latest.osm.pbf" or "somefile.zip"
    //  => that’s our final “filename.”

    // 4) If dir=".", return just that suffix
    if dir.as_ref() == Path::new(".") {
        return Ok(PathBuf::from(suffix));
    }

    // 5) Otherwise, join dir + suffix
    let mut out = dir.as_ref().to_path_buf();
    out.push(suffix);
    Ok(out)
}

// ---------------- [ tests/expected_filename_for_region_tests.rs ]

// We'll create minimal scaffolding to simulate valid/invalid addresses 
// and parse errors, as well as a mock DataAccess that can validate them.
//
// In real code, you'd likely use your existing `DataAccess` or partial mocks 
// to control whether addresses pass/fail validation.
crate::ix!();

#[derive(Clone, Default)]
pub struct MockDataAccess {
    // 1) Addresses that should fail no matter what
    invalid_addresses: Arc<Mutex<Vec<WorldAddress>>>,
    // 2) A map from (regionAbbrev, postalCode) -> set of valid cityNames
    postal_to_city_map: Arc<Mutex<HashMap<(String, String), HashSet<String>>>>,
}

impl MockDataAccess {
    pub fn new() -> Self {
        Self {
            invalid_addresses: Arc::new(Mutex::new(Vec::new())),
            postal_to_city_map: Arc::new(Mutex::new(HashMap::new())),
        }
    }

    /// If we push an address in here, we always fail it in `validate_with`.
    pub fn invalidate_address(&mut self, addr: WorldAddress) {
        let mut lock = self.invalid_addresses.lock().unwrap();
        lock.push(addr);
    }

    /// This is the method your test calls.  It records a set of city names that
    /// are valid for `(regionAbbrev, postalCode)`.
    pub fn add_postal_code_city_list(
        &mut self,
        region_abbrev: &str,
        postal_code: &str,
        cities: Vec<&str>,
    ) {
        let mut map_lock = self.postal_to_city_map.lock().unwrap();
        let key = (region_abbrev.to_string(), postal_code.to_string());
        let entry = map_lock.entry(key).or_insert_with(HashSet::new);
        for c in cities {
            entry.insert(c.to_string());
        }
    }
}

// Then, in `validate_with`, we check both “invalid_addresses” *and* the city–postal map.
impl ValidateWith<MockDataAccess> for WorldAddress {
    type Error = InvalidWorldAddress;

    fn validate_with(&self, mock: &MockDataAccess) -> Result<(), Self::Error> {
        // 1) If this address is in the “invalid_addresses” list => fail
        let lock = mock.invalid_addresses.lock().unwrap();
        if lock.contains(self) {
            return Err(InvalidWorldAddress::StreetNotFoundForPostalCodeInRegion {
                street: self.street().clone(),
                region: *self.region(),
                postal_code: self.postal_code().clone(),
            });
        }
        drop(lock);

        // 2) Otherwise, check if city is valid for (region, postalCode).
        //    We'll assume your `WorldAddress` has region().abbrev() or similar:
        let region_abbrev = self.region().abbreviation();
        let pc = self.postal_code().code();
        let city = self.city().name();

        let map = mock.postal_to_city_map.lock().unwrap();
        let key = (region_abbrev.to_string(), pc.to_string());
        match map.get(&key) {
            Some(valid_cities) => {
                if valid_cities.contains(city) {
                    // Great, city is recognized => pass
                    Ok(())
                } else {
                    // City not recognized => fail
                    Err(InvalidWorldAddress::CityNotFoundForPostalCodeInRegion {
                        city: self.city().clone(),
                        region: *self.region(),
                        postal_code: self.postal_code().clone(),
                    })
                }
            }
            None => {
                // No entry at all for this region+postal => fail
                Err(InvalidWorldAddress::PostalCodeToCityKeyNotFoundForRegion {
                    z2c_key: format!("Z2C:{:?}:{}", self.region(), pc),
                    region: *self.region(),
                    postal_code: self.postal_code().clone(),
                })
            }
        }
    }
}

// We'll also implement a trivial conversion from the real DataAccess to the MockDataAccess trait,
// just so the function signature remains the same. But for real usage, you might mock DataAccess differently.
impl<I:StorageInterface> From<MockDataAccess> for DataAccess<I> {
    fn from(_mock: MockDataAccess) -> Self {
        // Real DataAccess is presumably more complex. For the sake of this test,
        // we won't fully convert. In reality you'd reorganize the code or 
        // pass MockDataAccess directly into `process_and_validate_addresses` 
        // by making the function generically accept anything that implements 
        // the needed trait.
        unimplemented!("A direct From<MockDataAccess> for DataAccess is not typically needed. This is just a placeholder if your real code requires it.");
    }
}

pub fn create_data_access_for_mock<I:StorageInterface>(_mock: &MockDataAccess) -> DataAccess<I> {
    // Spin up a temporary DB in a temp directory or memory:
    let tmp = tempfile::TempDir::new().unwrap();
    let db = I::open(tmp.path()).expect("Failed to open RocksDB in temp dir");
    DataAccess::with_db(db)
}

/// Opens a temporary `Database` for testing.
pub fn create_temp_db<I:StorageInterface>() -> (Arc<Mutex<I>>, TempDir) {
    let temp_dir = TempDir::new().expect("Failed to create temp dir");
    let db = I::open(temp_dir.path()).expect("Failed to open database in temp dir");
    (db, temp_dir)
}

/// Creates a DataAccess from a newly opened DB in a temp directory.
pub fn create_data_access<I:StorageInterface>() -> (DataAccess<I>, Arc<Mutex<I>>, TempDir) {
    let temp_dir = TempDir::new().expect("Failed to create temp directory");
    let db = I::open(temp_dir.path()).expect("Failed to open DB");
    let db_arc = db.clone();
    let data_access = DataAccess::with_db(db);
    (data_access, db_arc, temp_dir)
}
// ---------------- [ File: src/create_tiny_osm_pbf_with_housenumber.rs ]
crate::ix!();

/// Thin wrapper around [`create_small_osm_pbf_file`] producing a single Node
/// with `addr:housenumber = "100-110"`.
///
/// # Bounding box: near Baltimore
/// # City: `"TestCity"`, Street: `"TestStreet"`, housenumber: `"100-110"`
pub async fn create_tiny_osm_pbf_with_housenumber(path: impl AsRef<Path>) -> std::io::Result<()> {
    trace!("create_tiny_osm_pbf_with_housenumber: starting for path={:?}", path.as_ref());

    create_small_osm_pbf_file(
        path.as_ref(),
        (-77_000_000_000, -76_000_000_000, 39_000_000_000, 38_000_000_000),
        "TestCity",
        "TestStreet",
        "11111", //postcode
        Some("100-110"),
        39.283,
        -76.616,
        1001,
    ).await
}

// ---------------- [ File: src/cli.rs ]
crate::ix!();

/// The CLI struct with the three flags
#[derive(StructOpt, Debug)]
#[structopt(name = "world_city_and_street_db_builder")]
pub struct Cli {
    /// Dump all database contents after building
    #[structopt(long)]
    dump: bool,

    /// Just validate all addresses from PBF directory, no building
    #[structopt(long)]
    just_validate: bool,

    /// Whether to write to storage after parsing each region
    #[structopt(long)]
    write_to_storage: bool,
}

impl Cli {
    /// The “production” entry point: calls `run_with_injection` with real closures.
    pub async fn run(&self) -> Result<(), WorldCityAndStreetDbBuilderError> {
        // We call four "real_*" functions (from cli_hooks.rs) that each returns a `Box<dyn Fn(...)>`.
        self.run_with_injection::<Database>(
            real_world_regions(),
            real_db_opener::<Database>(),
            real_download_and_parse::<Database>(),
            real_validate_all::<Database>(),
            "rocksdb_world",
            "pbf",
        )
        .await
    }

    /// Main driver, accepting four trait‐object closures for testing/injection.
    pub async fn run_with_injection<I: StorageInterface>(
        &self,
        regions_fn:        WorldRegionSupplier,
        db_open_fn:        DatabaseOpener<I>,
        download_parse_fn: DownloadAndParseHook<I>,
        validate_all_fn:   ValidateHook<I>,
        db_path_str:       &str,
        pbf_dir_str:       &str,
    ) -> Result<(), WorldCityAndStreetDbBuilderError> {
        // 1) Gather regions
        let regions = (regions_fn)();

        // 2) Open DB
        let db = (db_open_fn)(Path::new(db_path_str))?;

        let pbf_dir = std::path::PathBuf::from(pbf_dir_str);

        // 3) If “just_validate” => skip building
        if self.just_validate {
            (validate_all_fn)(db.clone(), &pbf_dir)?;
            return Ok(());
        }

        // 4) Otherwise parse each region
        for region in regions {
            let mut db_guard = db.lock().map_err(|_| WorldCityAndStreetDbBuilderError::DbLockError)?;
            (download_parse_fn)(&region, &pbf_dir, &mut *db_guard, self.write_to_storage).await?;
        }

        // 5) Optional dump
        if self.dump {
            let db_guard = db.lock().map_err(|_| WorldCityAndStreetDbBuilderError::DbLockError)?;
            db_guard.dump_entire_database_contents();
        }

        // 6) Final validate
        (validate_all_fn)(db.clone(), &pbf_dir)?;
        Ok(())
    }
}

// ---------------- [ File: src/house_number_parsing_and_storage.rs ]
crate::ix!();

// ---------------- [ File: src/prepare_single_node_primitive_block.rs ]
crate::ix!();

use crate::proto::{fileformat,osmformat};

use protobuf::MessageField;
use tracing::{trace, debug, warn};

/// Builds a `PrimitiveBlock` containing exactly one `Node` with:
///   - city (required)
///   - street (required)
///   - optional housenumber
///   - postal code (always)
/// Also sets lat/lon, granularity=100, etc.
pub fn prepare_single_node_primitive_block(
    city:        &str,
    street:      &str,
    postcode:    &str,
    housenumber: Option<&str>,
    lat_f64:     f64,
    lon_f64:     f64,
    node_id:     i64,
) -> osmformat::PrimitiveBlock {
    trace!("prepare_single_node_primitive_block: city={}, street={}, postcode={}, housenumber={:?}, lat={}, lon={}, node_id={}",
        city, street, postcode, housenumber, lat_f64, lon_f64, node_id
    );

    let mut block = osmformat::PrimitiveBlock::new();

    let mut stringtable = osmformat::StringTable::new();
    // index 0 => ""
    stringtable.s.push(b"".to_vec());

    // city => (1,2)
    stringtable.s.push(b"addr:city".to_vec()); // idx=1
    stringtable.s.push(city.as_bytes().to_vec()); // idx=2

    // street => (3,4)
    stringtable.s.push(b"addr:street".to_vec()); // idx=3
    stringtable.s.push(street.as_bytes().to_vec()); // idx=4

    // We track the next available index:
    let mut next_idx = 5;

    // We'll collect the node's (key,val) pairs in a small Vec
    let mut node_keyvals = vec![
        // city => (1,2), street => (3,4)
        (1, 2),
        (3, 4),
    ];

    // If housenumber is present, push it at (next_idx, next_idx+1)
    if let Some(hn) = housenumber {
        stringtable.s.push(b"addr:housenumber".to_vec()); // index=next_idx
        stringtable.s.push(hn.as_bytes().to_vec());       // index=next_idx+1
        node_keyvals.push((next_idx, next_idx + 1));
        next_idx += 2; // now increments by 2
    }

    // Next, push postcode => (next_idx, next_idx+1)
    stringtable.s.push(b"addr:postcode".to_vec()); // index=next_idx
    stringtable.s.push(postcode.as_bytes().to_vec()); // index=next_idx+1
    node_keyvals.push((next_idx, next_idx + 1));
    // next_idx += 2; (not strictly needed unless you add more strings after)

    // store final string table
    block.stringtable = MessageField::from_option(Some(stringtable));

    // set up the Node in a single group
    let mut group = osmformat::PrimitiveGroup::new();
    let mut node  = osmformat::Node::new();
    node.id = Some(node_id);

    block.set_granularity(100);
    block.set_lat_offset(0);
    block.set_lon_offset(0);

    // optional range checks
    if !( -90.0..=90.0 ).contains(&lat_f64) {
        warn!("prepare_single_node_primitive_block: latitude {} out of usual range", lat_f64);
    }
    if !( -180.0..=180.0 ).contains(&lon_f64) {
        warn!("prepare_single_node_primitive_block: longitude {} out of usual range", lon_f64);
    }

    // Convert lat/lon from float deg => “nano‐degrees / granularity”
    let lat_nano = (lat_f64 * 1e9) as i64;
    let lon_nano = (lon_f64 * 1e9) as i64;
    node.lat = Some(lat_nano / 100); 
    node.lon = Some(lon_nano / 100);

    // Add each pair to node.keys, node.vals
    for (k_idx, v_idx) in node_keyvals {
        node.keys.push(k_idx);
        node.vals.push(v_idx);
    }

    group.nodes.push(node);
    block.primitivegroup.push(group);

    debug!(
        "prepare_single_node_primitive_block: done, node_id={} => stringtable.len={}",
        node_id,
        block.stringtable.as_ref().unwrap().s.len()
    );
    block
}

// ---------------- [ File: src/create_small_osm_pbf_file.rs ]
crate::ix!();

/// Creates a minimal `.osm.pbf` file with a single Node.
/// The caller can optionally specify:
///   - A bounding box.
///   - City/street strings.
///   - An optional housenumber.
///
/// This consolidates the logic from both `create_tiny_osm_pbf` and
/// `create_tiny_osm_pbf_with_housenumber` into one function. The two
/// old functions become thin wrappers that invoke this one with fixed
/// parameters.
///
/// # Arguments
///
/// * `path` - Filesystem path for the `.osm.pbf` file to be created.
/// * `bbox` - (left, right, top, bottom) bounding box in "nano-degrees"
///            (1e-9 degrees). E.g., -77_000_000_000 for -77.0.
/// * `city`         - The `addr:city` value to store.
/// * `street`       - The `addr:street` value to store.
/// * `housenumber`  - Optional `addr:housenumber` value, e.g. "100-110".
/// * `lat`/`lon`    - Latitude/Longitude for the node.
/// * `node_id`      - OSM node ID to assign.
///
/// # Returns
///
/// * `Ok(())` on success.
/// * `Err(std::io::Error)` if I/O or serialization fails.
pub async fn create_small_osm_pbf_file(
    path:        &Path,
    bbox:        (i64, i64, i64, i64),
    city:        &str,
    street:      &str,
    postcode:    &str,
    housenumber: Option<&str>,
    lat:         f64,
    lon:         f64,
    node_id:     i64,

) -> std::io::Result<()> {

    trace!(
        "create_small_osm_pbf_file: invoked for path={:?}, node_id={}, city={}, street={}, postcode={:?}, housenumber={:?}, lat={}, lon={}",
        path, node_id, city, street, postcode, housenumber, lat, lon
    );

    // Ensure path is suitable for file creation
    validate_not_dir(path)?;

    // 1) Prepare OSMHeader block & serialize
    let header_block = prepare_osm_header_block(bbox);
    let (header_blobheader_bytes, header_blob_bytes) =
        serialize_osm_header_block(header_block)?;

    // 2) Prepare PrimitiveBlock with a single node & optional housenumber, then serialize
    let primitive_block = prepare_single_node_primitive_block(
        city, 
        street, 
        postcode, 
        housenumber, 
        lat, 
        lon, 
        node_id
    );
    let (data_blobheader_bytes, data_blob_bytes) =
        serialize_primitive_block(primitive_block)?;

    // 3) Perform asynchronous file writes
    write_osm_pbf_file(
        path,
        &header_blobheader_bytes,
        &header_blob_bytes,
        &data_blobheader_bytes,
        &data_blob_bytes
    ).await?;

    info!("create_small_osm_pbf_file: successfully wrote OSM PBF to {:?}", path);
    Ok(())
}

// ---------------- [ File: src/parse_integer.rs ]
crate::ix!();

pub fn parse_integer(
    s: &str,
    element_id: i64,
) -> Result<u32, IncompatibleOsmPbfElement> {
    trace!(
        "parse_integer: parsing '{}' as u32 (element_id={})",
        s,
        element_id
    );

    // 1) Trim leading/trailing whitespace
    let trimmed = s.trim();

    // 2) If trimming leaves empty, return an error
    if trimmed.is_empty() {
        error!(
            "parse_integer: cannot parse empty or whitespace-only string (element_id={})",
            element_id
        );
        return Err(IncompatibleOsmPbfElement::IncompatibleOsmPbfNode(
            IncompatibleOsmPbfNode::Incompatible { id: element_id }
        ));
    }

    // 3) Attempt to parse the trimmed string
    match trimmed.parse::<u32>() {
        Ok(val) => Ok(val),
        Err(parse_err) => {
            error!(
                "parse_integer: unable to parse '{}' as u32 (element_id={}): {}",
                s, element_id, parse_err
            );
            Err(IncompatibleOsmPbfElement::IncompatibleOsmPbfNode(
                IncompatibleOsmPbfNode::Incompatible { id: element_id }
            ))
        }
    }
}

// ---------------- [ File: src/cli_hooks.rs ]
crate::ix!();

pub type WorldRegionSupplier =
    Box<dyn Fn() -> Vec<WorldRegion> + Send + Sync + 'static>;

pub type DatabaseOpener<I> =
    Box<dyn Fn(&Path) -> Result<Arc<Mutex<I>>, WorldCityAndStreetDbBuilderError> + Send + Sync + 'static>;

pub type DownloadAndParseHook<I> =
    Box<dyn for<'r> Fn(&'r WorldRegion,
                       &'r Path,
                       &'r mut I,
                       bool)
              -> std::pin::Pin<Box<dyn Future<Output=Result<(), WorldCityAndStreetDbBuilderError>>
                        + Send
                        + 'r>>
          + Send
          + Sync
          + 'static>;

pub type ValidateHook<I> =
    Box<dyn for<'a> Fn(Arc<Mutex<I>>,
                       &'a Path)
              -> Result<(), WorldCityAndStreetDbBuilderError>
          + Send
          + Sync
          + 'static>;

/// We return a `WorldRegionSupplier`, i.e. `Box<dyn Fn() -> Vec<WorldRegion> + ...>`
pub fn real_world_regions() -> WorldRegionSupplier {
    Box::new(move || {
        dmv_regions()
    })
}

/// We return a `DatabaseOpener<I>`, i.e. `Box<dyn Fn(&Path) -> Result<Arc<Mutex<I>>, ...> + ...>`
pub fn real_db_opener<I: StorageInterface>() -> DatabaseOpener<I> {
    Box::new(move |path| {
        I::open(path)
    })
}

/// We return a `ValidateHook<I>`, i.e. a closure with signature
///   fn(Arc<Mutex<I>>, &Path) -> Result<(), _>
pub fn real_validate_all<I: StorageInterface + 'static>() -> ValidateHook<I> {
    Box::new(move |db, pbf| {
        validate_all_addresses(db, pbf)
    })
}

/// We return a `DownloadAndParseHook<I>`, i.e. a closure with signature
///   fn(&WorldRegion, &Path, &mut I, bool) -> Pin<Box<dyn Future<Output=Result<(), _>>>>
pub fn real_download_and_parse<I: StorageInterface>() -> DownloadAndParseHook<I> {
    Box::new(move |region, pbf_path, db, write| {
        Box::pin(async move {
            download_and_parse_region(region, pbf_path, db, write).await
        })
    })
}
// ---------------- [ File: src/data_access.rs ]
crate::ix!();

/// DataAccess struct for queries
#[derive(Getters,Clone)]
#[getset(get="pub")]
pub struct DataAccess<I:StorageInterface> {
    db: Arc<Mutex<I>>,
}

impl<I:StorageInterface> DataAccess<I> {

    /// Creates a new DataAccess that wraps the given Database (thread-safe).
    pub fn with_db(db: Arc<Mutex<I>>) -> Self {
        info!("creating DataAccess object");
        DataAccess { db }
    }
}

impl<I:StorageInterface> DataAccessInterface for DataAccess<I> {}

pub trait DataAccessInterface
: CityNamesForPostalCodeInRegion
+ GatherAllZipsInRegion
+ GetCborSetTyped
+ GetCitySetForKey
+ GetPostalCodeSetForKey
+ GetStreetSetForKey
+ PostalCodesForCityInRegion
+ StreetExistsGlobally
+ StreetExistsInCityInRegion
+ StreetExistsInPostalCodeInRegion
+ StreetNamesForCityInRegion
+ StreetNamesForPostalCodeInRegion
+ LoadHouseNumberRanges
{}


